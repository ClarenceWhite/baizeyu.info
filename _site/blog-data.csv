_id,title,content,last_modified,category,_class
63d2ffc989b5431024b2bc5e,"Dvořák: The Symphony No. 9 ""From the New World""","I started my first day as a part-time teaching assistant today and also started seeking work in a foreign country for the first time. On the way home I randomly cycled through Dvorak's classics, my favourites being the second and fourth chapter, they are very different in style but both reflect the feeling of living far from home in a new land. All in all, this piece made my heart sing and resonated with me and I fell in love with it on the first listen.  \n\nYoutube link to the great piece:  \n[Dvořák: The Symphony No. 9 ""From the New World""](https://youtu.be/jOofzffyDSA?t=2046)",2023-01-26T22:32:54.570Z,music,com.baizeyu.published.model.Published
63d5aa706df14f36708250b3,How to serve React with Docker and Nginx,"# Intro\nThis tutorial shows you how to serve your React.js web App with Docker + Nginx, we will also explore securing the website with Https using a trusted CA (Certificate Autority). Are you ready? Let's go!\n# Dockerfile without SSL firstly\nIn the frontend (React) root folder, say, the same level as 'public', 'src', 'node_modules', we are going to create a file named 'Dockerfile', this file contains the following configuration:  \n```\nFROM node:19-alpine as builder\n# Set the working directory to /app inside the container\nWORKDIR /app\n# Copy app files\nCOPY . .\n# Install dependencies (npm ci makes sure the exact versions in the lockfile gets installed)\nRUN npm ci \n# Build the app\nRUN npm run build\n\n# Bundle static assets with nginx\nFROM nginx:1.21.0-alpine as production\nENV NODE_ENV production\n# Copy built assets from `builder` image\nCOPY --from=builder /app/build /usr/share/nginx/html\n# Add your nginx.conf\nCOPY nginx.conf /etc/nginx/conf.d/default.conf\n# Expose port only for HTTP\nEXPOSE 80\n# Start nginx\nCMD [""nginx"", ""-g"", ""daemon off;""]\n```\nps: to avoid the image being huge, we also need a '.dockerignore' file, simply put the two folder names in this file:\n```\nnode_modules\nbuild\n```\n# Nginx Configuration for Http firstly\nAlso, at the same level as our 'Dockerfile', under React root folder, we gonna create another file called 'nginx.conf', this file configures the Nginx server:\n```\nserver {\n    listen 80;\n    server_name baizeyu.info www.baizeyu.info;\n\n    location / {\n        root /usr/share/nginx/html/;\n        include /etc/nginx/mime.types;\n        try_files $uri $uri/ /index.html;\n    }\n}\n```\n# Try to run Http version first\nOK, now we have a basic Dockerfile and nginx config file, let's build it into image and test it locally.\n- Open terminal, cd to our React root folder first.\n- Then run this command to build a image: `docker build -t react-http .`, while 'react-http' is the name of the image, oh, don't forget to start your Docker Desktop first ^-^!\n- Check if we've successfully built the image using: `docker images | grep react-http`.\n- If you already got an image, let's try to run this single image with port forwarding to localhost first: `docker run -p 80:80 react-http` .\n- After the above command, our react-http App has already started on localhost, go to the browser and enter http://localhost, you should see your React App default index page!\n# Want Https?\nTo enable Https on the site, we need to get a CA signed SSL certificate first, there are many free or paid options you can choose over the Internet, I used [ZeroSSL](https://zerossl.com/). Normally, you will get a zip which contains 3 files (a certificate file with extension .crt, a ca_bundle file with extension .crt, and a private key file with extension .key) from a provider. By the way, 'certificate.crt' and 'private.key' should be matched, we can check it using [this site.](https://www.sslshopper.com/certificate-key-matcher.htmll)\n   \nOnce you've got a certificate, we gonna move on:  \n**- Copy 'certificate.crt' and 'private.key' files to React root folder.**   \n**- Change  Dockerfile into this:**\n```\nFROM node:19-alpine as builder\n# Set the working directory to /app inside the container\nWORKDIR /app\n# Copy app files\nCOPY . .\n# Install dependencies (npm ci makes sure the exact versions in the lockfile gets installed)\nRUN npm ci \n# Build the app\nRUN npm run build\n\n# Bundle static assets with nginx\nFROM nginx:1.21.0-alpine as production\nENV NODE_ENV production\n# Copy built assets from `builder` image\nCOPY --from=builder /app/build /usr/share/nginx/html\n# Copy SSL certs to container\nCOPY ./certificate.crt /etc/nginx/certs/certificate.crt\nCOPY ./private.key /etc/nginx/certs/private.key\n# Add your nginx.conf\nCOPY nginx.conf /etc/nginx/conf.d/default.conf\n# Expose port\nEXPOSE 80\nEXPOSE 443\n# Start nginx\nCMD [""nginx"", ""-g"", ""daemon off;""]\n```\nAs we can see, we copied 'certificate.crt' and 'private.key' into the image, and exposed port 443 for Https requests, simple right?  \n\n**- Then change nginx.conf as well:**\n```\n# nginx.conf\n\nserver {\n    listen 443 ssl;\n    server_name baizeyu.info www.baizeyu.info;\n    ssl_certificate /etc/nginx/certs/certificate.crt;\n    ssl_certificate_key /etc/nginx/certs/private.key;\n\n    location / {\n        root /usr/share/nginx/html/;\n        include /etc/nginx/mime.types;\n        try_files $uri $uri/ /index.html;\n    }\n}\n\nserver {\n    listen 80;\n    server_name baizeyu.info www.baizeyu.info;\n    return 301 https://$host$request_uri;\n}\n```\nThis time, port 443 will host the static content, any request to port 80 which is Http, will be redirected to Https. Status code 301 means redirect.\n\n----------\n\nCongrats! We are all set by now! try to **build the image again** and **run the image with port forwarding to 443**, you should be fine if you go to https://localhost.",2023-01-28T23:04:31.361Z,tech,com.baizeyu.published.model.Published
63d98c2cf98c114fc8128ab1,The Symposium (会饮篇),# About\n这本书是我偶然刷到B站罗翔老师对这本书的解读后直接用1欧元买到三天读完的小书，感谢罗老师🤣，完整直播链接：https://www.bilibili.com/video/BV1zT4y1K7sm/\n\n# Notes\n- 因为我知道，对于一个刚开始生活的年轻人而言，没有什么能比有一个忠贞的爱人更幸福的了，或者对于爱人而言没有什么能比有一位心爱的少年更幸福的了。\n- 因此如果能想出一个方法，叫一个城邦或是一个军队全由爱人和他们的所爱组成，他们将会成为自己城市的最好管理者，戒除所有耻辱，彼此竞争获得荣誉；并且如果他们并肩作战，虽然只有少数人，也可征服全世界。\n- 爱情会使男人们敢于为他们心爱的人献出生命——这一点只有爱情可以做到，女人们亦是如此。\n- 尘世女神所引起的爱本质上是尘世的，并且没有差别，比如人类的较为粗俗的感受，这种爱往往是女人们的还有青年人们的爱，是肉体的而非心灵上的——最愚蠢的人就是这种爱的对象，即只贪求达到目标，却从不考虑是否是高尚地达到了目的，因此有这种爱的人做事不分善恶，而天国女神的产生却没有女性的成分，——她的产生只来自于男性。这种爱只属于青年，此外，因为这位女神年龄较长，她没有任何放荡淫乱的念头。受到这种爱鼓舞的人们更倾向于男子，喜欢他，因为他具有更勇敢、更聪明的本质。任何人都可以看出他们情感特质中的纯粹热情。他们爱的不是男孩，而是他们的智慧，他们推理能力差不多在他们刚长胡子的时候就开始发展提高了。在选择青年作为伴侣时，他们是想要对对方忠诚，并使之成为终生伴侣，而不是要利用他们的年幼无知来欺骗他们，愚弄他们，或是碰到另外的对象就将前者抛弃。\n- 爱肉体多于爱灵魂的凡俗人的爱是令人讨厌的，就像善变一样令人讨厌，因为他所爱的事物本身就是不稳定的，所以当他渴望的青春年华不复存在的时候，他就会不顾任何誓言，远走高飞。但品质高尚的爱却是永恒的，因为这爱与永恒不变结为一体。\n- 爱人为心上人做的任何事情对他来说都不算是谄媚，或是耻辱，因此被爱的人仅有一种自愿服务的方式，而且这方式是受人尊敬的，这是正直而善良的奉献。\n- 因此，但凡为了美德而接受一个人都是高尚的。这是神圣的，起于天国女神的爱情，对于个人和城邦来说，它都是非常宝贵的，它使得爱人和被爱的人都渴望为自身的进步而努力。\n- 分开后，人类的这两个部分，每一个都渴望找到他的另一半，他们走到一起，伸出手来，紧紧地拥抱彼此，渴望融为一体，他们几乎要死于饥饿和自我忽视，因为分开之后他们不愿做任何事情；而且当一半死去时，而另一半还活着，幸存的那一半就会寻找另一个伴侣，就像我们所称呼的那样，他们要么是男人要么是女人——因为他们是由百分之百的男人或女人截得下来的——找到后就紧紧依附在一起。\n- 要么如果是男人遇到男人，他们由此也会获得满足，平静下来，开始生活：根植在我们身上对彼此的渴望是如此久远，把我们原来的本性再次结合在一起，合二为一，治愈人类的伤痛。\n- 但是由男人截下的就会追求男人，当他们年轻时，由于原本是男人截下的，他们会徘徊在男人周围，拥抱他们，他们是男孩和青年中最优秀的，因为他们的男性特征最突出。有些人甚至肯定地说他们是伤风败俗的，但这说法不对。因为他们不是想要给自己蒙羞才这样做的，而是因为他们英勇而强壮，具有男人的沉着冷静，他们拥抱的是与他们相像的另一半。\n- 原因是人类的本性原本就是一个整体，对于完整的渴望和追求即被称作爱。\n- 有一行诗突然浮现在我的脑海里，诗文里说爱神就是这样一位神：“给世界带来和平，使暴风雨平静下来，让风静止，努力让受害者睡去。”\n- 是爱神把人类的不满去掉，取而代之的是喜爱，是他让人们在这样的场合上相遇：祭祀，宴席，舞会，他是我们的主——他送来了礼节，打发掉无礼和粗鲁，他永远善良、仁慈，从不刻薄；爱是美好带来的欢欣，智慧创造的奇观，神仙赋予的惊奇，缺乏爱的人渴望得到它，拥有爱的人又万般珍惜它；他是微妙、奢侈、愿望、爱好、温柔、优雅的根源；他关注美德，无视邪恶：在每个词语、职业、愿望和恐惧中，爱神是救世主、领航员、同伴和助手；神和人的荣耀，最优秀、最聪明的领导者：每个人都追寻他的脚步，唱着甜蜜的歌赞美他，加入到那甜蜜的旋律中，由此，爱让神和人的灵魂陶醉。\n- 因为对于不能永生的生物而言，繁殖是一种获得永存和永生的方式，”她答道，“如果，就像已经承认的，爱就是永远拥有美好的事物，所有的人就必然渴望既长生不老又拥有美好的事物：因此爱就是永生。”\n- 爱的事物之中真正的顺序，或由另一人引导的顺序是从尘世的美丽开始，为了寻求其他的美丽而攀升，只是把这些作为台阶，从一级走向二级，从二级走向所有美丽的形式，从美丽的形式走向美丽的实践，从美丽的实践到美丽的观念，直到从美丽的观念处他得出绝对美丽的概念，最后他知道了爱的本质是什么。\n- 对喜剧有天赋的人对悲剧也有天赋，真正创作悲剧的艺术家也是真正创作喜剧的艺术家。,2023-01-31T21:46:12.067Z,reading,com.baizeyu.published.model.Published
63dacfddf98c114fc8128ab3,《遥远的救世主》,# About\n这是一本影响了我两年的书，也有同名电视剧《天道》，王志文老师主演。有的人看了觉得这是有套路的霸道总裁装B小说，但我始终觉得书中很多地方在那个年代能写出来已经算是超前了，放在今天仍然值得思考，并不是简单的装B小说。\n\n# Notes\n- 丁元英从衣袋里拿出一盒三五香烟点上一支，说：「既是规矩，就没什么可抱歉的。是我该谢你们，没有你们的担保，我一个马克也拉不来。」 詹妮也点上一支烟说：「如果我认为有风险，我不会给你担保，韩楚风他们也不会。你让我们都赚到了钱，这才是本质。」\n- 丁元英说：「我也不同意，这倒不是因为茶馆的产权是老爹的。你把茶馆的门坎垒得太高了，家长里短的茶客喝不起了，茶馆的市井味儿就没了。老人有个事儿忙叨着，充实、乐呵，这是性价比最高的消费。」\n- 丁元英说：「有开张就会有倒闭，规律，只是咱们这周期短了点。」\n- 肖亚文把账单和现金放进箱子里，说：「丁总，您怎么不问问我以后有什么打算？」 丁元英说：「这不礼貌。」\n- 肖亚文问：「丁总，您明天什么时候动身？我去送您。」 丁元英说：「有地址，就不麻烦你了。这一年你也没少辛苦，回去好好休息休息。」 肖亚文笑了笑说：「丁总，您这茶凉得也太快了，连个溜须拍马的机会都不给？」 丁元英说：「拍了没用，就不用拍了。」 肖亚文说：「删掉溜须拍马的成分，我就更得去了。」\n- 丁元英望着车窗外流光溢彩的大街，说：「国内信用是个问题。私募基金是没爹没娘的买卖，一边做生意，一边得准备拼刀子，脑后还得长只眼睛看衙门的脸色。」\n- 丁元英也是淡淡一笑说：「建时凭心凭理超度亲疏，不失佛门正本。但他的佛根里只有熔点没有正智，所以他看我是一个元宝不失德性，一坛元宝图财害命。他那个佛，是修来世正果的佛，他还得到佛祖那儿多咨询咨询。」 韩楚风问：「那你呢？」 丁元英说：「我？正果是不想了，尘埃落定。」\n- 丁元英说：「我们这个民族总是以有文化自居，却忘了问一句：是有什么文化？是真理真相的文化还是弱势文化？是符合事物规律的文化还是违背事物规律的文化？任何一种命运，归根到底都是那种文化属性的产物，不以人的意志为转移。」\n- 丁元英说：「马克思主义的道理归根到底一句话：客观规律不以人的意志为转移。什么是客观规律？归根到底也是一句话：一切以时间、地点和条件为转移。」\n- 丁元英醉醺醺地说：「中国的传统文化是皇恩浩大的文化，它的实用是以皇天在上为先决条件。中国为什么穷？穷就穷在幼稚的思维，穷在期望救主、期望救恩的文化上，这是一个渗透到民族骨子里的价值判断体系，太可怕了。」\n- 韩楚风没有回答，脑海里却想着尼采的一句话：更高级的哲人独处着，这并不是因为他想孤独，而是因为在他周围找不到他的同类。　　\n- 丁元英说：「同一首《流浪者之歌》的曲子，以穆特与弗雷德里曼的小提琴相比较，穆特诠释的是悲凉、悲伤、悲戚，弗雷德里曼诠释的是悲愤、悲壮、悲怆，不一样，穆特多了点宫廷贵妇的哀怨，少了点吉普赛人流浪不屈的精神。」\n- 丁元英说：「海飞兹是伟大的小提琴大师，但是单就《流浪者之歌》这首曲子，他的诠释也不一定是最高境界。也许他太在乎技艺精湛了，反而染了一丝匠气，淡了一丝虔诚。以他们3人各自演奏的《流浪者之歌》相比较，我觉得穆特是心到手没到，海飞兹是手到心没到，只有弗雷德里曼是手到心到。」\n- 自　嘲  \n本是后山人， 偶做前堂客。 醉舞经阁半卷书， 坐井说天阔。 大志戏功名， 海斗量福祸。 论到囊中羞涩时， 怒指乾坤错。\n- 肖亚文说：「你先好好听着，我还没说到地狱呢。我见过他前妻，也聊过几句，你可以参考参考他前妻说的话。她说，他永远都不会跟你吵架，他的每一个毛孔里都渗透着对世俗文化的居高临下的包容，包容到不屑于跟你讲道理，包容到让你自己觉得低俗、自卑，当你快要憋死、快要疯掉的时候，你能想到的就只有一个字，逃！」\n- 丁元英心里明白这是揭幕的前奏，于是坦率地说：「女人是形式逻辑的典范，是辩证逻辑的障碍，我无意摧残女人，也不想被女人摧残。」 芮小丹说：「女人就这么难养吗？」 丁元英说：「红颜知己自古有之，这还得看男人是不是一杯好酒，自古又有几个男人能把自己酿到淡而又淡的名贵？这不是为之而可为的事，能混就混吧。」 芮小丹说：「我想，以后我们像这样坐在一起的机会该是没有了。你是明白人，女人那点兜圈子的套路就免了，我今天请你来不为别的，就为履行个程序。」\n- 他站起身，弯腰捡起那件睡衣，轻轻地给芮小丹裹在身上，又坐回到原处，望着她极其诚恳地说道：「你是一块玉，但我不是匠人，我不过是一个略懂投机之道的混子，充其量挣几个打发凡夫俗子的铜板。你要求的，是一种雄性文化的魂，我不能因为你没说出来而装不知道。接受你，就接受了一种高度，我没有这个自信。」\n- 丁元英说：「透视社会依次有三个层面：技术、制度和文化。小到一个人，大到一个国家一个民族，任何一种命运归根到底都是那种文化属性的产物。强势文化造就强者，弱势文化造就弱者，这是规律，也可以理解为天道，不以人的意志为转移。」 芮小丹问：「什么是强势文化？什么又是弱势文化？」 丁元英说：「强势文化就是遵循事物规律的文化，弱势文化就是依赖强者的道德期望破格获取的文化，也是期望救主的文化。强势文化在武学上被称为「秘笈」，而弱势文化由于易学、易懂、易用，成了流行品种。」\n- 「灵魂归宿感。」丁元英解释说：「这是人性本能的需要，是人性，你帮他找块干净的地方归宿灵魂，他需要的不是忏悔，而是一个可以忏悔的理由。」\n- 她脑海里再次浮现出肖亚文说过的那些话：是魔、是鬼都可以，就是不是人……以我的智力，我理解不了这种人……他想一个人清静清静……他的每一个毛孔里都渗透着对世俗文化的居高临下的包容……丁元英这种人对女人没有意义，是女人就有贪嗔痴，没有贪嗔痴的女人是天国的女人……\n- 丁元英站起来说：「散会前，咱们特别针对这个有救没救的事再絮叨两句。咱们翻开历史看看，你从哪一行哪一页能找到救世主救世的记录？没有，从来就没有，从来都是救人的被救了，被救的救了人。如果一定要讲救世主的话，那么符合和代表客观规律的文化就是救世主。这话在这儿讲有点转文了，具体到咱们当下这事，就是认准市场，吃别人吃不了的苦，受别人受不了的罪，做别人做不到的成本和质量。这个，就是你们的救世主。扶贫的本质在一个扶字，如果你根本就没打算自己站起来，老天爷来了都没用。好了，散会。」\n- 丁元英说：「什么神话？不过是强力作用的杀富济贫，扒着井沿看一眼而已，不解决造血问题，谁敢拿着一个村子的农民去证明扒井沿儿看一眼的结果？那就不是错了，是罪。如果真理是人做出来的，那也不叫真理了，叫主义。」\n- 韩楚风开着车说：「这盘菜不是人人都能吃的，如果扒着井沿儿看一眼再掉下去，那就真是饱了眼福，苦了贪心，又往地狱里陷了一截子。」\n- 悟  \n悟道休言天命， 修行勿取真经。 一悲一喜一枯荣， 哪个前生注定？ 袈裟本无清净， 红尘不染性空。 幽幽古刹千年钟， 都是痴人说梦。\n- 丁元英回答道：「大师考问晚辈自在情理之中，晚辈就斗胆妄言了。所谓真经，就是能够达到寂空涅碦的究竟法门，可悟不可修。修为成佛，在求。悟为明性，在知。修行以行制性，悟道以性施行，觉者由心生律，修者以律制心。不落恶果者有信无证，住因住果、住念住心，如是生灭。不昧因果者无住而住，无欲无不欲，无戒无不戒，如是涅碦。」\n- 丁元英说：「晚辈以为，传统观念的死结就在一个『靠』字上，在家靠父母，出门靠朋友，靠上帝、靠菩萨、靠皇恩……总之靠什么都行，就是别靠自己。这是一个沉积了几千年的文化属性问题，非几次新文化运动就能开悟。晚辈无意评说道法，只在已经缘起的事情里顺水推舟，借英雄好汉的嗓子喊上两声，至少不违天道朝纲。」\n- 智玄大师说：「弱势得救之道，也有也没有。没有竞争的社会就没有活力，而竞争必然会产生贫富、等级，此乃天道，乃社会进步的必然代价。无弱，强焉在？一个『强』字，弱已经在其中了。故而，佛度心苦，修的是一颗平常心。」\n- 韩楚风因为先前不了解情况，所以一直没有参与谈话。此时听了智玄大师一番话心生感慨，说道：「佛教主张利和同均，大师坦言等级乃天道与代价，不拘门户之见，令晚辈十分敬佩。晚辈在想，如果强者在公开、合法的情况下都可以做到杀掠，那么在不公开、不合法的条件下，弱势还剩下多大空间？佛度心苦虽慈悲，但人毕竟还有物质的一面。」\n- 丁元英说：「不敢，不敢。释、道、儒均是博大精深的学派，支撑中华民族走过了几千年的文明历程，是伟大的文明。但是，社会在发展，传统文化毕竟是以皇恩浩荡为先决条件的文化，讲的都是皆空、无为、中庸的理，以抑制个性而求生求解。当今社会已经发展到了市场经济的民主与法制，诸家学说也面临一个如实观照而俱进的课题，是传统？还是传承？统则僵死，承则光大。」\n- 丁元英说：「是皇天在上的文化，是救主、救恩的文化。如果一个民族的文化从骨子里就是弱势文化属性，怎么可能去承载强势文化的政治、经济？衡量一种文化属性不是看它积淀的时间长短，而是看它与客观规律的距离远近。五千年的文化是光辉、是灿烂，这个没有问题。但是，传统和习俗得过过客观规律的筛子。」\n- 肖亚文说：「记得有一次丁总请韩总吃饭的时候酒桌上闲聊，我问丁总，为人处事怎么才能做到恰到好处？丁总说，恰到好处是『正好』，『正好』是假的，不是究竟本来，是假的就立不住。我不懂，就问他是什么究竟本来？他说『一切』。我还是不懂，就说你就告诉我应该怎么做吧。丁总说了一句话：随缘惜缘不攀缘。这句话让我印象很深，也听懂了，我一直记着。」\n- 芮小丹说：「您不用做工作，我今天晚上就回去，我不想在这儿影响您的心情。我也想挣大钱过好日子，但是如果我是为了挣大钱过好日子去当编剧，我既挣不来大钱也写不出好剧本。您熬了几十年没熬成大师，就在于此。如果我的能力只能让我穷困潦倒，那穷困潦倒就是我的价值。」\n- 詹妮也笑了笑，弹弹烟灰说：「元英这个人最怕给别人添麻烦，他让我对中国的一句话很有印象，『君子之交淡如水』。」\n- 肖亚文微微一笑，说：「问题是，假客套不能当饭吃。格律诗扶起王庙村之时，就是格律诗受制于王庙村之日，而格律诗的价值也就在于此。万一将来公司不行了，我就把音响店改成餐馆，有你这么多年的经验垫底，我也饿不死了。」\n- 法律治标，文化治本。法律对于滋生法律的文化土壤无能为力，对于越过法律潜入文化土壤地带从事更大损害、更大掠夺的行为无能为力，法律是维持社会秩序的最后一道防线，是最软弱、最无奈的强大。法律的神圣是缘于道德文明的崩溃，关注弱势，激励强者构筑更高的道德平台和获得更大的综合效应，需要相应的社会文化。\n- 构筑强者的道德平台是一个复杂的社会工程，道德平台太低，势必挤压弱势群体的生存空间，而过高的道德平台又必然存在两个问题：首先是很少有人能攀援上去，没有可操作性。其次是过多的帮助不利于社会进步，弱势群体得到的输血越多，则自身的造血功能就越差，就越接近死亡。道德平台理想的高度，是优胜劣汰的法则与人人平等的道德两者之间的平衡。主流的文化，是优胜劣汰的文化，是不给落后观念生存空间的文化。然而，如果不关爱弱势，道德还有价值吗？等级是客观存在，如果我们连等级的存在都不敢承认，社会又怎么可能去建立一种更高级的道德文化？如果没有个体的文化价值的量变，又怎么可能会产生民族的文化价值的质变？,2023-02-01T20:47:18.817Z,reading,com.baizeyu.published.model.Published
63dad102f98c114fc8128ab4,Atomic Habits,"# About\nA book by Clear James, one of the best-selling books.\n# Notes\n- changes that seem small and unimportant at first will compound into remarkable results if you’re willing to stick with them for years .\n- The backbone of this book is my four - step model of habits — cue , craving , response , and reward — and the four laws of behavior change that evolve out of these steps .\n- “ The whole principle came from the idea that if you broke down everything you could think of that goes into riding a bike , and then improve it by 1 percent , you will get a significant increase when you put them all together . ”\n- Habits are the compound interest of self - improvement . The same way that money multiplies through compound interest , the effects of your habits multiply as you repeat them . They seem to make little difference on any given day and yet the impact they deliver over the months and years can be enormous . It is only when looking back two , five , or perhaps ten years later that the value of good habits and the cost of bad ones becomes strikingly apparent .\n- Your outcomes are a lagging measure of your habits . Your net worth is a lagging measure of your financial habits . Your weight is a lagging measure of your eating habits . Your knowledge is a lagging measure of your learning habits . Your clutter is a lagging measure of your cleaning habits . You get what you repeat .\n- Productivity compounds . Accomplishing one extra task is a small feat on any given day , but it counts for a lot over an entire career . The effect of automating an old task or mastering a new skill can be even greater . The more tasks you can handle without thinking , the more your brain is free to focus on other areas . Knowledge compounds . Learning one new idea won’t make you a genius , but a commitment to lifelong learning can be transformative . Furthermore , each book you read not only teaches you something new but also opens up different ways of thinking about old ideas . As Warren Buffett says , “ That’s how knowledge works . It builds up , like compound interest . ” Relationships compound . People reflect your behavior back to you . The more you help others , the more others want to help you . Being a little bit nicer in each interaction can result in a network of broad and strong connections over time .\n- THE PLATEAU OF LATENT POTENTIAL FIGURE 2 : We often expect progress to be linear . At the very least , we hope it will come quickly . In reality , the results of our efforts are often delayed . It is not until months or years later that we realize the true value of the previous work we have done . This can result in a “ valley of disappointment ” where people feel discouraged after putting in weeks or months of hard work without experiencing any results . However , this work was not wasted . It was simply being stored . It is not until much later that the full value of previous efforts is revealed .\n- Goals are about the results you want to achieve . Systems are about the processes that lead to those results .\n- If you want better results , then forget about setting goals . Focus on your system instead .\n- Goals are good for setting a direction , but systems are best for making progress .\n- Achieving a goal only changes your life for the moment . That’s the counterintuitive thing about improvement . We think we need to change our results , but the results are not the problem . What we really need to change are the systems that cause those results . When you solve problems at the results level , you only solve them temporarily . In order to improve for good , you need to solve problems at the systems level . Fix the inputs and the outputs will fix themselves .\n- Finally , a goal - oriented mind - set can create a “ yo - yo ” effect . Many runners work hard for months , but as soon as they cross the finish line , they stop training . The race is no longer there to motivate them . When all of your hard work is focused on a particular goal , what is left to push you forward after you achieve it ? This is why many people find themselves reverting to their old habits after accomplishing a goal . The purpose of setting goals is to win the game . The purpose of building systems is to continue playing the game . True long - term thinking is goal - less thinking . It’s not about any single accomplishment . It is about the cycle of endless refinement and continuous improvement . Ultimately , it is your commitment to the process that will determine your progress .\n- Habits are the compound interest of self - improvement . Getting 1 percent better every day counts for a lot in the long - run . Habits are a double - edged sword . They can work for you or against you , which is why understanding the details is essential . Small changes often appear to make no difference until you cross a critical threshold . The most powerful outcomes of any compounding process are delayed . You need to be patient . An atomic habit is a little habit that is part of a larger system . Just as atoms are the building blocks of molecules , atomic habits are the building blocks of remarkable results . If you want better results , then forget about setting goals . Focus on your system instead . You do not rise to the level of your goals . You fall to the level of your systems .\n- In this way , the process of building habits is actually the process of becoming yourself .\n",2023-02-01T20:52:12.749Z,reading,com.baizeyu.published.model.Published
63e2df9306c5e77178f3912f,Add Signed SSL to your Java REST APIs using Keystore and Openssl,"# Intro\nWhen we are building an application with front-end and back-end separation, our front-end is on one server, and the back-end is on another server. When the front-end has https but the back-end does not support https, the front-end will not be able to make API calls due to security reasons. How to solve this? The article will introduce you a simple way to secure your Java RESTful APIs.\n# Prerequisite\n- [openssl](https://macappstore.org/openssl/) (this link provides you on how to install this command line tool on macOS, if you are using Windows, try to search for that 😶‍🌫️)\n- keytool: Keytool is included as part of the Java runtime. So by installing Java, you'll also have keytool in your system. \n- CA signed certificate including two files: ""certificate.crt"" and ""private.key"".\n# Steps\n## Generate a '.jks' file which uses PKCS12 encryption method\nFirst, we gonna export a '.p12' file using ""certificate.crt"" and ""private.key"", drag the two files into a folder, open the folder with your terminal, and type:  \n```\nopenssl pkcs12 -export -in certificate.crt -inkey private.key \\n               -out cert.p12\n```\nNow, if you use the command `ls`, you will see a file named ""cert.p12"" has been generated. Next, we are going to create a Java Keystore with it:\n```\nkeytool -importkeystore \\n	-destkeystore my_first_keystore.jks -deststoretype pkcs12 -destkeypass [your password] -deststorepass [your password]\\n	-srckeystore cert.p12 -srcstoretype pkcs12 -srcstorepass [your password]\n```\nOK, if the second step succeeds, you could see the keystore file named `my_first_keystore.jks` in this folder!\n## Apply the keystore on your SpringBoot REST API application\n- Drag your `my_first_keystore.jks` into `/src/main/resources` folder\n- Create an `application.properties` config file in the same folder, and add the following configuration in it:\n```\n#SSL for SpringBoot Application\nserver.ssl.key-store=classpath:my_first_keystore.jks\nserver.ssl.key-store-type=pkcs12\nserver.ssl.key-store-password=[your password]\nserver.ssl.key-password=[your password]\n```\n**That's it! We are almost set!**\n## Test it\nJust run the SpringBoot Application, then go to https://localhost:{port}/{your_api_path}, you might see some warning from browser (because the certificate is signed for your domain rather than 'localhost', when you deploy your backend applications on the correct domain, this warning will be disappeared), just ignore it and your will see your API response!",2023-02-07T23:32:31.712Z,tech,com.baizeyu.published.model.Published
63e6360106c5e77178f39142,Arrays and Matrices,"# [Q283. Move Zeroes](https://leetcode.com/problems/move-zeroes/description/)\n```\nclass Solution {\n    public void moveZeroes(int[] nums) {\n\n        // An index for non zero numbers\n        int none_zero_index = 0;\n\n        // If we find none-zero values, just put it at index 'none_zero_index'\n        for (int i = 0; i < nums.length; i++) {\n            if (nums[i] != 0) {\n                nums[none_zero_index] = nums[i];\n                none_zero_index ++;\n            }\n        }\n        \n        // if none_zero_index is not the same as nums.length, replace rest positions to 0\n        if (none_zero_index != nums.length) {\n            for (int i = none_zero_index; i < nums.length; i++) {\n                nums[i] = 0;\n            }\n        }\n    }\n}\n```\n\n# [Q566. Reshape the Matrix](https://leetcode.com/problems/reshape-the-matrix/description/)\n```\nclass Solution {\n    public int[][] matrixReshape(int[][] mat, int r, int c) {\n\n        // get original number of rows and columns\n        int row_original = mat.length;\n        int column_original = mat[0].length;\n        int size_original = row_original * column_original;\n\n        // check if the given size is possible\n        if (size_original != (r*c)) {\n            return mat;\n        }\n        \n        // else\n        int[][] result = new int[r][c];\n\n        // loop input matrix to get all numbers\n        int[] all_nums = new int[size_original];\n        int index = 0;\n        for (int i = 0; i < row_original; i++) {\n            for (int j = 0; j < column_original; j++) {\n                int num = mat[i][j];\n                all_nums[index] = num;\n                index ++;\n            }\n        }\n\n        // fill result matrix\n        index = 0;\n        for (int i = 0; i < r; i++) {\n            for (int j = 0; j < c; j++) {\n                result[i][j] = all_nums[index];\n                index ++; \n            }\n        }\n\n        return result;\n        \n    }\n}\n```\n# [Q485. Max Consecutive Ones](https://leetcode.com/problems/max-consecutive-ones/description/)\n```\nclass Solution {\n    public int findMaxConsecutiveOnes(int[] nums) {\n        \n        // count\n        int count = 0;\n        List<Integer> max_counts = new ArrayList<>();\n\n        // loop over the array\n        for (int i = 0; i < nums.length; i++) {\n            if (i == nums.length-1 && nums[i] == 1) {\n                count++;\n                max_counts.add(count);\n                break;\n            }\n            if (nums[i] == 1 && nums[i+1] == 1) {\n                count++;\n            } else if (nums[i] == 1 && nums[i+1] != 1) {\n                count++;\n            } else {\n                max_counts.add(count);\n                count = 0;\n                continue;\n            }\n        }\n\n        // get max in the list\n        System.out.println(max_counts);\n        int max = Collections.max(max_counts);\n\n        return max;\n    }\n}\n```\n# [240. Search a 2D Matrix II](https://leetcode.com/problems/search-a-2d-matrix-ii/description/)\n```\nclass Solution {\n    public boolean searchMatrix(int[][] matrix, int target) {\n\n        // result\n        boolean result = false;\n        // check row by row, if the target is between first and last number\n        for (int i = 0; i < matrix.length; i++) {\n\n            // get row first and last\n            int[] row = matrix[i];\n            int first = row[0]; \n            int last = row[row.length-1];\n            if (target >= first && target <=last) {\n                for (int j = 0; j < row.length; j++) {\n                    if (target == row[j]) {\n                        result = true;\n                    }\n                }\n            }\n        }\n\n        return result; \n    }\n}\n```\n# [378. Kth Smallest Element in a Sorted Matrix](https://leetcode.com/problems/kth-smallest-element-in-a-sorted-matrix/description/)\n```\nclass Solution {\n    public int kthSmallest(int[][] matrix, int k) {\n\n        List<Integer> expanded = new ArrayList<>();\n        for (int i = 0; i < matrix.length; i++) {\n            for (int j = 0; j < matrix[i].length; j++) {\n                expanded.add(matrix[i][j]);\n            }\n        }\n\n        // sort the list\n        Collections.sort(expanded);\n\n        // return\n        return expanded.get(k-1);\n\n    }\n}\n```\n# [645. Set Mismatch](https://leetcode.com/problems/set-mismatch/description/)\n```\nclass Solution {\n    public int[] findErrorNums(int[] nums) {\n\n        // use a HashSet to find duplicates\n        Set<Integer> nums_set = new HashSet<>();\n\n        // result\n        int dup = 0;\n        int miss = 0;\n\n        // find duplicate\n        for (int i = 0; i < nums.length; i++) {\n            if(nums_set.contains(nums[i])){\n                dup = nums[i];\n            }\n            nums_set.add(nums[i]);\n        }\n\n        // find miss\n        for (int i = 1; i < nums.length+1; i++) {\n            if (!nums_set.contains(i)) {\n                miss = i;\n            }\n        }\n\n        // return\n        return new int[]{dup, miss};\n    }\n}\n```\n# [287. Find the Duplicate Number](https://leetcode.com/problems/find-the-duplicate-number/description/)\n```\nclass Solution {\n    public int findDuplicate(int[] nums) {\n\n        // use a HashSet\n        Set<Integer> nums_set = new HashSet<>();\n        for (int i = 0; i < nums.length; i++) {\n            if (nums_set.contains(nums[i])) {\n                return nums[i];\n            }\n            nums_set.add(nums[i]);\n        }\n\n        return -1;\n        \n    }\n}\n```",2023-02-10T12:18:06.535Z,hide,com.baizeyu.published.model.Published
63fd1db306c5e77178f39143,《查拉图斯特拉如是说》,# 写在开头\n从一月上旬开始，我抓起了尼采的神作《查拉图斯特拉如是说》，今天是2023年2月27日，在花了一个月的时间读完本书之后，我终于又在繁忙的生活中抽出一点时间来把我做的所有笔记整理成以下的部分了。\n# 笔记部分\n- 人的伟大之处在于，他是一座桥梁而非目的；人的可爱之处在于，他是一个过渡，也是一个沉沦 。\n- 我爱那些不懂得生活的人，假如他们不是沉沦者，那他们就是超越者。 我爱那些伟大的轻蔑者，因为他们是伟大的崇敬者，是指向彼岸的渴望之箭。 我爱这样的人：他们不是到星星背后去寻找沉沦和牺牲的理由，而是为大地而牺牲，使大地有一天成为超人的大地。我爱那先有金玉良言，后有行动，并且坚持做得比许诺更多的人：因为他想要的是他自己的沉沦。我爱那为未来者辩解，并拯救过去者的人：因为他愿意作为现在者而毁灭。我爱那灵魂即使在受伤害时仍然深沉，而且在一个很平凡的经历中就能毁灭的人：所以他愿意越过桥梁。我爱那灵魂过于丰富，以致忘却自我，而且集万物于一身的人：所以万物变成了他的沉沦。\n- 小孩是无辜与遗忘，一个新的开端，一场游戏，一个自转的轮子，一个最初的运动，一个神圣的肯定。\n- 人类是某种必然要被超越的东西：所以你应该爱你的美德，——因为你将因这些美德而死去。\n- 爱中总是有某种疯狂。但是疯狂中始终还有某些理性。\n- 你对你的朋友来说，是纯洁的空气、孤独、面包和良药吗？有些人不能解除自己的链条，可对朋友来说，却是一位救世主。\n- 我的兄弟，带着你的爱，带着你的创造，进入你的孤独吧；正义远远地落在你的后面。 我的兄弟，带着我的眼泪进入你的孤独吧。我爱想要超越自己而进行创造，并因此而毁灭的人\n- 你们尚未寻找自己：这时，你们却找到了我。所有的信徒都是如此；所以所有的信仰才如此微不足道。现在我命令你们丢失我，找到你们自己；只有当你们全部否定我的时候，我才会回到你们身边。\n- 然而我过去和现在都和他们在一起痛苦：对于我来说，他们是囚犯和复制品。他们称之为拯救者的人，给他们戴上了镣铐：—— 囚禁在虚假价值和谵语中！啊，但愿有人能把他们从他们的拯救者手中拯救出来！ 当大海使他们晕头转向时，他们还以为登上了一个岛屿；可是，瞧，这是一只熟睡的巨大怪物！ 虚假价值和谵语：这对于凡人来说，是最糟糕的巨大怪物，——长期以来，命运在它们身上休眠、等待。 可是，它终于来临，醒过来，狼吞虎咽，吞噬掉在它身上为自己建起小屋的一切。 哦，你们给我看一下这些教士们为自己建的小屋吧！他们将自己芳香的洞穴称为教堂。\n- 谁为自己创造了这洞穴和忏悔台阶？不正是那些想要躲藏起来，羞于见到纯净天空的人吗？ 只有当纯净的天空重新透过破碎的覆盖物投下它的目光，望着破墙上的草和红罂粟的时候，——我才愿意把我的心重新转向这上帝的所在。 他们称反对他们，给他们以痛苦的东西为上帝：真的，在他们的朝拜中颇有英雄气概！ 除了把人钉上十字架，他们不知道其他爱上帝的方法！ 他们打算做行尸走肉，用黑布裹起自己的尸体；从他们的言谈中我嗅到了停尸房里让人恶心的香料味道。 谁在他们附近生活，谁就是住在黑水潭的附近，水中的蟾蜍以甜美的深沉之音歌唱。 他们本应该给我唱更加动听的歌，我才会学着去相信他们的救世主：在我看来，他的门徒们本应该表现出更多得到了拯救的样子！ 我想要看见他们赤身裸体：因为只有美才应该宣讲忏悔之说。可是这种裹起来的哀伤说服得了谁！ 真的，你们的救世主们自己也不是来自自由，不是来自自由的第七重天！真的，他们自己从来没有在知识的地毯上走过！ 这些救世主的精神由空白构成；可是在每一个空白中，他们置入了他们的幻觉，他们的替代品，他们称之为上帝。 他们的精神溺死在他们的同情里，当他们膨胀起来，漫溢着同情的时候，上面总是游动着大愚蠢。 他们喊叫着拼命驱赶他们的羊群走过他们的小木桥：就好像通向未来的就只有一座小木桥！真的，这些牧羊人仍然属于羊群呀！ 这些牧羊人有狭隘的思想、宏大的灵魂：可是，我的兄弟们，甚至最宏大的灵魂至今也是怎样的小国寡民啊！ 他们在他们走的道路上写下了血字，他们的愚蠢教导说，人们用血来证明真理。 可是，血是真理的最糟之见证；血将最纯洁的信条毒化成心的幻觉和仇恨。 如果一个人为了他的信条赴汤蹈火，——这证明了什么！更真实的是从自己的火焰中产生出自己的信条！ 抑郁的心和僵冷的头脑：两者碰到一起，就产生泡腾效应，产生出“救世主”。 真的，存在着比人们称为救世主的、这些迷人的泡腾效应产生出的人更伟大、出身更高贵的人！ 我的兄弟们，如果你们想要找到通向自由的道路，你们就必然为比所有救世主都更加伟大的人所拯救！ 从来还没有过一位超人。我看见赤裸裸的两个人，最伟大的人和最卑微的人：—— 他们还是太相像了。真的，就是最伟大的人，我也发现他——太人性了！ 查拉图斯特拉如是说。\n- 我无疑是一座森林，一片幽暗树木之黑夜：可是谁不怕我的黑暗，谁就也会在我的柏树下找到开满玫瑰的斜坡。\n- 甚至在它命令自己的时候，它也不得不为自己的命令受到惩罚。它不得不成为它自己法则的法官、复仇者和牺牲品。 这究竟是怎么发生的！我如是问自己。是什么东西说服了生物既服从又命令，在命令中贯彻服从？ 你们现在听我说，你们这些最有智慧的人！认真地检验一下，我是否钻进了生命本身的心脏，直达它的心脏之根本！ 在我发现有生物的地方，我就发现强力意志；我还在仆人的意志中发现了当主人的意志。 弱者应该为强者服务，弱者的意志劝说他，弱者的意志是要当更弱者的主人：他单单不想放弃这种乐趣。 正如卑微者屈从于伟大者，从而能从最卑微者那里获取乐趣和力量：最伟大者也为了强力的缘故而屈从，并贡献——生命。 这是最伟大者的屈从：它是冒险、危难和孤注一掷。\n- 我当着火狗的面如是说：这时候它闷闷不乐地打断我，问道：“教会？那究竟是什么？” 教会？我回答说，这是一种国家，而且是最骗人的那种。不过不要说话，你这伪善之狗！你一定最了解你的同类！\n- 和人在一起生活很难，因为沉默如此之难。对于一个好讲话的人来说尤其如此。\n- 高处不可怕，斜坡才可畏！ 在斜坡上，目光向下坠落，手向上攀缘。这时，心在它的双重意志面前眩晕。\n- 你曾要抚摩任何怪物。只要它有一口温暖的气息，爪子上的一簇纤毛——：你马上就准备爱它、诱惑它。 爱 ，对一切活物的爱，是最孤独者的危险！我在爱中的愚蠢和谦虚真的很可笑！”—— 查拉图斯特拉如是说，同时再一次笑起来：可是，这时候他想起他那些被抛弃的朋友们——，就好像对他们的想念是糟蹋了他们，他为他的想法感到很生气。接下来，这个发笑的人哭了起来：——查拉图斯特拉因恼怒和渴望而痛哭着。\n- 查拉图斯特拉如是说。他整夜等待他的不幸：可是他徒然等待。夜晚始终晴朗而宁静，幸福本身离他越来越近。可是，临近早晨的时候，查拉图斯特拉心中暗笑，讽刺地说道：“幸福追逐我。这是由于我不追女人。而幸福就是一个女人。”\n- 然而我们的同类却愿意如是；而我爱那些不想要保存自己的人。我以我全部的爱，爱那些下沉者：因为他们正在过渡。\n- 实事求是——很少有人能做到这一点！能做到这一点的人却不愿意做！而好人是最不可能做到这一点的。\n- “为何要生活？一切皆空！生活——就是白费力气；生活——就是烧毁自己，却得不到温暖。”\n- “在洁净者凡物都洁净”[15]——大众如是说。可是我对你们说：对于猪来说，一切皆猪！\n- 世界上有许多的污秽：这是多么真实！可是世界本身并非因此就是肮脏的怪兽！\n- “让世界是什么样就什么样吧！不要竖起一根手指来反对它！”\n- “而你自己的理性——你自己应该掐住其喉咙；因为这是一种现世的理性，——你自己因此学习了抛弃世界。”\n- “学习很多的人忘记了所有强烈的渴望”——现今人们在所有幽暗的小巷里互相窃窃私语。\n- 万物皆去，万物皆回，存在之轮永恒转动。万物皆死，万物复苏，存在之年永恒地奔跑。 万物皆破，万物皆合；同样的存在之屋恒久地建造自己。万物皆分离，万物皆重逢，存在之环恒久地忠实于自己。 存在开始于每一瞬间；围绕着每一个‘这里’旋转着‘那里’之球。中心无处不在。永恒之径曲曲弯弯。”\n- 我们互相凝视，又朝绿色草地望过去，清凉的夜晚刚降临到这草地上，我们相对而泣。——当时，生命在我看来，比我的全部智慧曾经有过的面貌都更加可爱。\n- 我等候更高之人、更强之人、更有必胜信念之人、更满怀信心之人，那些身心健壮之人：笑面之狮必定会来！\n- 好吧！好吧！你们这些更高之人！现在，人类未来之山才开始有临产之阵痛。上帝死了：现在我们愿意——超人活着。\n- 我的意识、我的渴望趋向于少量、长远：你们的许多短暂的小不幸与我有何相干！ 在我看来，你们受苦还不够！因为你们受自己之苦，你们还没有受人类之苦。如果你们有其他说法，便是撒谎！你们大家都没有受我所受过的苦\n- 你们问一下女人吧：她们不是因为生育给人快乐才生育的。母鸡和诗人都痛苦得咯咯乱叫。\n- 至今为止，这个世界上最大的罪恶是哪一种呢？不就是那人说的那句话吗？那人说：“在这里喜笑的人有祸了！” 他自己也认为在世上没有理由笑吗？那只是他探索得很糟糕。一个孩子在此也找得到理由。\n- 那人——爱得不够：要不然，他本来也会爱我们这些笑颜常开者的呀！可是他恨我们，讽刺我们，预示我们会哀号，会战战兢兢地牙齿打颤。 倘若你不爱，那你就得马上诅咒吗？那——在我看来是一种糟糕的风气。可是他就是这么做的，这个绝对者。他来自群氓。 他自己只是爱得不够：要不然他不会因为人们不爱他而生气。所有的大爱都不要求爱：——它要求得更多。 避开所有这些绝对者吧！这是一种可怜的病态物种，一种群氓之类：他们恶劣地看待此生，用邪恶的眼光观看这个世界。 避开所有这些绝对者吧！他们步履沉重，内心淫荡：——他们不懂得跳舞。对于这些人来说，大地如何会变得轻松呢！\n- 在渐渐昏暗的天空中， 当露珠将抚慰 洒向大地， 无形亦无声：—— 因为安抚的露珠有如 所有抚慰者步履轻盈——： 回想吧，回想，炽热之心， 你曾经如何渴望， 天堂的眼泪和露珠 在煎熬中苦苦渴望， 因为在枯黄的草径上 夕阳之光恶毒地奔驰 穿越我周围的黑色树林， 日之耀眼灼光幸灾乐祸。\n- 因为恐惧——是我们的例外。可是，勇气，冒险，对不确定性、对未尝试事物的兴趣，——在我看来，勇气便是人类的整个由来。 人类嫉妒最有野性、最勇猛的动物，并从它们那里夺走了它们所有的美德：于是才变成了——人类。 这种勇气最终变得细腻，变成智性的、宗教性的了，这种有着老鹰的翅膀和蛇的智慧的人类勇气：在我看来，它今天叫做——” “查拉图斯特拉！”所有坐在一起的人都异口同声地喊道，同时大笑起来；可是从他们那里就像升腾起一朵沉甸甸的云。就连巫师也笑了，他机智地说道：“行了！他走了，我的恶魔！\n- 也许我可以不相信上帝：然而肯定的是，在我看来这种有形的上帝最值得信仰。\n- 按照最虔诚者的见证，上帝应该是永恒的：谁有这么多时间，尽管慢慢来。尽可能慢，尽可能愚蠢：如此这般，一个这样的人才能走得很远。\n- ‘人们不是通过怒火，而是通过笑来杀人’。\n- 最纯洁者应该主宰大地，最鲜为人知者，最坚强者，比任何白昼都更明亮、更深邃的午夜之魂。\n- 她反刍她的痛苦，在梦中，这古老而深沉的午夜，更多的还是她的快乐。因为快乐，尽管痛苦很深：快乐比哀痛更深 。\n- 犯我最后的罪过？查拉图斯特拉喊道，愤怒地嘲笑他自己的话：留给我犯的最后罪过是什么？” ——查拉图斯特拉再次陷入沉思，重新坐到那大石头上去思考问题。突然他跳起来，—— “同情！对更高之人的同情！”他喊叫起来，他的脸色变得铁青。“行了！那同情——它的时代过去了！ 我的痛苦、我的同情——那有何相干！难道我追求幸福吗？我追求我的工作 ！ 行了！狮子来了，我的孩子们很亲近，查拉图斯特拉成熟了，我的时刻到了：—— 这是我的早晨，我的白昼开始了：现在来吧，来吧，你伟大的晌午！”———— 查拉图斯特拉如是说，离开了他的洞穴，容光焕发，浑身是劲，有如一轮刚从黑暗群山中喷薄而出的朝阳。 查拉图斯特拉如是说之终结。\n- 参见《圣经·路加福音》第10章第42节：“你为许多的事，思虑烦扰，但是不可少的只有一件。”\n# 结语\n终于不用把“未完待续……”这几个字放在最后了，这本书实际让我花费的时间大概是一个月，读完一遍之后仍然有很多东西不能完全理解，但是始终还是要有点自己的见地吧！我如是对自己说。\n## 上帝是谁？\n这是个好问题，在这个传统的天主教国家，我每天都会看到好几个教堂，教堂外面会挂着一些上帝的标语，试图把一切的幸福都解释为上帝的杰作，可是，谁是上帝啊？为什么在耶路撒冷这个神圣的地方有残酷的战争？为什么在爱尔兰这种传统天主教的国家，会有很多骇人听闻令人无法接受的丑陋事件发生啊？（比如blackrock college的几百人性丑闻事件），为什么我从信仰基督教派的人身上看到的是痛苦，是处处被限制，是没有自由呢？——在我眼里，他们被拉进了一扇窄门，一根独木桥，他们像那个上帝一样被绑在十字架上动弹不了了，他们好可怜啊，他们中的有些人还试图拉其他人入教，声称这是为了别人好？荒谬可笑！我同情那些信仰上帝的人，他们被限制了，他们得不到真正的幸福了！上帝可能也不希望他们跟着上帝走吧，只有愚蠢的他们才会愚蠢地相信上帝。\n## 我赞成的超人哲学\n虽然没有完全读懂这本书，可能一辈子都没法完全读懂，但至少有一点我是十分赞成的，我想将它总结成简单的，我自己的语言——当你不信仰上帝时，你就是上帝，你不用去寻找所谓的上帝；而当你总想着听从上帝指引时，那你永远也达不到上帝的期待。\n\n人类，只有在不断突破，超越自我的时候，上帝才会微笑。\n## 发问\n上帝存在吗？——存在，也不存在。,2023-02-27T21:15:44.384Z,reading,com.baizeyu.published.model.Published
63fd24cb06c5e77178f39147,🌟 Collection: Data Structures and Algorithms,"# About\nThis is a collection of my learning journal of the subject Data Structures & Algorithms in Java, the collection will cover most common data structures and algorithms thougts, and provide solutions for those questions.\n# Data Structures\n- [Arrays and Matrices](https://baizeyu.info/blog/view/Arrays%20and%20Matrices)\n- [Stack, Queue, Heap]()\n- [Linked List]()\n- [Tree]()\n- [String]()\n- [Graph](url)\n- [Bit Operation](url)\n- [Hash Table](url)\n# Algorithms\n- [Two Pointers](url)\n- [Sorting](url)\n- [Greedy Algorithm](url)\n- [Binary Search](url)\n- [Partition](url)\n- [Search](url)\n- [Dynamic Programming](url)\n- [Math](url)",2023-02-27T21:46:50.737Z,tech,com.baizeyu.published.model.Published
6407060c06c5e77178f3914f,从0到1：开启商业与未来的秘密,"# About\n来自Paypal创始人的商业思考，本书核心如标题所示，书本身也不厚，一周左右能读完。\n# Notes\n- 谷歌那样的垄断企业则与众不同。因为不用担心和别的企业竞争，它有更大的自主权去关心自己的员工、产品和在更广阔世界里的影响力。谷歌的座右铭——“不作恶”，在某种程度上是品牌策略，同时也显示了成功企业的特性——即使严守道德，也不会影响公司的发展。在商界，钱就是一切，或至少是非常重要。垄断者除了想着赚钱外还有余力想其他事情，而非垄断者就不行。在完全竞争中，企业着眼于短期利益，不可能对未来进行长期规划。要想将企业从每日的生存竞赛中解脱出来，唯一的方法就是：获取垄断利润。\n- 但世界是动态的，我们可以创造更好的新事物。富有创意的垄断者创造出崭新的事物，给消费者更多的选择。有创意的垄断企业不仅对外界社会没有坏影响，相反，它们是使社会更美好的推动力。\n- 新兴垄断企业的活力解释了为什么老牌垄断企业不会抵制创新。有苹果公司的iOS系统打头阵，移动计算的崛起迅速把微软从长达数十年的操作系统的霸主地位推了下去。在那之前，微软的软件垄断取代了美国IBM公司20世纪60~70年代的硬件垄断。几乎整个20世纪，电话服务业被美国电话电报公司垄断，而现在每个人都能从随便一个供应商那里买来一部手机。如果垄断企业的趋势是阻碍进步，那我们应该抵制这种危险企业。但是进步的历史事实上是垄断企业不断更新换代的过程。 垄断企业推动社会进步，因为数年甚至数十年的垄断利润是有力的创新动机。之后垄断企业会不断创新，因为利润给了它们规划长远未来的资本，它们有能力投资雄心勃勃的研究项目，这些是困在竞争之中的企业想都不敢想的。\n- 托尔斯泰在《安娜·卡列尼娜》中以下面这段文字作为开头：“幸福的家庭总是相似的，不幸的家庭各有各的不幸。”而在商业中，情形恰恰相反。企业成功的原因各有不同：每个垄断企业都是靠解决一个独一无二的问题获得垄断地位；而企业失败的原因却相同：它们都无法逃脱竞争。\n- 这是一个简单的事实，但是我们都学会了对它视而不见。我们的教育体系既促使我们去竞争，也反映了我们对竞争的痴迷。成绩本身就是对每个学生竞争力的精准测度，分数最高的学生既得到地位又得到证书。我们用同样的方法教授年轻人同样的内容，而不顾个人的天赋和爱好。无法安静地一直坐在书桌前学习的学生，在环境的影响下感觉自己好像低人一等；而在考试和作业上出类拔萃的孩子最终都是在这个怪异的、与现实世界没有交集的学术界里找到个人定位。 越到高等教育阶段，这种现象越严重。优秀的学生自信地“往高处走”，直到竞争激烈到把他们的梦想吞噬殆尽。高等教育是一场困局，在高中时对未来有宏伟规划的学生，最后却陷入了与智力程度不相上下的同侪在传统职场上的竞争，如企业管理咨询和投资银行业务。为了获得把自己转变成一个墨守成规之人的特权，学生（或者家长）要支付数十万美元，并且学费仍在飙升，涨幅持续超过通货膨胀。为什么我们要对自己做这种事呢？ 我多么希望自己年轻的时候就这么思考过。我的道路循规蹈矩，一个朋友曾在我八年级的纪念册上这样预测：四年后我会成为斯坦福大学的二年级学生。按部就班地上完了大学，我考入了斯坦福法学院，在这里我更加努力，追求更大的成功。\n- 每个法学院学生都目标明确——得到最高分。因为每年，只有十几个学生从数以万计的学生中脱颖而出，成为最高法院的书记员。在联邦上诉法院工作了一年后，我终于得到了书记员的面试资格，面试官是肯尼迪和斯卡利亚法官。面试进行得很顺利，胜利在望。我想，要是我能当上书记员该多好，我这一辈子就不用愁了。但结果却是我失败了。那时候，我备受打击，意志消沉。\n- 为什么人们非要一较高下呢？马克思和莎士比亚给出的回答有助于我们理解几乎每种冲突的原因。按照马克思所说，人们因为差异才会斗争。无产阶级和资产阶级因为观点与目标截然不同（来自于不同的物质环境）而斗争。差异越大，冲突就越大。 对莎士比亚来说则恰恰相反，所有的斗争者都或多或少有些相似。由于没有什么好争的，所以他们为什么而争斗不得而知。《罗密欧与朱丽叶》开篇就说：“两家人，同样尊贵体面。”这两家人差不多，但是他们互相敌对。随着矛盾升级，他们甚至变得更相似。直到最后，他们自己也忘记了最初矛盾产生的原因。\n- 至少在商界，莎士比亚的理论更为高明。在公司内部，人们为了升职，时刻关注对手动态。而公司为获得市场也留意着竞争者。在所有人类冲突的戏码中，人们往往忽视了真正重要的事情，只把精力放在竞争对手身上。\n- 有时你不得不投入战斗。需要的时候，你不仅要战斗，还必须得赢，没有中间选择：要么和风细雨润物无声，要么暴风骤雨速战速决。 这个建议也许很难做到，因为自尊和荣誉会拦着你。因此哈姆雷特说： 他仗着勃勃之勇气与天命之雄心 , 罔顾不测之凶险 , 拼着血肉之躯奋然和命运、死神与危机挑战。 这全为了小小一块弹丸之地 ! 真正的伟大，并不只是肯为轰轰烈烈之大事奋斗 , 而是肯为区区草芥力争一份荣耀。\n- 对于哈姆雷特，伟大是肯为了微不足道的理由抗争：每个人都会为重要的事进行斗争；而真正的英雄把他们个人的荣誉看得更重要，即使事情不重要，他们也会一争到底。这个扭曲的逻辑是人的天性，但是用在商业上却很致命。如果你能看出竞争不能带来价值的提升，而是充满破坏力，那你就比大多数人要理智。下一章我们就来讨论一下如何以清醒的头脑去打造垄断的事业。\n- 这种说法顿时引来嘘声一片。《大西洋月刊》上，记者亚历克西斯·马德加格尔说他的第一反应是反驳：“所有白人巨富都会说， ‘成功绝非偶然。’”的确，已经成功的人涉足新领域要容易一些，不管是因为他们的网络效应、财富，还是丰富的经验。但也许，是我们自己太快地否定了那种按计划一步一步获得成功的可能性。\n- 从文艺复兴、启蒙运动到20世纪中期，运气是可以被掌握支配的；大家都认为一个人应该做力所能及的事，而不是纠结于做不到的事。拉尔夫·瓦尔多·爱默生捕捉到了这种社会思潮，他写道：“浅薄的人才会相信运气和境遇……强者只相信因果。”1912年，罗尔德·阿蒙森成为第一个探索南极的人，他说：“胜利只等待那些有准备的人，也许这就是人们说的运气吧！”没有人会假装坏运气不存在，但是前辈们相信努力会换来好运气。\n- 而一个明确的愿景可以坚定人的信念。与其努力成为一个各方面都一知半解的庸才，还美其名曰“全能人才”，一个目标明确的人往往会选择一件最该做的事，并专心去做好这一件事。与其不知疲倦地工作，最终却只把自己变得毫无特色，不如努力培养实力，以求独霸一方。现今的年轻人并没有做到这些，因为他们周围的每个人都已经对明确的世界丧失信心。没有人会因为仅仅一方面特别杰出而进入斯坦福大学，除非他擅长的那一方面碰巧和传接球有关。\n- 有些人认为未来比现在更好，有些人认为未来比现在更糟。乐观的人迎接未来，悲观的人害怕未来。这些可能性组合成四种观点。\n- 一个对未来明确的悲观主义者相信未来是可知的，但却是暗淡的，所以他必须提前做好准备。也许当今的中国是最典型的对未来明确的悲观主义者。美国人看见中国的经济迅猛增长（自从2000年以来，每年都有10% 的增长），便认为中国是一个自信能够掌握自己未来的国家。但这是因为美国人仍然很乐观，并以同样的乐观看待中国。从中国的角度来看，经济增长得还不够快。其他国家都害怕中国将要统治整个世界，而中国是唯一一个认为自己不会统治世界的国家。\n- 中国之所以增长得如此迅速是因为它的起步基础很低。对中国来说，最容易的发展方式就是不断学习已经在西方行之有效的模式。中国现在就在做这样的事情：燃烧更多的煤，建更多的工厂和摩天大楼。因为人口数量巨大，资源价格不断攀升，没有什么办法能使中国人民的生活水平完全赶上世界那些最富有的国家，中国人也知道这一点。 这就是为什么中国仍执着地选择了这条有风险的道路。老一辈的中国人孩童时都经历过饥荒，因此展望未来时，总会考虑到天灾。中国公众也知道“冬天”即将来临。局外人着迷于中国内部的巨大财富，但是他们没有注意到，富有的中国人正努力把自己的财产转移出国，贫穷一些的则能省就省，以求储备充足。中国各阶层人士都对未来严阵以待。\n- 在一个明确乐观的未来中，会有工程师设计水下城市和太空定居地，而在一个不明确的乐观未来中，会有更多的银行家和律师。金融其实是不明确思想的集中体现，因为只有人们不知如何赚钱时，才会想到去搞金融。如果不去法学院，优秀的大学毕业生会选择华尔街，这是因为他们对自己的职业生涯没有切实的规划。而一旦他们到了高盛，就会发现金融界每件事都不明确。你仍然会乐观，因为你渴望成功，但是根本问题在于市场具有随机性。你无法明确地或实质地了解任何事情，而且多样化变得极其重要。\n- 在这样的循环中，人们都不知道拿钱在实体经济中做什么。但是在一个未来不明确的世界中，人们就是喜欢无限的可选择性；钱比其他任何用钱能得到的东西更有价值。只有在一个明确的未来中，钱才是达到最终目的的手段，而非最终目的。\n- 生物技术初创企业是不明确思维的一个极端例子。研究者们只拿可能行得通的东西实验，而不是去发展人体系统如何运作的确定理论。生物学家说他们需要采取这种做法，因为基础生物学太难。按他们所说，信息技术初创公司之所以经营得起来，是因为我们自己创造了电脑，而且使其可靠地执行我们的指令。生物技术之所以困难是因为身体不是我们设计的，而且我们越是了解自己的身体，就越是发现身体真是太复杂了。\n- 但是精益是一种方法，而不是目标。对已经存在的事物做出小的改变可能让你达到局部市场最大化的成绩，但是不能帮助你取得全球市场的最大化。你可以推出一款最好的应用程序，让人们可以通过iPhone订购手纸。但是没有大胆计划的修正不会使你实现从0到1的跨越。对于一个对未来不明确的乐观主义者，公司是最奇怪的地方：没有一个计划，你有什么理由希望自己的生意成功？达尔文主义在其他环境中也许是个有用的理论，但是对于初创公司，最有效的还是富有智慧的设计。\n- 长期规划在我们未来不明的追求短期利益的世界里经常被低估。当2001年10月第一部iPod发布时，产业分析师对它的评论只是“对麦金塔电脑用户有很好的号召”，对其他人“毫无影响”。乔布斯计划使iPod成为新一代便携式移动装置，但是大多数人都看不到这一点。图6–3公司的股价走向向我们展示了这个长期计划的结果。\n- 钱 能生钱。**“凡是有的，还要加给他，叫他有余。凡没有的，连他所有的，也要夺过来。”**（《马太福音》第25章29节）当爱因斯坦宣称复利是“世界第八大奇迹”，是“有史以来最伟大的数学发现”，甚至是“宇宙最强大的力量”时，他同样对这句《圣经》箴言产生了共鸣。不管你赞同哪种说法，其中的观点是一致的：不要低估了指数级增长。事实上，并没有什么证据显示爱因斯坦确实提到过这些。但是硬是把话塞给爱因斯坦恰恰强化了这样的信息：爱因斯坦一生奉献出的智慧本金带来的利息直至他去世后仍源源不断，连他没有讲过的话都会归功于他。\n- 这一章将解释幂次法则在你向钱看时是如何体现的：风险投资中，投资者都努力想从公司创立早期呈指数级的增长中获利，而只有一小部分公司较之其他公司获得了呈指数级增长的价值。大多数企业根本不需要和风险投资基金打交道，但是每个人都需要明确一件事，一件甚至是风险投资家也在努力去明确的事：我们所在的世界不是正常的世界，而是处在幂次法则之下。\n- 但是“撒网式投资，然后祈祷”这种方法通常会全盘皆输。这是因为风险投资的回报并不遵循正态分布，而是遵循幂次法则：一小部分公司完胜其他所有公司。如果你看重撒大网，而不是把注意力放在仅仅几个日后价值势不可当的公司上，一开始你就会与这些稀有公司失之交臂\n- 学校教给我们的却恰恰相反：体制化教育传授的是无差别的一般知识。每个身在美国教育体制中的人都没有学会用幂次法则来思考。每所中学不管什么课都一律上45分钟，每个学生都以相同的步伐向前迈进。在大学中，模范学生痴迷于学习另类的冷门技能，想以此保证自己的未来发展。每所大学都相信“卓越”，教育部门随意给出的几百页按字母排序的课程表看起来就是为了确保“你做什么并不重要，重要的是你要把它做好”。你做什么并不重要？真是彻头彻尾的错误。你应该将全部注意力放在你擅长的事情上，而且在这之前要先仔细想一想未来这件事情是否会变得很有价值。\n- 伴随着地理隔阂的淡化，四种社会趋势已经合力瓦解了人们仍然相信秘密存在的信念。第一是渐进主义。从小我们便被教育做事的正确方法是积跬步以至千里。如果超过正常进度，且学到了考卷范围以外的知识，你并不能因此多拿学分。反之，如果严格做到所要求的事（而且做得比同学稍好一些），你将会得到好成绩。这种做法一直延续到工作阶段，这也就解释了为什么学者们通常争相发表无足轻重的论文而不去探索新的领域。第二是风险规避。人们害怕秘密是因为怕犯错。显然，秘密还没有经过主流的审查。如果你的目标是一生不犯错，你就不应该去探索秘密。将一生奉献于别人不相信的事情，在正确的路途上孑孓独行已是艰难，而在错误的路途上独自前行更是不可忍受。\n- 第三是自满。社会精英享有最大的自由，也最有能力去探索新想法，但是他们似乎最不相信秘密。既然能够舒舒服服地享用已有成果，为什么还要去探索秘密呢？每年秋天，顶尖的法学院和商学院的新生欢迎词都暗含了同样的信息：“进入了精英学校，你的人生就高枕无忧了。”但这件事也许只有你不相信它，它才是真的。\n- 秘密分为两种：关于自然的和关于人的。自然界的秘密无处不在，想要发现，你必须探索物质世界的未知部分。关于人的秘密是不同的：是人类对自身认知的空白或者是人们以防他人知道而隐藏的事情。思考要创建哪种公司时，需要问自己两个不同的问题：自然没有告诉你的秘密是什么？人类没有告诉你的秘密是什么？\n- 掌握秘密的极少数人， 愚蠢地将心扉全然洞开， 将自己的满腔热情示人， 总是惨遭迫害与火刑。\n- 那么要告诉谁呢？不管你必须要对谁说，都不要多讲。实际上，选择谁也不告诉和选择人人都告诉之间有一个黄金平衡——那就是公司存在的秘密。最好的企业家深谙此理：所有成功的企业都是基于鲜为人知的秘密创立的。好企业是改变世界的密谋者，当你与人分享秘密时，听众就成为了你的谋士。 就像托尔金在《魔戒》中所写： 不断向前延伸的道路， 是从家门开始的。\n- 人生是漫长的旅程；由前人踏出来的路，一眼望去，没有尽头。不过这个故事后面还有另一首诗： 转角处等待我们的 是新路或神秘的门， 即使我们今天路过， 明天可能还会回转。 请选择这隐秘的路 通向月亮或者太阳。 道路不必无限延伸，一直走下去。选择那条隐秘的路吧。\n- 在这方面，公司就像国家。早先的错误决定一旦做出（比如选错合伙人、挑错员工），之后就很难改正。而要纠正这些错误，公司可能面临几近破产的危险。作为创始人，你的首要工作就是打好基础，因为你无法在有缺陷的基础上创建一个伟大的企业。\n- 现在我考虑投资一家初创公司时，会考察其创立团队。技术能力和才华互补固然重要，但创始人之间的了解程度和他们合作的默契程度也同样重要。创始人在共同创业前应有深厚的交情，否则就是在碰运气。\n- 不仅仅创始人要好好相处，公司的每个人都需要和谐共处。硅谷的自由派人士可能会说你可以通过独资的方式解决这个问题。虽然弗洛伊德、荣格和其他心理学家都有一套理论解释每个人的理智与自我是如何相离相悖的，但至少在商业上，为自己工作能保证团结。不幸的是，它还限制了你创立公司的种类。因为如果没有团队，从0到1是非常困难的。 硅谷无政府主义者可能会说只要选对人，你就能做到团结一致，没有任何管理架构也能平稳发展。员工的奇思怪想和在办公场所各行其是的混乱状态被认为有助于“打破”由其他人制定并遵守的旧规则。的确，“如果人类是天使，就不需要政府了”。但是无政府主义的公司忽略了詹姆斯·麦迪逊所指出的：人类不是天使。因此管理公司的高管与控制公司的董事要各司其职，这也正是要对创始人和投资人在公司的权力上进行正式界定的原因。你需要能与你和睦相处的同事，但也需要规章制度来帮助所有人长期保持团结。\n- 总之，不要打福利待遇之战。奔着免费洗衣或宠物看护而来的人是不会成为你团队中一名合格成员的。你只需提供健康保险之类的基本福利，并许之其他公司无法提供的，即同优秀同事一道完成不可替代工作的机会。在薪酬福利上你可能比不上2014年的谷歌，但如果能就公司使命和团队给出好的回答，你便与1999年的谷歌站在同一高度。\n- 管理PayPal时，我做得最棒的事是让每个人只负责做一件事。每个人的工作都是独特的，且他们知道我只以此作为评判标准。我这样做的本意是简化管理，但是随后我注意到一个更深层的成果：界定角色可减少矛盾。公司里绝大多数矛盾是由同事竞争同一岗位引起的。由于初创公司初期的工作角色流动性大，所以面临很大的风险。消除竞争更易于建立长久的纯粹的工作关系以外的交情。除此之外，内部和谐是初创公司存活的关键。我们常常将初创公司的失败归咎于竞争体系中的强劲对手。但每个公司本身就是一个生态系统，派别冲突会使其无力应付外部威胁。内部冲突就像是自体免疫系统疾病，致死的原因可能是肺炎，而真正的死因却隐藏在内部，无法一眼看出来。\n- 在硅谷，技术精英质疑广告、营销和销售行业，因为这些似乎是肤浅荒谬的。但广告之所以重要是因为它确实有效，对技术精英管用，对你也管用。你或许会说你是个例外，没人能操控你的喜好，所以广告只对其他人管用。拒绝明显的推销术并不难，所以我们轻信自己能独立思考。但是广告不会立刻让你购买产品，而是为以后的购买埋下伏笔。没有意识到广告影响力的人会受到双重欺骗。\n- 技术精英希望可以忽视销售，把销售人员都放逐到其他星球。我们都认为自己才是做决定的人，销售对我们没有用处，但这不是真的。每个人都有产品需要销售——不论是员工、创始人还是投资者。即使你的公司仅仅由你和电脑组成，也是如此。环视四周，如果没有看到销售员，那么你就是。\n- 人们不仅竞争工作岗位，也竞争相同的资源。美国人在低价购买从中国进口的玩具和纺织品的同时，需要以更高的价格购买汽油，因为数百万中国车主也开始参与到对汽油的竞争中。不管是在上海吃鱼翅，还是在圣地亚哥吃鱼肉玉米饼，人们都需要食物，都需要房屋。人们也不只满足于温饱——随着全球化的推进，人们的需求会不断增加。既然数亿中国农民最终达到了温饱水平，他们自然希望多吃点儿肉，少吃点儿粮食。上层社会的欲望更是惊人的一致：从圣彼得堡到平壤的寡头都喜爱水晶香槟。\n- 我们痴迷于大数据仅仅是因为觉得科技很奇特。我们为计算机单独取得的一些小成就而惊叹，却忽视了人类在计算机的辅助下取得的巨大进步，因为人类的参与淡化了其神秘性。沃森、深蓝电脑和越来越厉害的算法虽然很酷，但未来最有价值的公司肯定不是靠计算机单独解决问题，而是关注计算机如何才能帮助人类解决难题。\n- 能源问题属于工程问题，因此你可能以为工程技术人员在经营清洁技术公司。你错了，失败的公司是由非技术人员经营的。这些销售型高管们擅长募集资金、拿到政府补贴，但他们拙于创造顾客愿意购买的产品。\n- 团队。特斯拉的首席执行官是很棒的工程师，也是杰出的销售人员，因此，他建立的团队两者都很擅长，也就没什么可惊讶的了。埃隆如此描述他的员工：“进入特斯拉，如同你选择进入特种部队。进入普通军队也很好，但在特斯拉工作，你就选择了接受挑战。”\n- 公司应该汲取的教训是企业离不开创始人。对于创始人看似极端怪异的行为，要有更大的容忍度，我们需要靠非同寻常的人来领导公司，取得大的飞跃，而非限于小的进步。 创始人应该汲取的教训是不要沉醉于自己的声望和他人对自己的追捧，否则，会使自己臭名远播，或是被妖魔化——因此，要小心行事。\n- 总而言之，不要高估自己的个人能力。创始人的重要性并非源于自身工作带来的价值，事实上，优秀的创始人能使公司的每个人发挥所长。我们需要独特的创始人并不意味着我们需要崇拜美国小说家艾茵·兰德笔下那些不依赖周围任何人的“行动领导者”。在此方面，兰德只能算是半个好作家：她陛下的恶棍是真实的，但英雄是虚构的。现实生活中没有代表自由主义社区的高尔特峡谷，人也无法脱离社会。相信自己具有不依赖他人的神圣能力并不能表明个体的强大，而是表明你把人们的崇拜或嘲弄错认为事实。创始人最大的危险是对自己的神话过于肯定，因而迷失了方向。同样，对于公司，最大的危险是不再相信创始人的神话，错把不信神话当作一种智慧。\n- 我们是否在整个宇宙范围实现“奇点”或许不重要，重要的是我们是否能抓住独一无二的机会，在日常工作中创新。对我们——全宇宙、全球、全国、全公司、整个人生乃至此刻最为重要的是——独特。",2023-03-07T09:38:10.617Z,reading,com.baizeyu.published.model.Published
640a227606c5e77178f39150,🚢 Docker,"# Contents\n- [The Evolution of Containerization for Application Deployment](https://baizeyu.info/blog/view/642f0be101fef57cfca2f647)\n- [Key Linux Kernel Technologies Involved in Container Technology](https://baizeyu.info/blog/view/6433fb71cb5aec730fd6f479)\n- [Docker Architecture and Installation](https://baizeyu.info/blog/view/6436aabf882850106f5c0bb3)\n- [Use Container to run Nginx and Docker commands](https://baizeyu.info/blog/view/6437e29b882850106f5c0bb4)\n- [Introduction to Docker Image](https://baizeyu.info/blog/view/64398524882850106f5c0bb5)\n- [Docker containerized deployment of enterprise-level application clusters](https://baizeyu.info/blog/view/644182dd9ba29477b0013f0c)\n- [Comprehensive explanation of Dockerfile and novel container image construction techniques](https://baizeyu.info/blog/view/6443c60b9ba29477b0013f0d)\n- [Deep analysis of Docker networking, achieving cross-host communication between containers using etcd+flannel](https://baizeyu.info/blog/view/644913089ba29477b0013f0e)\n- [Mechanism for persistent storage of container data](https://baizeyu.info/blog/view/644d73e39ba29477b0013f0f)\n- [Docker Compose](https://baizeyu.info/blog/view/644fc7e29ba29477b0013f10)",2023-05-01T14:09:40.941Z,tech,com.baizeyu.published.model.Published
640b849b06c5e77178f39156,⚓️ Kubernetes,"# Please Find the Full Article via:\nhttps://clarencewhite.notion.site/k8s-547357f62deb4022b95960ba198cb35a\n\n**Note**: this is a temporary link, I will keep updating it, once completed, the full article will be moved from notion web link to this blog site!\n\n\n\n----------\n# Useful Resources:\n- https://k8s.easydoc.net/docs/dRiQjyTY/28366845/6GiNOzyZ/9EX8Cp45 (入门教程)\n- https://github.com/eip-work/kuboard-press （kuboard, a GUI for k8s management）\n- https://k3s.io/ (k3s, a lightweight distribution)\n- https://k3d.io/v5.4.8/ (a local runner for k3s, nice!)\n- https://minikube.sigs.k8s.io/docs/ (minikube, a local mini version for quick local development and test)\n- https://www.yuque.com/wukong-zorrm/qdoy5p (入门教程)",2023-03-10T19:27:22.193Z,tech,com.baizeyu.published.model.Published
640f0ad706c5e77178f39157,💥 Computer Network,# Outline\n- [应用层](https://clarencewhite.notion.site/36c809f23d204bcd973b240438303fad)\n- [传输层](https://clarencewhite.notion.site/6cb1b019cd73460aac49fbe12cbfc27c)\n- [网络层](https://clarencewhite.notion.site/867a8ee4197f4c468c4a016e7ee6585c)\n- [链路层](https://clarencewhite.notion.site/04e9b47df73c41faa1d1702fc1e35125)\n- [物理层](url) (Nothing here),2023-03-13T11:36:53.244Z,tech,com.baizeyu.published.model.Published
6423629306c5e77178f3915d,2021.7 离开作业帮团队的告别,时间长河流淌至此，我们不得不说一声告别，我不太希望我的告别是激烈的，我希望我的来去和上图中的诗一样轻描淡写（“轻轻地我走了，正如我轻轻地来”）。我想感谢这个团队中每一个人，这是个有爱的团队，我能感受到这里每位老师的善良与温暖；我也想郑重道歉，我没有为大家带来更多的价值，以至于春季的结果并不是很理想🙏。在这最后，我想和大家分享我对几个事物的看法，希望能为大家带来什么。\n## 关于教育\n  说实话，我只是一个2020疫情年毕业的普通本科生，一个偶然的机会让我接触到线上教育行业，我亲眼看到，亲自教过不少来自偏远地区的孩子，在这个过程中，我体会到了这个大国发展的不平衡。可能有时候身处武汉这样的新一线城市，我们很容易被眼前的繁荣蒙住双眼，认为全中国孩子们都有这样的良好教育机会，有时单通过网络镜头也无法让我们对一件事有切身体会，但如果我们有机会去别的地方亲自走一走，看看那里的孩子们的状况，那个感受会很不一样。记得五一假期去随县旅游，那是下午放学，我亲眼看到一个小孩子背着脏脏的书包一个人回家，那一刻的我在想，这个孩子回家后做什么呢？这个孩子以后会是一个怎样的人才呢？\n  我认为教育永远都不是塞知识点帮助孩子们闯过重重考试关卡，而是引导孩子们在学知识的过程中发现自己的所长并坚持下去，最终成为一个有建树的人，这也成了我的动力。\n  如果我们每次面对一个孩子都这样想，那我相信我们结果不会差。\n\n## 关于成长\n  我们都是很年轻的人，甚至可以说“太年轻了”，这是非常好的事情。\n  我认为我们的成长应该是多维度的，这包括思维认知方面，也包括实操技能方面，通过寻求创新能获得自我的成长。我们手头的工作有时候看起来是“枯燥无味”的，但同一个事情，总有一些人能做出花样来，这种花样可能在短期内取得很好的结果，也可能将事情的发展推向一个新的高度，这就是创新。\n  那么要怎么从创新中收获成长呢？刻意和无意。刻意即做事情的时候不停想“我要如何完美达成目标？”；无意是我们在生活中要随时留意细节，多去阅读经历，这些东西可以作为工作上创见的突破口。\n\n## 关于发展和金钱\n  眼下这个行业正处在变革的时期，但是变革能否成功以及变革之路要走多久无人知晓。但有一件事情是确定的，那就是供需关系没有太大改变，我们依然要做好本职工作。\n  大家也感受到了从前两年到今年的形势变化，在我看来，企业的初创者一定是怀揣着“让优质教育触手可及”的理想做事的。只不过在实现这个理想的过程中，必须借助资本，这是发展的一个必然。但我始终认为，资本并不可怕，可怕的是人性中无止境的贪婪。\n\n\n----------\n\n  最后，希望大家能通过我这只言片语有所启发，争取找到并实现自我的人生价值，愿更好的我们在更好的未来相遇! \n  Stay in touch.  \n白泽宇,2023-04-06T19:39:53.253Z,life,com.baizeyu.published.model.Published
642563d406c5e77178f3915e,"Goals for Week 13&14, 2023","# About\nMy golas for week 13 and 14 in 2023...\n## Website\n- ~~Use article id to retrieve articles~~\n- ~~Fix mobile displaying bug (more responsive)~~\n- ~~Add category selection feature to backend editor~~\n- ~~Change markdown editor library~~\n- ~~Optimize overall architecture~~\n- Add image upload feature to markdown editor:\n- [x] create a test page during developmenet\n- [x] a basic md editor on that page\n- [x] write a function that reads the pase from clipboard, in the function upload to java api\n- [x] in backend, add another service (api) for receiving image file from frontend -> upload to google drive -> return a image link to frontend -> replace the markdown link in frontend.\n\n## Studying\n- Keep updating Kubernetes blog\n## Workout\n- 4 days per week\n## Reading\n- 40 min's reading per day （《楚留香传奇》）",2023-04-06T19:39:57.602Z,life,com.baizeyu.published.model.Published
642ea57e01fef57cfca2f646,The Architecture of this website,"# Architecture Diagram\n<p align=""center"">\n<img src=""https://raw.githubusercontent.com/ClarenceWhite/BlogImage/main/images/newblog4-6-11-47-31.jpg"" id=""blog-image"" />\n</p>\n\n# Intro\nThere are 6 docker containers in this app, all of them are under the same docker network, so they can communicate with each other easily. Once there is a code update, a bash script can be executed to automate the re-deployment process.\n\n# Update Logs\n- 2023.3 - 2023.4: \n    - Rebuilt the overall architecture to improve the stability and aesthetics of the site; \n    - Added image upload feature in online Markdown editor.\n- 2023.4.18:\n    - Optimized image uploading function in online markdown editor\n<p align=""center"">\n<img src=""https://raw.githubusercontent.com/ClarenceWhite/BlogImage/main/images/642ea57e01fef57cfca2f646-4-18-12-41-10.jpg"" id=""blog-image"" width=""500""/>\n</p>\n\n- 2023.4.19:\n    - Updated SSL certificate for the next 5 years, cost me 20$.",2023-04-19T11:07:09.172Z,tech,com.baizeyu.published.model.Published
642f0be101fef57cfca2f647,The Evolution of Containerization for Application Deployment,"# 1. Pain Points of Application Deployment\n\n## 1.1 Application Deployment Process\n\n**Example: Deploying a web application developed in the Java programming language using the War package to Tomcat.**\n\n- The deployment process is as follows:\n  - Configure the server runtime environment: the Java runtime environment, such as JDK or JRE.\n  - Install the Tomcat web middleware on the server to run the War package.\n  - Place the corresponding War package for the Java web application in the Tomcat directory.\n  - Start the Tomcat application on the server.\n  - Optional: Deploy database (MySQL) or caching system (Redis), etc., one by one.\n\n\n\n## 1.2 Application Scaling\n\n- Involves deploying the same environment on multiple servers.\n- Pain point: redeploying the above environment is time-consuming and costly in terms of labor and resources.\n\n\n\n## 1.3 Multi-Environment Application Deployment\n\n- Environments: Local testing environment, pre-production environment, production environment.\n- A successful test in the local environment may encounter problems in the pre-production environment, or even though both environments are fine, there might be issues in the production environment.\n- Need: One successful deployment that can run everywhere.\n# 2. Evolution of Computing Resources Application\n\n## 2.1 Pain Points of Physical Server Usage\n- From the perspective of physical server management:\n  - High manpower cost to deploy physical server environment, especially without sufficient automation means, relying on manual operation and maintenance.\n  - When a physical server fails, the restart time is too long, ranging from 1-2 minutes to 3-5 minutes, which does not meet the requirement of achieving 99.999999999% uptime for servers.\n  - Troubleshooting hardware issues during application runtime on physical servers is complicated.\n  - It is difficult to effectively schedule and utilize computational resources on physical servers.\n\n- From the perspective of deploying applications on physical servers:\n  - Time is wasted in deploying environments on physical servers without automated management tools.\n  - Changing application configurations on physical servers requires repeating the previous steps.\n\n\n\n## 2.2 Pros and Cons of Using Virtual Machines\n\n<p align=""center"">\n<img src=""https://raw.githubusercontent.com/ClarenceWhite/BlogImage/main/images/640a227606c5e77178f39150-4-6-18-40-3.jpg"" id=""blog-image"" height=""300"" width=""400""/>\n</p>\n\n### 2.2.1 Pros of Using Virtual Machines\n\n- From the perspective of virtual machine management:\n  - Virtual machines are lighter than physical servers and can be quickly generated using virtual machine templates.\n  - The deployment of applications in virtual machines is as controllable as physical servers, and when virtual machines fail, new ones can be used directly to replace them.\n  - Efficient use of physical server resources by virtual machines.\n  - Virtual machines provide isolation similar to physical servers for a good application runtime environment.\n\n- From the perspective of deploying applications in virtual machines:\n  - Applications can be easily scaled up or down in virtual machines.\n  - Compared to physical servers, when the virtual machine running an application fails, it can be quickly restarted, usually within seconds, and the application can continue to provide services.\n  - Easy migration of applications.\n\n### 2.2.2 Cons of Using Virtual Machines\n\n- Virtual machine management software itself consumes a lot of physical server computing resources. For example, VMware Workstation Pro will take up a large amount of physical server resources, so KVM virtual machines are more commonly used in enterprise applications.\n- The underlying hardware of virtual machines consumes a lot of physical server resources. For example, the virtual machine operating system's hard disk directly occupies a large amount of physical server hard disk space.\n- Compared to container technology, virtual machine startup time is long, while container startup can be calculated in milliseconds.\n- Virtual machines add a chain of calls for physical server hardware resource allocation, which wastes time and makes virtual machines less performant than physical servers.\n- Since applications are deployed directly on virtual machine hard disks, when migrating applications, the operating system in the virtual machine hard disk needs to be migrated together, resulting in larger migration files, wasting more storage space and consuming more time.\n\n\n\n## 2.3 Pros and Cons of Using Containers\n<p align=""center"">\n<img src=""https://raw.githubusercontent.com/ClarenceWhite/BlogImage/main/images/640a227606c5e77178f39150-4-6-18-39-21.jpg"" id=""blog-image"" height=""300"" width=""400""/>\n</p>\n\n### 2.3.1 Pros of Using Containers\n\n- No need to install an operating system in the container, saving a lot of time.\n- Applications can be directly deployed in the container without manually setting up the runtime environment.\n- Container networking is automatically managed for accessing the services provided by applications in the container.\n- Convenient sharing and building of application containers.\n- Millisecond-level startup time.\n- Containers can directly use physical server hardware resources, with high hardware resource utilization and good performance.\n\n### 2.3.2 Cons of Using Containers\n\nFor those who are accustomed to using physical servers or virtual machines, the controllability of containerization is not strong. The most intuitive example is trying to manage containers in the same way as physical servers or virtual machines. In fact, there are fundamental differences in how containers are managed, and it is best not to manage them that way.\n\n# 3. What is a Container?\n\n## 3.1 Container Definition\n- Virtual machine:\n  - Uses virtualization technology to package physical server computing resources, providing an environment similar to a physical server for applications.\n  - Isolates applications from each other.\n  - Provides convenience in deploying and migrating applications using automation technology.\n  - Can scale horizontally.\n\n- Container:\n  - Packages lightweight physical server computing resources, similar to a lightweight virtual machine, to provide a runtime environment for applications.\n  - Can achieve high-density deployment in a physical server.\n\n- Comparison of Containers and Virtual Machines\n\n\n\n| Attribute      | Container | Virtual Machine |\n| -------------- | --------- | --------------- |\n| Isolation      | Process   | Full resource    |\n| Startup time   | Milliseconds or seconds | Seconds or minutes    |\n| Kernel         | Shares host kernel | Uses independent kernel    |\n| Resource usage | Megabytes | Gigabytes       |\n| System support capacity (same level) | Supports thousands of containers | Supports dozens of virtual machines |\n\n## 3.2 Container Functions\n\n- Install container management tools such as Docker and Containerd to run applications in a containerized manner.\n- Run applications in their own containers, achieving isolation between applications.\n- The container where the application runs can generate an application template file, called a container image, which is immutable and serves as the foundation for cloud-native infrastructure technologies. It can be run on other physical servers as well.\n\n## 3.3 Problems Solved by Containers\n\n- Rapid delivery and deployment of applications (through images and containers)\n- Efficient utilization and isolation of resources (high-density deployment on physical servers)\n- Convenient migration and scaling (build once, run anywhere)\n",2023-04-10T12:54:15.856Z,hide,com.baizeyu.published.model.Published
64318d95cb5aec730fd6f477,本性,> 根据我最近的观察和思考，我发现一个人的性格其实在生下来的那一刻就已经决定了，后天的环境可能会对他的性格有所改变，但是这种改变是微小的，可能 20%是可以改变的，但是始终有一个底色，这个底色是无论如何都很难被改变的（除非重大的变故）。  \n\n>  接下来此人的人生七八十年都会遵从这个性格底色来发展。 我们总在强调后天的努力因素有多重要，但多数人没有看清楚的是先天的底色，因此，了解自己往往是最难的。我愿意将人生分为三种境界：底层的不自知，中层的自知，上层的不自知。低级的不自知理解起来很简单，就是无法认清自己，但却去做一些自己做不了的事情，注定失败。中级的自知就是很清楚自己什么样子，自己能干什么，不能干什么， 干一件事情有多大把握能成功。而最高级的，就是“我不知道我，所以我是我”的心态。我们重点讨论后两者，因为第一种没有什么值得好讨论的，也许第一种人一辈子都认不清自己。\n\n>  我们当中的大部分人可能都会到第二种境界，费尽九牛二虎之力来认清自己，然后找到适合自己的发展路线，这已经很不错了。认清自己需要大量的时间独自和自己相处，需要大量的实践和试错，通过这一大堆的试错，我们才能最终明白自己这一生应该做什么才能将自己的意义感最大化。\n\n> 有少数的天资聪颖的人，他们好像不需要探索，他们好像不需要费很大力气就从很早的时期知道自己这一生的目标和所要做的事，这些人是天才，他们不需要指引，只需要跟随自己的本性就能有所成就。\n\n> 用这样的思维观察别人：你会很快发现这个人的本性，他那些不能被改变地方，他那些天性会让他在未来变成什么样子，通过这样的延伸思考就能在很快的时间内断定这个适不适合或者值不值得合作，如果合作了会有什么样的收益和风险。\n\n> 用这种思维观察自己：我们需要经常注意到自己的微小习惯，举个简单的例子，在遇到一件令人生气或者遇到不好的事情的时候，我们的第一反应是什么样子的，mindset 是什么样子的，这样的 mindset 会有什么样的影响，能不能解决当下的困境？对自己和他人是好的还是不好的？经常对自己潜意识或者无意识行为的一种细致入微的观察，以及主动去接触不同的事物然后观察自己对这件事情的喜好程度和情绪的反应，那么很快一个清晰的自我就会暴露在自我面前，长此以往，自我的本性也就昭然若揭。明白了自己的本性， 那么这就是一种自我身上独特的规律，遵循这种“客观”的规律去行事，就不会让自己陷入不好的状况。\n\n\n> 保持纯真和本性： 在这里我想谈到的就是两点——拒绝虚伪和顺其自然。很多人被外界的环境所影响，渐渐将自己纯真的本性掩藏起来，这样只会徒增痛苦，保持本真不为外界所动摇，是我们需要修炼的地方，当外界分外嘈杂的时候，影响你判断的时候，能不能屏蔽嘈杂做出正确的跟随纯真的自我的判断哪怕会牺牲短期利益，是一种珍贵的品质。顺应自己的“道”，才能永生。,2023-04-09T13:03:59.091Z,life,com.baizeyu.published.model.Published
6432bbabcb5aec730fd6f478,"Goals for week 15&16, 2023","# About\nThese are my goals for week 15 & 16 in 2023 (from 10th April to 23rd April). I will start my work at HUAWEI Ireland from the 24th of April, so this is the last two-week section that I will follow the same routine as usual, hope I can save more time for studying after I start working there.\n# Tech\n- For week 15:\n    - Mainly focus on containerizing techs (Docker & Containerd), will update related tech blogs in ""tech"" section of this website\n- For week 16:\n    - Will focus on Kubernetes\n# Workout\nI am very frustrated after injuring my back last week. I hope the following two weeks will not let me down, because man needs to exercise to keep motivated and fit. \n# Reading\nJust keep going, try to reach 50% of the book.",2023-04-09T13:23:19.357Z,life,com.baizeyu.published.model.Published
6433fb71cb5aec730fd6f479,Key Linux Kernel Technologies Involved in Container Technology,"# 1. History of Container Technology\n\n## 1.1 1979 - chroot\n\n- The concept of container technology can be traced back to UNIX chroot in 1979.\n- It is a set of ""UNIX operating system"" designed to change the root directory and other subdirectories to a new location within the file system, only accessible by specific processes.\n- The design purpose of this feature is to provide each process with a set of isolated disk space.\n- It was added to BSD in 1982.\n\n## 1.2 2000 - FreeBSD Jails\n\n- FreeBSD Jails is one of the early container technologies built by Derrick T. Woolworth in the FreeBSD Development Consortium in 2000.\n- It is a set of ""operating system"" systems similar in positioning to chroot, but includes other process sandboxing mechanisms for isolating file systems, users, networks, and other resources.\n- In this way, it can provide a corresponding IP address for each Jail, customized software package, and even configuration plan.\n\n## 1.3 2001 - Linux VServer\n\n- Linux VServer is another type of jail mechanism that can be used to protect the security of resources on various partition resources on the computer system (including file systems, CPU time, network addresses, and memory).\n- Each partition is called a security context, and the virtualized system is called a virtual private server.\n\n## 1.4 2004 - Solaris Container\n\n- The Solaris Container was born targeting x86 and SPARC system architectures. It initially appeared in the February 2004 Solaris 10 Build 51 beta and was officially launched in the full version of Solaris 10 in 2005.\n- The Solaris Container combines system resource control with boundaries provided by partitions. Each partition runs as a completely isolated virtual server within a single instance of the operating system.\n\n## 1.5 2005 - OpenVZ\n\n- OpenVZ is very similar to Solaris Containers and uses a patched Linux kernel to achieve virtualization, isolation, resource management, and checkpoint delivery.\n- Each OpenVZ container has an isolated file system, users and user groups, a process tree, network, devices, and IPC objects.\n\n## 1.6 2006 - Process Container\n\n- The Process Container was introduced by Google in 2006 and aims to limit, allocate, and isolate resource usage (including CPU, memory, disk I/O, and network) in a set of processes.\n- It was later renamed Control Groups to avoid conflicts with another term in Linux kernel 2.6.24. This shows Google's keen insight into the importance of container technology and its outstanding contributions.\n\n## 1.7 2007 - Control Groups\n\nControl Groups, also known as cgroups, were added to the Linux kernel in 2007 by Google.\n\n## 1.8 2008 - LXC\n\n- LXC stands for Linux Containers.\n- It is the first complete Linux container management implementation solution.\n- Its functionality is implemented through cgroups and Linux namespaces.\n- LXC is delivered through the liblxc library and provides APIs that can be integrated with Python3, Python2, Lua, Go, Ruby, Haskell, and other languages.\n- Compared to other container technologies, LXC can run on the original Linux kernel without any additional patches.\n\n## 1.9 2011 - Warden\n\n- Warden was created by CloudFoundry in 2011, using LXC as the initial stage and then replacing it with their own implementation.\n- Unlike LXC, Warden is not tightly coupled with Linux. Instead, it can run on any operating system that can provide multiple isolation environment methods. Warden runs as a background process and provides APIs for container management.\n\n## 1.10 2013 - LMCTFY\n\n- LMCTFY stands for ""Let Me Contain That For You"". It is actually an open-source version of Google's container technology stack, responsible for providing Linux application containers. In the early stages of the project, Google claimed that it could provide reliable performance, high resource utilization, resource sharing mechanisms, ample room for development, and near-zero additional resource consumption.\n- The first version of lmctfy was officially released in October 2013. Google decided to transform the core concepts and abstraction mechanisms of lmctfy into libcontainer in 2015. After losing its mainstream status, lmctfy has lost all positive development momentum.\n\n　　The Libcontainer project was originally established by Docker, and is now under the jurisdiction of the Open Container Initiative.\n\n## 1.11 2013 - Docker\n- When Docker was first released in 2013, it was an open-source container management engine based on LXC.\n- It simplified the complex process of creating and using containers with its own command system.\n- As Docker developed further, it began to have more ambitious goals, such as defining a standard for container implementation by abstracting the underlying implementation to the Libcontainer interface. This means that the underlying container implementation has become a variable solution, regardless of whether namespace, cgroups technology, or other solutions such as systemd are used, as long as a set of interfaces defined by Libcontainer is implemented, Docker can run. This also makes it possible for Docker to achieve comprehensive cross-platform support.\n# 2. Namespace\n## 2.1 Introduction to NameSpaces\n\n- Many programming languages ​​include the concept of namespaces, and we can think of namespaces as a kind of encapsulation, which actually achieves code isolation.\n\n- In the operating system, namespaces provide isolation of system resources, including processes, networks, file systems, etc.\n\n- In fact, one of the main purposes of implementing namespaces in Linux is to provide lightweight virtualization services, that is, containers. Processes in the same namespace can perceive each other's changes while knowing nothing about processes in other namespaces. This allows processes in containers to create an illusion that they are in an independent system environment, achieving independence and isolation.\n\n## 2.2 Classification of NameSpaces in Linux System\n\n\n\n| Namespace Type |             Description             |                        Function                        |                             Remarks                             |\n| :------------: | :--------------------------------: | :----------------------------------------------------: | :--------------------------------------------------------------: |\n| Process NS     |       Isolates process IDs          | Linux manages process IDs through namespaces, and the same process has different IDs in different namespaces |         The process namespace is a parent-child structure, and the child namespace is visible to the parent namespace         |\n| Network NS     | Isolates network devices and ports  |           Network isolation is achieved through network namespaces            | Docker uses virtual network devices to connect network devices in different namespaces |\n| IPC NS         |    Isolates interprocess comm.     |                       Inter-process communication methods                       | PID NS and IPC NS can be combined together, processes in the same IPC namespace can interact with each other, and processes in different namespaces cannot |\n| Mount NS       |        Isolates mount points        |                      Isolates file directories                       |   Processes can separate mount points from the system during operation. Using this feature, we can achieve the function of chroot, which is more secure than chroot in terms of security.  |\n| UTS NS         | Isolates Hostname and NIS domain   |     Allows containers to have independent hostnames and domains, making them look like independent hosts     |            The purpose is to isolate the hostname and network information service (NIS)             |\n| User NS        |      Isolates user and group IDs    | Users on each container are not in the same namespace as those on the host machine. |  Like process ID, user ID and group ID are different inside and outside the namespace, and can exist with the same ID in different namespaces. |\n\n## 2.3 Use Case of NameSpaces\n\n> Taking net namespace as an example\n\n- In Linux, the network namespace can be considered as an environment with a separate network stack (network card, routing table, iptables) that is isolated. Network namespaces are often used to isolate network devices and services, and only devices with the same network namespace can see each other.\n\n- Logically, a network namespace is a copy of the network stack, with its own network devices, routing tables, adjacency tables, Netfilter tables, network sockets, network procfs entries, network sysfs entries, and other network resources.\n\n- From the system's point of view, when creating a new process through the clone() system call, passing the flag CLONE_NEWNET will create a brand new network namespace in the new process.\n\n- From the user's perspective, we just need to use the tool ""ip"" (package is iproute2) to create a new persistent network namespace.\n\n<p align=""center"">\n<img\nsrc=""https://raw.githubusercontent.com/ClarenceWhite/BlogImage/main/images/6433fb71cb5aec730fd6f479-4-10-13-33-29.jpg"" id=""blog-image"" width=""400""/>\n</p>\n\n### 2.3.1 Creating a net namespace\n\n```\n# Creating a network namespace named bzy\nip netns add bzy\n```\n\n```\n# View the created network namespaces\nip netns ls\n\nbzy\n```\n\n### 2.3.2 Deleting a net namespace\n\n```\n# Delete the created network namespace\nip netns delete bzy\n```\n\n### 2.3.3 Running commands in the net namespace\n\n```\n# Execute bash command in the network namespace. Use ""exit"" to exit.\nip netns exec bzy bash\n```\n\n### 2.3.4 Viewing network connectivity (NIC) commands in the net namespace\n\n```\n# View network card information in the network namespace\nip link\n1: lo: <LOOPBACK> mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n```\n\n```\n# View in the Linux host system\nip netns exec bzy ip link list\n1: lo: <LOOPBACK> mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n```\n\n### 2.3.5 Exiting current net namespace\n\n```\n# Exit the network namespace that has been entered\nexit\n```\n\n### 2.3.6 Executing multiple commands in the net namespace\n\n```\n# View the routing table in the network namespace\nroute -n\n\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n```\n\n```\n# View firewall rules in the network namespace\niptables -t nat -nL\n\nChain PREROUTING (policy ACCEPT)\ntarget     prot opt source               destination         \n\nChain INPUT (policy ACCEPT)\ntarget     prot opt source               destination         \n\nChain OUTPUT (policy ACCEPT)\ntarget     prot opt source               destination         \n\nChain POSTROUTING (policy ACCEPT)\ntarget     prot opt source               destination\n```\n\n### 2.3.7 Creating a virtual network card\n\n>Creating a pair of virtual network cards at the same time.\n\n```\n# Create a pair of virtual network cards\nip link add veth0 type veth peer name veth1\n```\n\n```\n# View in the physical host system\nip a s\n......\n10: veth1@veth0: <BROADCAST,MULTICAST,M-DOWN> mtu 1500 qdisc noop state DOWN group default qlen 1000\n    link/ether de:44:f8:b7:12:65 brd ff:ff:ff:ff:ff:ff\n11: veth0@veth1: <BROADCAST,MULTICAST,M-DOWN> mtu 1500 qdisc noop state DOWN group default qlen 1000\n    link/ether 46:5e:89:8c:cb:b3 brd ff:ff:ff:ff:ff:ff\n```\n\n### 2.3.8 Migrating virtual network cards to a namespace\n\n> Both network cards still belong to the ""default"" or ""global"" namespace, just like physical network cards. Move one of the network cards to the bzy namespace.\n\n```\n# Add the veth1 network card that was created to the bzy network namespace\nip link set veth1 netns bzy\n```\n\n```\n# Viewing networking interfaces within the namespace in the Linux command line\nip netns exec bzy ip link\n1: lo: <LOOPBACK> mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n10: veth1@if11: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000\n    link/ether de:44:f8:b7:12:65 brd ff:ff:ff:ff:ff:ff link-netnsid 0\n```\n\n### 2.3.9 Migrating virtual network cards out of namespace\n\n```\n# Delete the veth1 virtual network card from the network namespace in the Linux system command line\nip netns exec bzy ip link delete veth1\n```\n\n```\n# View results in the Linux system command line\nip netns exec bzy ip link\n1: lo: <LOOPBACK> mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n```\n\n### 2.3.10 Configuring virtual network card IP addresses\n\n```\n# Create virtual network cards again, add to the bzy network namespace, and set IP addresses.\nip link add veth0 type veth peer name veth1\nip link set veth1 netns bzy\nip netns exec bzy ip addr add 192.168.50.2/24 dev veth1\n```\n\n```\n# Check network status in the Linux system command line\nip netns exec bzy ip addr\n1: lo: <LOOPBACK> mtu 65536 qdisc noop state DOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n12: veth1@if13: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group default qlen 1000\n    link/ether fe:20:ac:a8:13:4c brd ff:ff:ff:ff:ff:ff link-netnsid 0\n    inet 192.168.50.2/24 scope global veth1\n       valid_lft forever preferred_lft forever\n```\n\n```\n# Start the virtual network card, both veth1 and lo need to be started.\nip netns exec bzy ip link set veth1 up\n\nip netns exec bzy ip link set lo up\n```\n\n```\n# Add an IP address to the physical machine veth0\nip a s\n......\n15: veth0@if14: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group defau\nlt qlen 1000\n    link/ether 2e:b4:40:c8:73:dc brd ff:ff:ff:ff:ff:ff link-netnsid 0\n```\n\n```\nip addr add 192.168.50.3/24 dev veth0\n\nip a s veth0\n15: veth0@if14: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group default qlen 1000\n    link/ether 2e:b4:40:c8:73:dc brd ff:ff:ff:ff:ff:ff link-netnsid 0\n    inet 192.168.50.3/24 scope global veth0\n       valid_lft forever preferred_lft forever\n```\n\n\n\n```\nip link set veth0 up\n```\n\n\n\n```\n# Ping veth1 in bzy from the host machine\nping 192.168.50.2\n\nPING 192.168.50.2 (192.168.50.2) 56(84) bytes of data.\n64 bytes from 192.168.50.2: icmp_seq=1 ttl=64 time=0.102 ms\n64 bytes from 192.168.50.2: icmp_seq=2 ttl=64 time=0.068 ms\n64 bytes from 192.168.50.2: icmp_seq=3 ttl=64 time=0.068 ms\n```\n\n\n\n```\n# Ping veth0 on the host machine from veth1 in bzy\nip netns exec bzy ping 192.168.50.3\n\nPING 192.168.50.3 (192.168.50.3) 56(84) bytes of data.\n64 bytes from 192.168.50.3: icmp_seq=1 ttl=64 time=0.053 ms\n64 bytes from 192.168.50.3: icmp_seq=2 ttl=64 time=0.031 ms\n64 bytes from 192.168.50.3: icmp_seq=3 ttl=64 time=0.029 ms\n```\n\n\n\n```\n# If you need to access other networks on your computer, you can manually add the following default route entry.\nip netns exec bzy ip route add default via 192.168.50.3\n```\n\n\n\n> To be able to ping external hosts, you'll need to set up routing and forwarding.\n\n\n# 3. CGroups\n\n## 3.1 Introduction to CGroups\n\n- Control groups (cgroups) is a mechanism provided by the Linux kernel that allows limiting, tracking, and isolating the physical resources used by process groups. It was born for containers, and without cgroups, there would be no container technology today.\n\n\n<p align=""center"">\n<img src=""https://raw.githubusercontent.com/ClarenceWhite/BlogImage/main/images/6433fb71cb5aec730fd6f479-4-10-13-56-41.jpg"" id=""blog-image"" width=""400""/>\n</p>\n\n\n## 3.2 Functions of CGroups\n\n- Resource limitation: CGroups can limit the total amount of resources used by a process group. For example, setting a limit on the amount of memory an application can use during runtime, once it exceeds this quota, an OOM (Out of Memory) is issued.\n- Priority allocation: By allocating CPU time slices and hard disk IO bandwidth sizes, it actually controls the priority of process execution.\n- Resource accounting: CGroups can be used to track resource usage in the system, such as CPU usage time, memory usage, etc., which is very suitable for billing purposes.\n- Process control: CGroups can execute operations such as suspension and recovery on process groups.\n\n\n\n## 3.3 CGroups Application Case\n\n\n\n### 3.3.1 Installation and Starting Services\n\n\n\n```shell\n[root@localhost ~]# yum -y install libcgroup\n[root@localhost ~]# systemctl start cgconfig.service 	\n[root@localhost ~]# systemctl enable cgconfig.service\n```\n\n\n\n### 3.3.2 Limiting Process CPU Usage\n\n#### 3.3.2.1 View CPU shares\n\n```\nView resource control subsystems\n[root@localhost ~]# lssubsys\ncpuset\ncpu,cpuacct\nmemory\ndevices\nfreezer\nnet_cls,net_prio\nblkio\nperf_event\nhugetlb\npids\n\nView the location of the subsystem configuration files\n[root@localhost ~]# ls /sys/fs/cgroup/\nblkio  cpuacct      cpuset   freezer  memory   net_cls,net_prio  perf_event  systemd\ncpu    cpu,cpuacct  devices  hugetlb  net_cls  net_prio          pids\n[root@localhost ~]# ls /sys/fs/cgroup/cpu\ncgroup.clone_children  cpuacct.stat          cpu.cfs_quota_us   cpu.stat\ncgroup.event_control   cpuacct.usage         cpu.rt_period_us   notify_on_release\ncgroup.procs           cpuacct.usage_percpu  cpu.rt_runtime_us  release_agent\ncgroup.sane_behavior   cpu.cfs_period_us     cpu.shares         tasks\n\nView CPU time slices to ensure the total amount of CPU slices obtained by the group.\n[root@localhost ~]# cat /sys/fs/cgroup/cpu/cpu.shares\n1024\n```\n\n\n\n\n\n#### 3.3.2.2 Create 2 groups using the CPU subsystem\n\n```shell\n[root@localhost ~]# vim /etc/cgconfig.conf\ngroup lesscpu {\n	cpu{\n		cpu.shares=200;\n	}	\n}\ngroup morecpu {\n	cpu{\n		cpu.shares=800;\n	}	\n}\n\n[root@localhost ~]# systemctl restart cgconfig\n```\n\nPrepare a script\n\n```\n#!/bin/bash\n\na=1\nwhile true\ndo\n\n        a=$[$a+1]\ndone\n\n```\n\n\n\nAssign the application that will be run to the specified group (**Please use a single-CPU machine and verify with three terminals**)\n\n```shell\nTerminal 1# cgexec -g cpu:lesscpu sh /tmp/1.sh\n\nTerminal 2# cgexec -g cpu:morecpu sh /tmp/1.sh\n\nTerminal 3# top\n```\n\n\n\n**PS: If the host has multiple CPUs, for verification purposes, you can perform the following operation**\n\n```shell\n# lscpu\n# echo 0 > /sys/devices/system/cpu/cpu0/online\n# echo 1 > /sys/devices/system/cpu/cpu1/online\n```\n\n",2023-04-10T12:58:05.603Z,hide,com.baizeyu.published.model.Published
6436868d882850106f5c0bb2,How I set and reach goals (not plans) in life?,"When we talk about goals or plans, the first thing that comes to mind is usually a to-do list or an organized timetable that includes what we will be doing during a certain period of time, like the picture below:\n\n <p align=""center"">\n   <img src=""https://raw.githubusercontent.com/ClarenceWhite/BlogImage/main/images/newblog4-12-10-50-47.jpg"" id=""blog-image"" width=400/>\n </p>\n\nHowever, when you actually follow this type of table, you may end up disrupting the entire plan because you are unable to complete tasks within the designated time blocks. You might also easily become frustrated.\n\nI prefer an objective-oriented approach to setting goals in daily life. In this way, time blocks are not fixed, and everything can be flexible. At the same time, goals can be reached without a sense of urgency but achievement. Let me show you an example:\n\nInstead of saying, ""**I am going to learn English from 9-10 am today, I will sit there and read/listen to the book, and I will start exactly at 9 and end at 10, then move on to the next task**"", I would say, ""**I am going to study chapters 1&2 of the material in the next 5 days. After that, I will have a short break and can start new interesting chapters based on the ideas I learned from the first two chapters. Once I have a big time block during the day, I will move a little bit forward to complete the small goal set for the week/day**"". Of course, we can have multiple goals for a week or a month. By switching among them, we can achieve our goals without getting bored easily.\n\nTherefore, setting small goals instead of ""big plans"" is a better way to stay motivated. The goal represents desire, and setting oneself a short-term goal and focusing on achieving it is actually the pursuit of conquering and satisfying desire.",2023-04-16T09:54:51.285Z,life,com.baizeyu.published.model.Published
6436aabf882850106f5c0bb3,Docker Architecture and Deployment,"# 1. Architecture\n\n## 1.1 Docker Containers Are Everywhere\n\n<p align=""center"">\n<img src=""https://raw.githubusercontent.com/ClarenceWhite/BlogImage/main/images/newblog4-12-13-55-36.jpg"" id=""blog-image"" width=500/>\n</p>\n\n\n\n## 1.2 Architecture\n\n<p align=""center"">\n<img src=""https://raw.githubusercontent.com/ClarenceWhite/BlogImage/main/images/newblog4-12-13-56-12.jpg"" id=""blog-image"" />\n</p>\n\n\n### 1.2.1 Docker Host\n\nThe host used to install the Docker daemon is known as the Docker Host, which can run containers based on container images.\n\n\n### 1.2.2 Docker daemon\n\nIt is used to manage the containers, container images, container networks, etc. running on the Docker Host, and manages the containers provided by Containerd.io.\n\n\n\n### 1.2.3 Registry\n\nContainer image repository is used to store the generated container runtime templates. When users use it, they can directly download container images from the repository, which is the container runtime template, and then run the applications contained in the container image. For example, Docker Hub, or you can use Harbor to implement a private container image repository for enterprises.\n\n\n\n### 1.2.4 Docker client\n\nThe Docker Daemon client tool is used to communicate with the Docker Daemon, execute user commands, and can be deployed on the Docker Host or other hosts as long as it can connect to the Docker Daemon to operate.\n\n\n\n### 1.2.5 Image\n\nThe template file that packages the application runtime environment and computing resources in a way that can be reused to start a container is used primarily to launch a container based on it, and is an immutable infrastructure.\n\n\n\n### 1.2.6 Container\n\nIt is an environment for running an application that is generated from a container image. It includes all the files in the container image and any files added by the user later. It belongs to the read-write layer generated based on the container image, and it is also the active space for the application.\n\n\n\n### 1.2.7 Docker Dashboard\n\n> Only available for Mac and Windows\n\nDocker Dashboard provides a simple interface that allows you to manage your containers, applications, and images directly from your machine without using the CLI to perform core operations.\n\n<p align=""center"">\n<img src=""https://raw.githubusercontent.com/ClarenceWhite/BlogImage/main/images/newblog4-12-13-57-5.jpg"" id=""blog-image"" />\n</p>\n\n\n\n## 1.3 Docker Versions\n\n- Docker-ce is the community edition of Docker, primarily used for personal developer testing and is a free version.\n- Docker-ee is the enterprise edition of Docker, primarily used for enterprise development and application deployment and is a paid version. It offers a free trial period of one month.\n\n\n\n# 2. Docker Installation\n\n> We are going to use Ubuntu server, so just follow the official doc!\n\n[Click here to go to the official installation guide](https://docs.docker.com/engine/install/), just select the doc that suits your operating system in sidebar.\n\n\n\n",2023-04-12T18:15:04.988Z,hide,com.baizeyu.published.model.Published
6437e29b882850106f5c0bb4,Use Container to run Nginx and Docker commands,"# 1. Use docker to run Nginx\n\n## 1.1 Use 'docker run' to run Nginx\n\n### 1.1.1 Inpect the process of downloading the image\n\n> Loking for the image locally\n\n```\n# docker run -d nginx:latest\n\nUnable to find image 'nginx:latest' locally\nlatest: Pulling from library/nginx\na2abf6c4d29d: Downloading  1.966MB/31.36MB \na9edb18cadd1: Downloading  1.572MB/25.35MB\n589b7251471a: Download complete \n186b1aaa4aa6: Download complete\nb4df32aa5a72: Waiting\na0bcbecc962e: Waiting\n```\n\n\n\n### 1.1.2 Check the running status of containers\n\n```\n# docker run -d nginx:latest\n\n9834c8c18a7c7c89ab0ea4119d11bafe9c18313c8006bc02ce57ff54d9a1cc0c\n```\n\n\n```\n# Command explanation \ndocker run (start a container based on a image)\n-d (execute the commands in the image by daemon way)\nnginx (the name of the image)\nlatest (tag/version of the image)\n```\n\n\n\n```\n# docker ps\nCONTAINER ID   IMAGE        COMMAND                  CREATED          STATUS        PORTS     NAMES\n9834c8c18a7c   nginx:latest ""/docker-entrypoint.…""   24 seconds ago   Up 23 seconds 80/tcp condescending_pare\n```\n\n\n\n```\ndocker ps is like 'ps' in linux, used to check all running containers\n```\n\n\n\n**docker ps outputs**\n\n| CONTAINERID  | IMAGE        | COMMAND                | CREATED        | STATUS        | PORTS  | NAMES              |\n| ------------ | ------------ | ---------------------- | -------------- | ------------- | ------ | ------------------ |\n| 9834c8c18a7c | nginx:latest | ""/docker-entrypoint.…"" | 24 seconds ago | Up 23 seconds | 80/tcp | condescending_pare |\n\n\n\n## 1.2 Access to the service running in the container\n\n### 1.2.1 Get container's ip address\n\n> Don't have to do this in production\n\n```\n # docker inspect 9834\n \n ""GlobalIPv6Address"": """",\n            ""GlobalIPv6PrefixLen"": 0,\n            ""IPAddress"": ""172.17.0.2"", 容器IP地址\n            ""IPPrefixLen"": 16,\n            ""IPv6Gateway"": """",\n            ""MacAddress"": ""02:42:ac:11:00:02"",\n            ""Networks"": {\n                ""bridge"": {\n                    ""IPAMConfig"": null,\n                    ""Links"": null,\n                    ""Aliases"": null,\n                    ""NetworkID"": ""d3de2fdbc30ee36a55c1431ef3ae4578392e552009f00b2019b4720735fe5a60"",\n                    ""EndpointID"": ""d91f47c9f756ff22dc599a207164f2e9366bd0c530882ce0f08ae2278fb3d50c"",\n                    ""Gateway"": ""172.17.0.1"",\n                    ""IPAddress"": ""172.17.0.2"",  (here)\n                    ""IPPrefixLen"": 16,\n                    ""IPv6Gateway"": """",\n                    ""GlobalIPv6Address"": """",\n                    ""GlobalIPv6PrefixLen"": 0,\n                    ""MacAddress"": ""02:42:ac:11:00:02"",\n                    ""DriverOpts"": null\n                }\n            }\n        }\n    }\n]\n```\n\n\n\n```\n命令解释\ndocker inspect is used to check containers  information\n9834 is the first 4 digits of the container id, we can use a short id sequence to find a container, don't have to copy the whole id\n```\n\n\n\n### 1.2.2 Network in container\n\n<p align=""center"">\n<img src=""https://raw.githubusercontent.com/ClarenceWhite/BlogImage/main/images/newblog4-13-12-6-29.jpg"" id=""blog-image"" width=500/>\n</p>\n\n\n```\n# ip a s\n......\ndocker0 is the default bridge network that Docker creates when it is installed. It is a virtual bridge that allows Docker containers to communicate with each other and with the host system, as well as providing connectivity to external networks through the host's network interface. By default, all Docker containers are attached to the docker0 bridge unless otherwise specified. The IP address range for docker0 is 172.17.0.0/16.\n\n5: docker0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default\n    link/ether 02:42:d5:c3:d4:cc brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::42:d5ff:fec3:d4cc/64 scope link\n       valid_lft forever preferred_lft forever\n       \n       \n# It is used to connect the network of a container to the host system, and is located in the same namespace as the virtual networking devices within the container.\n\n9: veth393dece@if8: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master docker0 state UP group default\n    link/ether 02:e3:11:58:54:0f brd ff:ff:ff:ff:ff:ff link-netnsid 0\n    inet6 fe80::e3:11ff:fe58:540f/64 scope link\n       valid_lft forever preferred_lft forever\n```\n\n\n\n### 1.2.3 Use `curl` to access\n\n```\n# curl http://172.17.0.2\n\n<!DOCTYPE html>\n<html>\n<head>\n<title>Welcome to nginx!</title>\n<style>\nhtml { color-scheme: light dark; }\nbody { width: 35em; margin: 0 auto;\nfont-family: Tahoma, Verdana, Arial, sans-serif; }\n</style>\n</head>\n<body>\n<h1>Welcome to nginx!</h1>\n<p>If you see this page, the nginx web server is successfully installed and\nworking. Further configuration is required.</p>\n\n<p>For online documentation and support please refer to\n<a href=""http://nginx.org/"">nginx.org</a>.<br/>\nCommercial support is available at\n<a href=""http://nginx.com/"">nginx.com</a>.</p>\n\n<p><em>Thank you for using nginx.</em></p>\n</body>\n</html>\n```\n\n\n\n# 2. Docker commands\n\n## 2.1 Get help with docker commands\n\n\n\n```\n# docker -h\nFlag shorthand -h has been deprecated, please use --help\n\nUsage:  docker [OPTIONS] COMMAND\n\nA self-sufficient runtime for containers\n\nOptions:\n      --config string      Location of client config files (default ""/root/.docker"")\n  -c, --context string     Name of the context to use to connect to the daemon (overrides\n                           DOCKER_HOST env var and default context set with ""docker context use"")\n  -D, --debug              Enable debug mode\n  -H, --host list          Daemon socket(s) to connect to\n  -l, --log-level string   Set the logging level (""debug""|""info""|""warn""|""error""|""fatal"")\n                           (default ""info"")\n      --tls                Use TLS; implied by --tlsverify\n      --tlscacert string   Trust certs signed only by this CA (default ""/root/.docker/ca.pem"")\n      --tlscert string     Path to TLS certificate file (default ""/root/.docker/cert.pem"")\n      --tlskey string      Path to TLS key file (default ""/root/.docker/key.pem"")\n      --tlsverify          Use TLS and verify the remote\n  -v, --version            Print version information and quit\n\nManagement Commands: \n  app*        Docker App (Docker Inc., v0.9.1-beta3)\n  builder     Manage builds\n  buildx*     Docker Buildx (Docker Inc., v0.7.1-docker)\n  config      Manage Docker configs\n  container   Manage containers\n  context     Manage contexts\n  image       Manage images\n  manifest    Manage Docker image manifests and manifest lists\n  network     Manage networks\n  node        Manage Swarm nodes\n  plugin      Manage plugins\n  scan*       Docker Scan (Docker Inc., v0.12.0)\n  secret      Manage Docker secrets\n  service     Manage services\n  stack       Manage Docker stacks\n  swarm       Manage Swarm\n  system      Manage Docker\n  trust       Manage trust on Docker images\n  volume      Manage volumes\n\nCommands:\n  attach      Attach local standard input, output, and error streams to a running container\n  build       Build an image from a Dockerfile\n  commit      Create a new image from a container's changes\n  cp          Copy files/folders between a container and the local filesystem\n  create      Create a new container\n  diff        Inspect changes to files or directories on a container's filesystem\n  events      Get real time events from the server\n  exec        Run a command in a running container\n  export      Export a container's filesystem as a tar archive\n  history     Show the history of an image\n  images      List images\n  import      Import the contents from a tarball to create a filesystem image\n  info        Display system-wide information\n  inspect     Return low-level information on Docker objects\n  kill        Kill one or more running containers\n  load        Load an image from a tar archive or STDIN\n  login       Log in to a Docker registry\n  logout      Log out from a Docker registry\n  logs        Fetch the logs of a container\n  pause       Pause all processes within one or more containers\n  port        List port mappings or a specific mapping for the container\n  ps          List containers\n  pull        Pull an image or a repository from a registry\n  push        Push an image or a repository to a registry\n  rename      Rename a container\n  restart     Restart one or more containers\n  rm          Remove one or more containers\n  rmi         Remove one or more images\n  run         Run a command in a new container\n  save        Save one or more images to a tar archive (streamed to STDOUT by default)\n  search      Search the Docker Hub for images\n  start       Start one or more stopped containers\n  stats       Display a live stream of container(s) resource usage statistics\n  stop        Stop one or more running containers\n  tag         Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE\n  top         Display the running processes of a container\n  unpause     Unpause all processes within one or more containers\n  update      Update configuration of one or more containers\n  version     Show the Docker version information\n  wait        Block until one or more containers stop, then print their exit codes\n```\n\n\n\n## 2.2 Official docs on commands\n\nhttps://docs.docker.com/reference/\n\n\n\n## 2.3 Docker commands usage\n\n### 2.3.1 docker run\n\n\n```\n# docker run -i -t --name c1 centos:latest bash\n[root@948f234e22a1 /]#\n```\n\n\n\n```\ndocker run: When running a command in a container, the command is the main process. If there is no command, the container will exit immediately.\n-i: interactive\n-t: terminal\n--name: name the container to c1\ncentos:latest: use the latest centos image\nbash: execute bash command in container\n```\n\n\n\n```\nthis is the host name:\n[root@948f234e22a1 /]#\n```\n\n\n\n```\ncheck network info in container\n[root@948f234e22a1 /]# ip a s\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n12: eth0@if13: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default\n    link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff link-netnsid 0\n    inet 172.17.0.3/16 brd 172.17.255.255 scope global eth0\n       valid_lft forever preferred_lft forever\n```\n\n\n\n```\ncheck processes in container\n[root@948f234e22a1 /]# ps aux\nUSER        PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\nroot          1  0.0  0.1  12036  2172 pts/0    Ss   09:58   0:00 bash\nroot         16  0.0  0.0  44652  1784 pts/0    R+   10:02   0:00 ps aux\n```\n\n\n\n```\ncheck user info in the container:\n[root@948f234e22a1 /]# cat /etc/passwd\nroot:x:0:0:root:/root:/bin/bash\nbin:x:1:1:bin:/bin:/sbin/nologin\ndaemon:x:2:2:daemon:/sbin:/sbin/nologin\nadm:x:3:4:adm:/var/adm:/sbin/nologin\nlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\nsync:x:5:0:sync:/sbin:/bin/sync\nshutdown:x:6:0:shutdown:/sbin:/sbin/shutdown\nhalt:x:7:0:halt:/sbin:/sbin/halt\nmail:x:8:12:mail:/var/spool/mail:/sbin/nologin\noperator:x:11:0:operator:/root:/sbin/nologin\ngames:x:12:100:games:/usr/games:/sbin/nologin\nftp:x:14:50:FTP User:/var/ftp:/sbin/nologin\nnobody:x:65534:65534:Kernel Overflow User:/:/sbin/nologin\ndbus:x:81:81:System message bus:/:/sbin/nologin\nsystemd-coredump:x:999:997:systemd Core Dumper:/:/sbin/nologin\nsystemd-resolve:x:193:193:systemd Resolver:/:/sbin/nologin\n```\n\n\n\n```\ncheck directory:\n[root@948f234e22a1 /]# pwd\n/\n[root@948f234e22a1 /]# ls\nbin  etc   lib    lost+found  mnt  proc  run   srv  tmp  var\ndev  home  lib64  media       opt  root  sbin  sys  usr\n```\n\n\n\n```\nexit the container:\n[root@948f234e22a1 /]# exit\nexit\n[root@localhost ~]#\n```\n\n\n\n### 2.3.2 docker ps\n\n\n\n```\n# docker ps\nCONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n```\n\n\n\n```\n# docker ps -a\nCONTAINER ID   IMAGE           COMMAND     CREATED             STATUS                         PORTS     NAMES\n948f234e22a1   centos:latest   ""bash""    10 minutes ago      Exited (0) 2 minutes ago                    c1\n```\n\n\n\n| CONTAINERID  | IMAGE         | COMMAND | CREATED        | STATUS                   | PORTS | NAMES |\n| ------------ | ------------- | ------- | -------------- | ------------------------ | ----- | ----- |\n| 948f234e22a1 | centos:latest | ""bash""  | 10 minutes ago | Exited (0) 2 minutes ago |       | c1    |\n\n\n\n```\ndocker ps -a: check all containers including running and stopped\n```\n\n\n\n### 2.3.3 docker inspect\n\n\n\n```\n# docker run -it --name c2 centos:latest bash\n[root@9f2eea16da4c /]# \n```\n\n\n\n```\nnote:\nuse ctrl p+q can exit without terminate the container.\n```\n\n\n\n```\n# docker inspect c2\n\n""Networks"": {\n                ""bridge"": {\n                    ""IPAMConfig"": null,\n                    ""Links"": null,\n                    ""Aliases"": null,\n                    ""NetworkID"": ""d3de2fdbc30ee36a55c1431ef3ae4578392e552009f00b2019b4720735fe5a60"",\n                    ""EndpointID"": ""d1a2b7609f2f73a6cac67229a4395eef293f695c0ac4fd6c9c9e6913c9c85c1c"",\n                    ""Gateway"": ""172.17.0.1"",\n                    ""IPAddress"": ""172.17.0.2"",\n                    ""IPPrefixLen"": 16,\n                    ""IPv6Gateway"": """",\n                    ""GlobalIPv6Address"": """",\n                    ""GlobalIPv6PrefixLen"": 0,\n                    ""MacAddress"": ""02:42:ac:11:00:02"",\n                    ""DriverOpts"": null\n                }\n            }\n        }\n    }\n]\n\n```\n\n\n\n\n\n### 2.3.4 docker  exec \n\n\n\n```\n# docker exec -it c2 ls /root\nanaconda-ks.cfg  anaconda-post.log  original-ks.cfg\n```\n\n\n\n```\ndocker exec: execute a command outside the container\n-it: interactive terminal\n```\n\n\n\n\n### 2.3.5 docker attach\n\n\n\n```\n[root@localhost ~]# docker attach c2\n[root@9f2eea16da4c /]#\n```\n\n\n\n```\ndocker attach is like ssh, allow us to enter in to the container\n```\n\n\n\n```\nWhen using `docker attach` to exit a container, if you do not need the container to continue running, you can simply use the `exit` command to terminate the container. However, if you want to keep the container running in the background, you can detach from it without stopping it by pressing `Ctrl + P` followed by `Ctrl + Q`. This will return you to the host shell without terminating the container.\n```\n\n\n\n### 2.3.6 docker stop\n\n\n\n```\n# docker ps\nCONTAINER ID   IMAGE           COMMAND   CREATED          STATUS          PORTS     NAMES\n9f2eea16da4c   centos:latest   ""bash""    22 minutes ago   Up 22 minutes             c2\n```\n\n\n\n```\n# docker stop 9f2eea\n9f2eea\n```\n\n\n\n```\n# docker ps -a\nCONTAINER ID   IMAGE           COMMAND                  CREATED          STATUS                       PORTS     NAMES\n9f2eea16da4c   centos:latest   ""bash""                   22 minutes ago   Exited (137) 4 seconds ago             c2\n```\n\n\n\n\n\n### 2.3.7 docker start\n\n\n\n```\n# docker ps -a\nCONTAINER ID   IMAGE           COMMAND     CREATED          STATUS                       PORTS     NAMES\n9f2eea16da4c   centos:latest   ""bash""      22 minutes ago   Exited (137) 4 seconds ago              c2\n```\n\n\n\n```\n# docker start 9f2eea\n9f2eea\n```\n\n\n\n```\n# docker ps\nCONTAINER ID   IMAGE           COMMAND   CREATED          STATUS          PORTS     NAMES\n9f2eea16da4c   centos:latest   ""bash""    24 minutes ago   Up 16 seconds             c2\n```\n\n\n\n\n\n### 2.3.8  docker top\n\n> in Docker Host, check processes in the container\n\n```\n# docker top c2\nUID    PID     PPID      C      STIME        TTY              TIME                CMD\nroot  69040   69020      0      18:37       pts/0           00:00:00              bash\n```\n\n\n\n| UID  | PID   | PPID  | C    | STIME | TTY   | TIME     | CMD  |\n| ---- | ----- | ----- | ---- | ----- | ----- | -------- | ---- |\n| root | 69040 | 69020 | 0    | 18:37 | pts/0 | 00:00:00 | bash |\n\n\n\nThe `docker top` command is used to view information about the processes running in a container from the Docker host's perspective. It allows you to see the list of processes that are running inside the container along with their process IDs (PIDs), and resource utilization statistics such as CPU and memory usage.\n\nOn the other hand, `docker exec -it c2 ps -ef` command is used to run the `ps -ef` command inside the container with ID or name `c2`. This command allows you to view the processes running inside the container from within the container itself, rather than from the Docker host's perspective.\n\n\n\n```\nOutputs explanation:\nUID: user id in container\nPID: process id in container\nPPID: parent process id\nC: CPU\nSTIME: start time\nTTY: terminal\nTIME: running time\nCMD: executed command\n```\n\n\n\n### 2.3.9 docker rm\n\n> If the container is stopped, use this command to delete it directly; if the container is running, you need to shut down the container in advance before deleting the container. The following demonstrates the method of deleting after the container is running and shutting down.\n\n\n#### 2.3.9.1 Specify the container ot be removed\n\n\n\n```\n# docker ps\nCONTAINER ID   IMAGE           COMMAND   CREATED      STATUS         PORTS     NAMES\n9f2eea16da4c   centos:latest   ""bash""    2 days ago   Up 3 seconds             c2\n```\n\n\n\n```\n# docker stop c2\nor\n# docker stop 9f2eea16da4c\n```\n\n\n\n```\n# docker rm c2\nor\n# docker rm 9f2eea16da4c\n```\n\n\n\n#### 2.3.9.2 batch deletion\n\n\n\n```\n# docker ps -a\nCONTAINER ID   IMAGE           COMMAND          CREATED      STATUS                  PORTS    NAMES\n948f234e22a1   centos:latest   ""bash""           2 days ago   Exited (0) 2 days ago            c1\n01cb3e01273c   centos:latest   ""bash""           2 days ago   Exited (0) 2 days ago            systemimage1\n46d950fdfb33   nginx:latest    ""/docker-ent..."" 2 days ago   Exited (0) 2 days ago            upbeat_goldberg\n```\n\n\n\n```\n# docker ps --a | awk '{if (NR>=2){print $1}}' | xargs docker rm\n```",2023-04-13T11:08:07.169Z,hide,com.baizeyu.published.model.Published
64398524882850106f5c0bb5,Introduction to Docker Image,"# 1. Operations on Docker images\n\n## 1.1 Check local images\n\n### 1.1.1 Use `docker images` command\n\n```\n# docker images\nREPOSITORY   TAG       IMAGE ID       CREATED        SIZE\nbash         latest    5557e073f11c   2 weeks ago    13MB\nnginx        latest    605c77e624dd   3 weeks ago    141MB\ncentos       latest    5d0da3dc9764   4 months ago   231MB\n```\n\n\n\n### 1.1.2 Use `docker image` command\n\n```\n# docker image list (or ls)\nREPOSITORY   TAG       IMAGE ID       CREATED        SIZE\nbash         latest    5557e073f11c   2 weeks ago    13MB\nnginx        latest    605c77e624dd   3 weeks ago    141MB\ncentos       latest    5d0da3dc9764   4 months ago   231MB\n```\n\n\n\n### 1.1.3 Find the location of docker image locally\n\n> Considering that Docker container images can take up local storage space, it is recommended to set up other storage systems and mount them locally to solve the problem of consuming a large amount of local storage.\n\n\n\n```\n# ls /var/lib/docker\nbuildkit  containers  image  network  overlay2  plugins  runtimes  swarm  tmp  trust  volumes\n```\n\n\n\n\n\n## 1.2 Search for images on Docker Hub\n\n### 1.2.1 Command line searching\n\n\n\n```\n# docker search centos\n```\n\n\n\n```\n# Outputs\nNAME                              DESCRIPTION                                     STARS     OFFICIAL   AUTOMATED\ncentos                            The official build of CentOS.                   6987      [OK]\nansible/centos7-ansible           Ansible on Centos7                              135                  [OK]\nconsol/centos-xfce-vnc            Centos container with ""headless"" VNC session…   135                  [OK]\njdeathe/centos-ssh                OpenSSH / Supervisor / EPEL/IUS/SCL Repos - …   121                  [OK]\n```\n\n\n\n\n\n### 1.2.2 Docker Hub Website\nJust go to this website and search for the image you want: https://hub.docker.com/.\n\n\n\n## 1.3 Pull images\n\n```\n# docker pull centos\n```\n\n\n\n## 1.4 Remove images\n\n\n\n```\n# docker images\nREPOSITORY   TAG       IMAGE ID       CREATED        SIZE\nbash         latest    5557e073f11c   2 weeks ago    13MB\nnginx        latest    605c77e624dd   3 weeks ago    141MB\ncentos       latest    5d0da3dc9764   4 months ago   231MB\n```\n\n\n\n```\n# docker rmi centos\nUntagged: centos:latest\nUntagged: centos@sha256:a27fd8080b517143cbbbab9dfb7c8571c40d67d534bbdee55bd6c473f432b177\nDeleted: sha256:5d0da3dc976460b72c77d94c8a1ad043720b0416bfc16c52c45d4847e53fadb6\nDeleted: sha256:74ddd0ec08fa43d09f32636ba91a0a3053b02cb4627c35051aff89f853606b59\n```\n\nor\n\n```\n# docker images\nREPOSITORY   TAG       IMAGE ID       CREATED        SIZE\ncentos       latest    5d0da3dc9764   4 months ago   231MB\n```\n\n\n\n```\n# docker rmi 5d0da3dc9764\n```\n\n\n\n\n\n# 2. Introduction to Docker image\n\n## 2.1 Docker Image\n\n- Docker images are read-only container templates and are the foundation of Docker containers.\n- They provide a static file system runtime environment (rootfs) for Docker containers.\n- Docker images represent the static state of a container.\n- Containers represent the running state of a Docker image.\n\n\n\n## 2.2 Union Filesystem\n\n### 2.2.1 Definition\n\n- Union File System is a file system that implements union mount technology.\n- Union mount technology allows multiple file systems to be mounted at the same mount point, integrating the original directory of the mount point with the mounted content, so that the resulting visible file system contains the layered files and directories after integration.\n\n\n\n### 2.2.2 Architecture\n\n\n\n<p align=""center"">\n<img src=""https://raw.githubusercontent.com/ClarenceWhite/BlogImage/main/images/newblog4-14-17-49-58.jpg"" id=""blog-image"" />\n</p>\n\n\n\n\n## 2.3 Docker Overlay2\n\nThere are several ways to implement storage drivers for container file systems, including aufs, devicemapper, overlay, and overlay2. In this case, we will use overlay2 as an example for explanation.\n\n### 2.3.1 Concepts\n\n- Registry/Repository: The registry is a collection of repositories, and a repository is a collection of images.\n- Image: An image is metadata that stores information related to the image, including its architecture, default configuration information, container configuration information, and more. It is a ""logical"" concept and does not correspond to a physical image file.\n- Layer: A layer (image layer) makes up the image, and a single layer can be shared by multiple images.\n\n\n\n<p align=""center"">\n<img src=""https://raw.githubusercontent.com/ClarenceWhite/BlogImage/main/images/newblog4-14-17-51-33.jpg"" id=""blog-image"" />\n</p>\n\n\n\n\n\n### 2.3.2 Check the storage driver of the Docker Host\n\n\n\n```\n# docker info | grep overlay\n Storage Driver: overlay2\n```\n\n\n\n\n\n### 2.3.3 Layers of images\n\n\n\n```\n# docker pull nginx\nUsing default tag: latest\nlatest: Pulling from library/nginx\na2abf6c4d29d: Pull complete\na9edb18cadd1: Pull complete\n589b7251471a: Pull complete\n186b1aaa4aa6: Pull complete\nb4df32aa5a72: Pull complete\na0bcbecc962e: Pull complete\nDigest: sha256:0d17b565c37bcbd895e9d92315a05c1c3c9a29f762b011a10c54a66cd53c9b31\nStatus: Downloaded newer image for nginx:latest\ndocker.io/library/nginx:latest\n```\n\n\n\nWe can see that the downloaded image consists of 6 layers. How to find out where these 6 layers are stored on the Docker Host?\n\nFirstly, check Nginx image:\n\n```\n# docker images\nREPOSITORY   TAG       IMAGE ID       CREATED        SIZE\nnginx        latest    605c77e624dd   3 weeks ago    141MB\n```\n\n\n\nWe can find the storage location via the Image ID 605c77e624dd:\n\n\n\n```\n# ls /var/lib/docker/image/overlay2/\ndistribution  imagedb  layerdb  repositories.json\n```\n\nThis directory is the entry point for the search and is very important. It stores the metadata for image management.\n\n- repositories.json: records the mapping between repo and image ID.\n- imagedb: It records the architecture of the image, the operating system, the container ID and configuration used to build the image, and the rootfs information.\n- layerdb: Records the metadata of each layer.\n\n\n\nFind the long ID of the image nginx by looking up the repositories.json file using its short ID, and then use the long ID to locate the metadata of this image in the imagedb:\n\n\n```\n# cat /var/lib/docker/image/overlay2/repositories.json | grep 605c77e624dd\n{""Repositories"":""nginx"":{""nginx:latest"":""sha256:605c77e624ddb75e6110f997c58876baa13f8754486b461117934b24a9dc3a85"",""nginx@sha256:0d17b565c37bcbd895e9d92315a05c1c3c9a29f762b011a10c54a66cd53c9b31"":""sha256:605c77e624ddb75e6110f997c58876baa13f8754486b461117934b24a9dc3a85""}}}}\n```\n\n\n\n```\n# cat /var/lib/docker/image/overlay2/imagedb/content/sha256/605c77e624ddb75e6110f997c58876baa13f8754486b461117934b24a9dc3a85\n......\n""os"":""linux"",""rootfs"":{""type"":""layers"",""diff_ids"":[""sha256:2edcec3590a4ec7f40cf0743c15d78fb39d8326bc029073b41ef9727da6c851f"",""sha256:e379e8aedd4d72bb4c529a4ca07a4e4d230b5a1d3f7a61bc80179e8f02421ad8"",""sha256:b8d6e692a25e11b0d32c5c3dd544b71b1085ddc1fddad08e68cbd7fda7f70221"",""sha256:f1db227348d0a5e0b99b15a096d930d1a69db7474a1847acbc31f05e4ef8df8c"",""sha256:32ce5f6a5106cc637d09a98289782edf47c32cb082dc475dd47cbf19a4f866da"",""sha256:d874fd2bc83bb3322b566df739681fbd2248c58d3369cb25908d68e7ed6040a6""]}}\n```\n\n\n\nHere we keep only the metadata we want, which is `rootfs`. In `rootfs`, we can see that there are 6 layers in the `layers` directory, which correspond to the 6 image layers of the Docker image. These layers are mapped from bottom to top in the container. Having found the 6 layers of the image, the next question is where the file contents of each layer are located.\n\nThe `layerdb` metadata will provide us with the information we need. By using the base layer diff ID`2edcec3590a4ec7f40cf0743c15d78fb39d8326bc029073b41ef9727da6c851f`, we can find the `cache_id` of the bottom layer image. By using this `cache_id`, we can find the file contents of the image layer.\n\n\n\n```\n# ls /var/lib/docker/image/overlay2/layerdb/sha256/2edcec3590a4ec7f40cf0743c15d78fb39d8326bc029073b41ef9727da6c851f\ncache-id  diff  size  tar-split.json.gz\n```\n\n\n\n```\n# cat /var/lib/docker/image/overlay2/layerdb/sha256/2edcec3590a4ec7f40cf0743c15d78fb39d8326bc029073b41ef9727da6c851f/cache-id\n85c4c5ecdac6c0d197f899dac227b9d493911a9a5820eac501bb5e9ae361f4c7\n```\n\n\n\n```\n# cat /var/lib/docker/image/overlay2/layerdb/sha256/2edcec3590a4ec7f40cf0743c15d78fb39d8326bc029073b41ef9727da6c851f/diff\nsha256:2edcec3590a4ec7f40cf0743c15d78fb39d8326bc029073b41ef9727da6c851f\n```\n\n\n\nUse cacheID to check the content of the file\n\n\n\n```\n# ls /var/lib/docker/overlay2/85c4c5ecdac6c0d197f899dac227b9d493911a9a5820eac501bb5e9ae361f4c7\ncommitted  diff  link\n# ls /var/lib/docker/overlay2/85c4c5ecdac6c0d197f899dac227b9d493911a9a5820eac501bb5e9ae361f4c7/diff\nbin   dev  home  lib64  mnt  proc  run   srv  tmp  var\nboot  etc  lib   media  opt  root  sbin  sys  usr\n```\n\n\n\nIn the example above, the image metadata and image layer contents are stored separately. Therefore, by using the `cache_id`, we need to find the image layer contents in the `/var/lib/docker/overlay2` directory. The contents exist in the `diff` directory, where the `link` file stores the short ID corresponding to the image layer. We will see its usage later on.\n\n\n\nAfter finding the bottom layer of the image, we can proceed to look for the ""middle layers"" of the image. We found out that there is no image layer with diff ID `e379e8aedd4d72bb4c529a4ca07a4e4d230b5a1d3f7a61bc80179e8f02421ad8` in the `layerdb` directory.\n\n\n\n```\n# ls /var/lib/docker/image/overlay2/layerdb/sha256/e379e8aedd4d72bb4c529a4ca07a4e4d230b5a1d3f7a61bc80179e8f02421ad8\nls: error /var/lib/docker/image/overlay2/layerdb/sha256/e379e8aedd4d72bb4c529a4ca07a4e4d230b5a1d3f7a61bc80179e8f02421ad8: no such directory\n```\n\n\n\nThis is because Docker introduced a content-addressable mechanism, which indexes images and image layers based on their file contents. Docker uses the `diff_id` in the `rootfs` to calculate the content-addressable `chainID`. By using this `chainID`, layer information can be obtained, and ultimately the content of the image layer file can be indexed.\n\nFor the bottom layer of the image, its diff_id is also the chainID. Therefore, we can find the file contents of this layer. For layers other than the bottom layer, the chainID is calculated using the formula chainID(n) = SHA256(chain(n-1) + diffID(n)).\n\n\n\n```\n# echo -n ""sha256:2edcec3590a4ec7f40cf0743c15d78fb39d8326bc029073b41ef9727da6c851f sha256:e379e8aedd4d72bb4c529a4ca07a4e4d230b5a1d3f7a61bc80179e8f02421ad8"" | sha256sum -\n780238f18c540007376dd5e904f583896a69fe620876cabc06977a3af4ba4fb5  -\n```\n\n\n\nFind files contents based on the ""middle layer"" `chainID`:\n\n```\n# ls /var/lib/docker/image/overlay2/layerdb/sha256/780238f18c540007376dd5e904f583896a69fe620876cabc06977a3af4ba4fb5\ncache-id  diff  parent  size  tar-split.json.gz\n```\n\n\n\n\n\n```\n# cat /var/lib/docker/image/overlay2/layerdb/sha256/780238f18c540007376dd5e904f583896a69fe620876cabc06977a3af4ba4fb5/cache-id\n57e1f1b11e26f748161b7fccbf2ba6b24c2f98dc8a821729f0be215ad267498c\n```\n\n\n\n\n\n```\n# cat /var/lib/docker/image/overlay2/layerdb/sha256/780238f18c540007376dd5e904f583896a69fe620876cabc06977a3af4ba4fb5/diff\nsha256:e379e8aedd4d72bb4c529a4ca07a4e4d230b5a1d3f7a61bc80179e8f02421ad8\n```\n\n\n\n```\n# cat /var/lib/docker/image/overlay2/layerdb/sha256/780238f18c540007376dd5e904f583896a69fe620876cabc06977a3af4ba4fb5/parent\nsha256:2edcec3590a4ec7f40cf0743c15d78fb39d8326bc029073b41ef9727da6c851f\n```\n\n\n\n```\nContent of the image layer:\n# ls /var/lib/docker/overlay2/57e1f1b11e26f748161b7fccbf2ba6b24c2f98dc8a821729f0be215ad267498c\ncommitted  diff  link  lower  work\n# ls /var/lib/docker/overlay2/57e1f1b11e26f748161b7fccbf2ba6b24c2f98dc8a821729f0be215ad267498c/diff/\ndocker-entrypoint.d  etc  lib  tmp  usr  var\n```\n\n\n\n\n\n```\nshort id:\n# cat /var/lib/docker/overlay2/57e1f1b11e26f748161b7fccbf2ba6b24c2f98dc8a821729f0be215ad267498c/link\n24GM2IZVPTUROAG7AWJO5ZWE6B\n```\n\n\n\n\n\n```\nparent image layer short id:\n# cat /var/lib/docker/overlay2/57e1f1b11e26f748161b7fccbf2ba6b24c2f98dc8a821729f0be215ad267498c/lower\nl/SICZO4QNVZEVOIJ4HDXVDKNYA2\n```\n\n\n\nOnce the file contents for the bottom layer and middle layers are found, it becomes easy to locate the file contents for the top layer.\n\n\n\n## 2.4 Docker container and image\n\n\n\nUse `docker run` to start an Nginx container\n\n\n\n```\n# docker run -d nginx:latest\n3272831107a3499afe8160b0cd423e2ac4223522f1995b7be3504a1d3d272878\n# docker ps | grep nginx\n3272831107a3   nginx:latest   ""/docker-entrypoint.…""   11 seconds ago   Up 9 seconds   80/tcp    angry_beaver\n```\n\n\n\n```\n# mount | grep overlay\noverlay on /var/lib/docker/overlay2/b3f5c8b42ac055c715216e376cfe44571f618a876f481533ec1434aa0bc4f8ed/merged type overlay (rw,relatime,seclabel,lowerdir=/var/lib/docker/overlay2/l/MS2X66BYF6UZ7EKUWMZJKCF4HO:/var/lib/docker/overlay2/l/ODJROQUGY3WQMOGQ3BLYZGIAG4:/var/lib/docker/overlay2/l/Q5LOBFJRH5M7M5CMSWW5L4VYOY:/var/lib/docker/overlay2/l/ZR35FN2E3WEARZV4HLRU373FT7:/var/lib/docker/overlay2/l/NSM2PTAT6TIT2H6G3HFNGZJH5N:/var/lib/docker/overlay2/l/24GM2IZVPTUROAG7AWJO5ZWE6B:/var/lib/docker/overlay2/l/SICZO4QNVZEVOIJ4HDXVDKNYA2,upperdir=/var/lib/docker/overlay2/b3f5c8b42ac055c715216e376cfe44571f618a876f481533ec1434aa0bc4f8ed/diff,workdir=/var/lib/docker/overla 2/b3f5c8b42ac055c715216e376cfe44571f618a876f481533ec1434aa0bc4f8ed/work)\n```\n\n\n\nWe can see that a union file system called overlay is mounted into the container when it starts. This file system is composed of three layers:\n\n- `lowerdir`: the read-only layer, which corresponds to the image's image layer\n- `upperdir`: the read-write layer, which is the container's read-write layer and reflects all read/write operations in the container.\n- `workdir`: an internal layer of overlayfs used to implement the copy_up operation from the read-only layer to the read-write layer.\n- `merge`: The directory that is mounted as a unified view inside the container.\n\n\n\nWhat needs to be emphasized here is the read-only layer of the lowerdir image of the container. View the short ID of the read-only layer:\n\n\n\n```\nlowerdir=/var/lib/docker/overlay2/l/MS2X66BYF6UZ7EKUWMZJKCF4HO\n/var/lib/docker/overlay2/l/ODJROQUGY3WQMOGQ3BLYZGIAG4\n/var/lib/docker/overlay2/l/Q5LOBFJRH5M7M5CMSWW5L4VYOY\n/var/lib/docker/overlay2/l/ZR35FN2E3WEARZV4HLRU373FT7\n/var/lib/docker/overlay2/l/NSM2PTAT6TIT2H6G3HFNGZJH5N\n/var/lib/docker/overlay2/l/24GM2IZVPTUROAG7AWJO5ZWE6B\n/var/lib/docker/overlay2/l/SICZO4QNVZEVOIJ4HDXVDKNYA2\n```\n\n\n\nThere are only 6 layers in the mirror layer, but there are 7 short IDs here?\nIn the /var/lib/docker/overlay2/l directory we found the answer:\n\n\n\n```\n# cd /var/lib/docker/overlay2/l\n# pwd\n/var/lib/docker/overlay2/l\n# ls\n24GM2IZVPTUROAG7AWJO5ZWE6B  LZEAXJGRW6HKBBGGB2N4CWMSVJ  R2XTGODAA67NQJM44MIKMDUF4W\n5OI5WMJ2FP7QI7IFWDMHLBRDDN  MS2X66BYF6UZ7EKUWMZJKCF4HO  SICZO4QNVZEVOIJ4HDXVDKNYA2\n644ISPHLTBSSC2KLP6BGHHHZPR  NSM2PTAT6TIT2H6G3HFNGZJH5N  ZR35FN2E3WEARZV4HLRU373FT7\n6CQUILQSJNVTMFFV3ABCCOGOYG  ODJROQUGY3WQMOGQ3BLYZGIAG4\nBQENAYC44O2ZCZFT5URMH5OADK  Q5LOBFJRH5M7M5CMSWW5L4VYOY\n```\n\n\n\n\n\n```\n# ls -l MS2X66BYF6UZ7EKUWMZJKCF4HO/\nTotal usage 0\ndrwxr-xr-x. 4 root root 43 1月  25 01:27 dev\ndrwxr-xr-x. 2 root root 66 1月  25 01:27 etc\n[root@192 l]# ls -l ODJROQUGY3WQMOGQ3BLYZGIAG4/\nTotal usage 0\ndrwxr-xr-x. 2 root root 41 12月 30 03:28 docker-entrypoint.d\n\n[root@192 l]# ls -l Q5LOBFJRH5M7M5CMSWW5L4VYOY/\nTotal usage 0\ndrwxr-xr-x. 2 root root 41 12月 30 03:28 docker-entrypoint.d\n[root@192 l]# ls -l ZR35FN2E3WEARZV4HLRU373FT7/\nTotal usage 0\ndrwxr-xr-x. 2 root root 45 12月 30 03:28 docker-entrypoint.d\n[root@192 l]# ls -l NSM2PTAT6TIT2H6G3HFNGZJH5N/\nTotal usage 4\n-rwxrwxr-x. 1 root root 1202 12月 30 03:28 docker-entrypoint.sh\n[root@192 l]# ls -l 24GM2IZVPTUROAG7AWJO5ZWE6B/\nTotal usage 4\ndrwxr-xr-x.  2 root root    6 12月 30 03:28 docker-entrypoint.d\ndrwxr-xr-x. 18 root root 4096 12月 30 03:28 etc\ndrwxr-xr-x.  4 root root   45 12月 20 08:00 lib\ndrwxrwxrwt.  2 root root    6 12月 30 03:28 tmp\ndrwxr-xr-x.  7 root root   66 12月 20 08:00 usr\ndrwxr-xr-x.  5 root root   41 12月 20 08:00 var\n[root@192 l]# ls -l SICZO4QNVZEVOIJ4HDXVDKNYA2/\nTotal usage 12\ndrwxr-xr-x.  2 root root 4096 12月 20 08:00 bin\ndrwxr-xr-x.  2 root root    6 12月 12 01:25 boot\ndrwxr-xr-x.  2 root root    6 12月 20 08:00 dev\ndrwxr-xr-x. 30 root root 4096 12月 20 08:00 etc\ndrwxr-xr-x.  2 root root    6 12月 12 01:25 home\ndrwxr-xr-x.  8 root root   96 12月 20 08:00 lib\ndrwxr-xr-x.  2 root root   34 12月 20 08:00 lib64\ndrwxr-xr-x.  2 root root    6 12月 20 08:00 media\ndrwxr-xr-x.  2 root root    6 12月 20 08:00 mnt\ndrwxr-xr-x.  2 root root    6 12月 20 08:00 opt\ndrwxr-xr-x.  2 root root    6 12月 12 01:25 proc\ndrwx------.  2 root root   37 12月 20 08:00 root\ndrwxr-xr-x.  3 root root   30 12月 20 08:00 run\ndrwxr-xr-x.  2 root root 4096 12月 20 08:00 sbin\ndrwxr-xr-x.  2 root root    6 12月 20 08:00 srv\ndrwxr-xr-x.  2 root root    6 12月 12 01:25 sys\ndrwxrwxrwt.  2 root root    6 12月 20 08:00 tmp\ndrwxr-xr-x. 11 root root  120 12月 20 08:00 usr\ndrwxr-xr-x. 11 root root  139 12月 20 08:00 var\n```\n\n\n\nAnd MS2X66BYF6UZ7EKUWMZJKCF4HO is mapped to the initialization layer init of the container. The content of this layer is the file content related to the container configuration, which is read-only.\n\nThe container is started, and docker mounts the content of the image into the container. So, if writing files in the container will have any impact on the image?\n\n\n\n## 2.5 Write files in the container\n\nIt is not difficult to understand that the image layer is read-only, and writing a file in the container is actually writing the file to the readable and writable layer of the overlay.\n\nHere are a few cases to test:\n\n- The file does not exist in the read-write layer, but exists in the read-only layer.\n- The file exists in the read-write layer, but not in the read-only layer.\n- The file does not exist in both the read-write layer and the read-only layer.\n\nWe simply build a scenario where neither the read-write layer nor the read-only layer exists:\n\n\n\n```\n# docker run -it centos:latest bash\n[root@355e99982248 /]# touch bzy.txt\n[root@355e99982248 /]# ls\nbin  etc   lib    lost+found  mnt      opt   root  sbin  sys  usr\ndev  home  lib64  media       bzy.txt  proc  run   srv   tmp  var\n```\n\n\n\nCheck whether the file exists in the read-write layer:\n\n```\nCheck the image for changes\n# docker images\nREPOSITORY   TAG       IMAGE ID       CREATED        SIZE\nubuntu       latest    d13c942271d6   2 weeks ago    72.8MB\nbash         latest    5557e073f11c   2 weeks ago    13MB\nnginx        latest    605c77e624dd   3 weeks ago    141MB\ncentos       latest    5d0da3dc9764   4 months ago   231MB\n\n[root@localhost ~]# cat /var/lib/docker/image/overlay2/repositories.json | grep 5d0da3dc9764\n{""Repositories""{""centos:latest"":""sha256:5d0da3dc976460b72c77d94c8a1ad043720b0416bfc16c52c45d4847e53fadb6"",""centos@sha256:a27fd8080b517143cbbbab9dfb7c8571c40d67d534bbdee55bd6c473f432b177"":""sha256:5d0da3dc976460b72c77d94c8a1ad043720b0416bfc16c52c45d4847e53fadb6""}}}\n\n\n\n[root@localhost ~]# cat /var/lib/docker/image/overlay2/imagedb/content/sha256/5d0da3dc976460b72c77d94c8a1ad043720b0416bfc16c52c45d4847e53fadb6\n{""os"":""linux"",""rootfs"":{""type"":""layers"",""diff_ids"":[""sha256:74ddd0ec08fa43d09f32636ba91a0a3053b02cb4627c35051aff89f853606b59""]}}\n\n\n[root@localhost ~]# ls \n/var/lib/docker/image/overlay2/layerdb/sha256/74ddd0ec08fa43d09f32636ba91a0a3053b02cb4627c35051aff89f853606b59:\ncache-id  diff  size  tar-split.json.gz\n[root@localhost ~]# cat /var/lib/docker/image/overlay2/layerdb/sha256/74ddd0ec08fa43d09f32636ba91a0a3053b02cb4627c35051aff89f853606b59/cache-id\nb17bc5c5103514923a30983c48f909e06f366b7aa1e85f112b67abb3ef5cd0cb\n\n[root@localhost ~]# cat /var/lib/docker/image/overlay2/layerdb/sha256/74ddd0ec08fa43d09f32636ba91a0a3053b02cb4627c35051aff89f853606b59/diff\nsha256:74ddd0ec08fa43d09f32636ba91a0a3053b02cb4627c35051aff89f853606b59\n\n\n[root@localhost ~]# ls /var/lib/docker/overlay2/b17bc5c5103514923a30983c48f909e06f366b7aa1e85f112b67abb3ef5cd0cb\ncommitted  diff  link\n[root@localhost ~]# ls /var/lib/docker/overlay2/b17bc5c5103514923a30983c48f909e06f366b7aa1e85f112b67abb3ef5cd0cb/diff/\nbin  etc   lib    lost+found  mnt  proc  run   srv  tmp  var\ndev  home  lib64  media       opt  root  sbin  sys  usr\n\n\nCheck if the container has changed\n[root@localhost ~]# mount | grep overlay\ntype overlay (rw,relatime,seclabel,lowerdir=/var/lib/docker/overlay2/l/R2W2LEMDPRIUFYDVSLIQSCYTGX:/var/lib/docker/overlay2/l/R2XTGODAA67NQJM44MIKMDUF4W,upperdir=/var/lib/docker overlay2/7f0b54c748171872ce564305e394547555cb1182abf802c2262384be3dc78a8f/diff,workdir=/var/lib/docker/overlay2/7f0b54c748171872ce564305e394547555cb1182abf802c2262384be3dc78a8f/work)\n\n\n[root@localhost ~]# ls -l /var/lib/docker/overlay2/l/\nTotal usage 0\n\nlrwxrwxrwx. 1 root root 77 1月  25 01:41 R2W2LEMDPRIUFYDVSLIQSCYTGX -> ../7f0b54c748171872ce564305e394547555cb1182abf802c2262384be3dc78a8f-init/diff\nlrwxrwxrwx. 1 root root 72 1月  25 00:29 R2XTGODAA67NQJM44MIKMDUF4W -> ../b17bc5c5103514923a30983c48f909e06f366b7aa1e85f112b67abb3ef5cd0cb/diff\n\n\n[root@localhost ~]# ls /var/lib/docker/overlay2/7f0b54c748171872ce564305e394547555cb1182abf802c2262384be3dc78a8f/diff\nbzy.txt\n\n\n[root@localhost ~]# ls /var/lib/docker/overlay2/7f0b54c748171872ce564305e394547555cb1182abf802c2262384be3dc78a8f/merged/\nbin  etc   lib    lost+found  mnt      opt   root  sbin  sys  usr\ndev  home  lib64  media       bzy.txt  proc  run   srv   tmp  var\n\n```\n\n\n\n# 3. Docker container image operation command\n\n## 3.1  docker commit\n\nAs mentioned in the previous section, writing files in the container will be reflected in the readable and writable layer of the overlay, so can the contents of the files in the readable and writable layer be mirrored?\n\nYes. Docker implements image building through commit and build operations. commit submits the container as an image, and build builds an image based on an image.\n\nUse commit to submit the container in the previous section as an image:\n\n\n\n```\n[root@355e99982248 /]#   ctrl+p+q\n```\n\n\n\n```\n# docker ps\nCONTAINER ID   IMAGE           COMMAND                  CREATED          STATUS          PORTS     NAMES\n355e99982248   centos:latest   ""bash""                   21 minutes ago   Up 21 minutes             fervent_perlman\n```\n\n\n\n```\n# docker commit 355e99982248\nsha256:8965dcf23201ed42d4904e2f10854d301ad93b34bea73f384440692e006943de\n```\n\n\n\n\n\n```\n# docker images\nREPOSITORY   TAG       IMAGE ID       CREATED              SIZE\n<none>       <none>    8965dcf23201   About a minute ago   231MB\n```\n\n\n\n\n\nThe image short ID 8965dcf23201 is the image submitted by the container, check the imagedb metadata of the image:\n\n\n\n```\n# cat  /var/lib/docker/image/overlay2/imagedb/content/sha256/8965dcf23201ed42d4904e2f10854d301ad93b34bea73f384440692e006943de\n......\n""os"":""linux"",""rootfs"":{""type"":""layers"",""diff_ids"":[""sha256:74ddd0ec08fa43d09f32636ba91a0a3053b02cb4627c35051aff89f853606b59"",""sha256:551c3089b186b4027e949910981ff1ba54114610f2aab9359d28694c18b0203b""]}}\n```\n\n\n\nIt can be seen that the diff_id of the first mirror layer from top to bottom of the mirror layer is the same as the diff_id of the centos mirror layer, indicating that each mirror layer can be shared by multiple mirrors. And the extra layer of mirror layer content is the content we wrote to the file in the previous section:\n\n\n\n```\n# echo -n ""sha256:74ddd0ec08fa43d09f32636ba91a0a3053b02cb4627c35051aff89f853606b59 sha256:551c3089b186b4027e949910981ff1ba54114610f2aab9359d28694c18b0203b"" | sha256sum -\n92f7208b1cc0b5cc8fe214a4b0178aa4962b58af8ec535ee7211f335b1e0ed3b  -\n```\n\n\n\n```\n# cd /var/lib/docker/image/overlay2/layerdb/sha256/92f7208b1cc0b5cc8fe214a4b0178aa4962b58af8ec535ee7211f335b1e0ed3b\n[root@192 92f7208b1cc0b5cc8fe214a4b0178aa4962b58af8ec535ee7211f335b1e0ed3b]# ls\ncache-id  diff  parent  size  tar-split.json.gz\n\n\n\n[root@192 92f7208b1cc0b5cc8fe214a4b0178aa4962b58af8ec535ee7211f335b1e0ed3b]# cat cache-id\n250dc0b4f2c5f27952241a55cd4c286bfaaf8af4b77c9d0a38976df4c147cb95\n\n\n[root@192 92f7208b1cc0b5cc8fe214a4b0178aa4962b58af8ec535ee7211f335b1e0ed3b]# ls /var/lib/docker/overlay2/250dc0b4f2c5f27952241a55cd4c286bfaaf8af4b77c9d0a38976df4c147cb95\ndiff  link  lower  work\n\n\n[root@192 92f7208b1cc0b5cc8fe214a4b0178aa4962b58af8ec535ee7211f335b1e0ed3b]# ls /var/lib/docker/overlay2/250dc0b4f2c5f27952241a55cd4c286bfaaf8af4b77c9d0a38976df4c147cb95/diff\nbzy.txt\n\n```\n\n\n\n## 3.2 docker save\n\n> Export container images for easy sharing.\n\n\n\n```\n# docker save -o centos.tar centos:latest  \n```\n\n\n\n```\n# ls\n\ncentos.tar  \n```\n\n\n\n\n\n## 3.3 docker load\n\n> Import the container image shared by others to the local, which is usually one of the container image distribution methods.\n\n\n\n```\n# docker load -i centos.tar\n```\n\n\n\n\n\n## 3.4 docker export\n\n> Export the running container.\n\n\n\n```\n# docker ps\nCONTAINER ID   IMAGE           COMMAND                  CREATED       STATUS       PORTS     NAMES\n355e99982248   centos:latest   ""bash""                   7 hours ago   Up 7 hours             fervent_perlman\n```\n\n\n\n```\n# docker export -o centos7.tar 355e99982248\n```\n\n\n\n```\n# ls\ncentos7.tar\n```\n\n\n\n\n\n## 3.5 docker import\n\n> Import the container exported using docker export as a local container image.\n\n\n\n```\n# ls\ncentos7.tar \n```\n\n\n\n```\n# docker import centos7.tar centos7:v1\n```\n\n\n\n```\n# docker images\nREPOSITORY   TAG       IMAGE ID       CREATED              SIZE\ncentos7      v1        3639f9a13231   17 seconds ago       231MB\n```\n\n\n\nIt is very troublesome to share container images through docker save and docker load, docker export and docker import. Is there a more convenient way to share container images?\n",2023-04-14T17:22:51.061Z,hide,com.baizeyu.published.model.Published
644110899ba29477b0013f0b,Recording a hiking and exploration experience,"On Saturday, April 15th, I woke up early and went alone to the Great Sugar Loaf in Wicklow. I had never been to that mountain before, so I did not know the correct route to take up the mountain. However, I knew that the highest peak was my goal for the day, and I needed to find a way to reach it. After getting off the bus, I stood at the foot of the mountain and gazed up at the summit.\n\nI did not have any guide or plan, but only saw a white line on Google Maps that seemed like a route to the summit. I assumed that it would be an easy pathway taken by everyone. However, I realized halfway up that the white line was actually a small stream flowing down from the peak. The route was full of water holes on the muddy ground covered by dense vegetation, with no clear path ahead. I felt lost and confused about how to proceed.\n\n<p align=""center"">\n<img src=""https://raw.githubusercontent.com/ClarenceWhite/BlogImage/main/images/newblog4-20-11-11-16.jpg"" id=""blog-image"" />\n</p>\n\nBut when I looked up at the summit, I told myself that the journey up the mountain was like life's uncertainties. You never know if your choices will be difficult or simple, and what challenges you might face. However, I could see the summit, and that was where I needed to go. So, I put on some climbing music, focused on the destination, and searched for a path that would lead me towards my goal. I changed my target to a point 50 meters away from me, and aimed to reach there despite the obstacles in my way.\n\nBy setting small targets and concentrating on each step, I gradually shifted my attention from the pain to the present moment. After 50 minutes of exploration, I finally found the right path leading to the summit. I joyfully sprinted along the pathway, leaving behind all the hardships I had endured. When I reached another fork in the road, I was faced with two routes that led to the summit. One was an easy route with large rocks for stepping on, but it would take more time since it was not so steep. The other was a steeper route almost 80° angle, with no one else around to help if anything went wrong.\n\nI chose the second path and rested for two minutes at the junction, took a deep breath and began climbing. I continued to set small goals for myself, focusing on reaching each point along the way. I climbed up step by step, without getting tired or discouraged. Finally, standing at the summit, I looked down at the beautiful coastline and marveled at my own abilities. I had achieved my goal through perseverance and determination.\n<p align=""center""><img src=""https://raw.githubusercontent.com/ClarenceWhite/BlogImage/main/images/newblog4-20-11-13-14.jpg"" id=""blog-image"" /></p>\n\nAfter sitting at the summit for 20 minutes, I started on my journey back down. Once again, fate played a trick on me, and I found myself lost midway through the descent. However, this time my mindset had changed. I was no longer worried about whether I could get back down safely because I knew that I could. I had overcome the uncertainty of climbing up the mountain. Although I was on the wrong path, I still saw sights that others couldn't see and smelled the fragrance of April flowers that others couldn't smell.\n\n<p align=""center""><img src=""https://raw.githubusercontent.com/ClarenceWhite/BlogImage/main/images/newblog4-20-11-13-34.jpg"" id=""blog-image"" /></p>\n\n<p align=""center""><img src=""https://raw.githubusercontent.com/ClarenceWhite/BlogImage/main/images/newblog4-20-11-13-54.jpg"" id=""blog-image"" /></p>\n\nAs expected, after many twists and turns, I finally made it back to the bus stop. I was so exhausted that I fell asleep on the bus ride back. When I got off the bus, my legs were numb, and it took 100 meters of walking before I regained feeling in them.\n\nThis experience taught me that although some things in life can be certain, it is the unexpected uncertainties that are worth challenging ourselves with. Pursuing stability is encoded in human genes, but courage and action in the face of uncertainty are the treasures that bring vitality to our lives.",2023-04-20T10:35:13.473Z,life,com.baizeyu.published.model.Published
644182dd9ba29477b0013f0c,Docker containerized deployment of enterprise-level application clusters,"# 1. Docker containerized deployment of enterprise-level applications\n\n## 1.1 Necessity of Deploying Enterprise-level Applications Using Docker Containerization\n\n- Conducive to rapid implementation of enterprise-level application deployment\n- Facilitate rapid implementation of enterprise-level application recovery\n\n\n# 2. Docker Nginx\nHere is a demonstration of the technique I use on this site. (link to be updated)\n\n# 3. Docker Tomcat\n\n## 3.1 Search for the image on DockerHub and run it\nhttps://hub.docker.com/_/tomcat\n\n### 3.1.1 Without port exposure\n\n```\n# docker run -d --rm tomcat:9.0\n```\n\n\n```\n# docker ps\nCONTAINER ID   IMAGE        COMMAND                  CREATED             STATUS             PORTS                                                  NAMES\nc20a0e781246   tomcat:9.0   ""catalina.sh run""        27 seconds ago      Up 25 seconds      8080/tcp                                               heuristic_cori\n```\n\n\n\n\n\n\n\n### 3.1.2 With port exposure\n\n```\n# docker run -d -p 8080:8080 --rm tomcat:9.0\n2fcf5762314373c824928490b871138a01a94abedd7e6814ad5f361d09fbe1de\n```\n\n\n\n```\n# docker ps\nCONTAINER ID   IMAGE        COMMAND                  CREATED             STATUS             PORTS                                                  NAMES\n2fcf57623143   tomcat:9.0   ""catalina.sh run""        3 seconds ago       Up 1 second        0.0.0.0:8080->8080/tcp, :::8080->8080/tcp              eloquent_chatelet\n```\n\nThen you can go to localhost:8080.\n\n\n\n\n\n### 3.1.3 Port exposure and add a static file\n\n\n\n```\ndocker run -d -p 8081:8080 -v /opt/tomcat-server:/usr/local/tomcat/webapps/ROOT tomcat:9.0\n\n# f456e705d48fc603b7243a435f0edd6284558c194e105d87befff2dccddc0b63\n```\n\n\n\n```\n# docker ps\n\nCONTAINER ID   IMAGE        COMMAND             CREATED         STATUS         PORTS                                       NAMES\nf456e705d48f   tomcat:9.0   ""catalina.sh run""   3 seconds ago   Up 2 seconds   0.0.0.0:8081->8080/tcp, :::8081->8080/tcp   cool_germain\n```\n\n\n```\n# echo ""tomcat running"" > /opt/tomcat-server/index.html\n```\n\n\n**Access on localhost**\n\n```\nroot@master-01:~# curl localhost:8081\n\ntom cat running\n```\n\n# 4. Docker MySQL\n\n## 4.1 Single Node MySQL Deployment\n\n```\n# docker run -p 3306:3306 --name=mysql-container \\n-e MYSQL_ROOT_PASSWORD=your_password \\n-e MYSQL_DATABASE=your_database \\n-d mysql\n```\n\n```\n# docker ps\nCONTAINER ID   IMAGE     COMMAND                  CREATED         STATUS         PORTS                 NAMES\n6f0303faae0c   mysql     ""docker-entrypoint.s…""   2 minutes ago   Up 2 minutes   3306/tcp, 33060/tcp   mysql-container\n```\n\n```\nAccess via client inside container\n# docker exec -it mysql-container mysql -u root -p\nEnter password: your_password\nWelcome to the MySQL monitor.  Commands end with ; or \g.\nYour MySQL connection id is 10\nServer version: 8.0.33 MySQL Community Server - GPL\n\nCopyright (c) 2000, 2023, Oracle and/or its affiliates.\n\nOracle is a registered trademark of Oracle Corporation and/or its\naffiliates. Other names may be trademarks of their respective\nowners.\n\nType 'help;' or '\h' for help. Type '\c' to clear the current input statement.\n\nmysql>\n```\n\n\n\n## 4.2 MySQL Master-Slave Node Deployment\n\n### 4.2.1 Master Node\n\n```\ndocker run -p 3306:3306 --name=mysql-master \\n-e MYSQL_ROOT_PASSWORD=root \\n-e MYSQL_DATABASE=your_database \\n-v /opt/mysql_master/log:/var/log \\n-v /opt/mysql_master/data:/var/lib/mysql \\n-d mysql\n```\n\n\n```\n# docker ps\nCONTAINER ID   IMAGE     COMMAND                  CREATED         STATUS         PORTS                                                  NAMES\n024f3008ec0e   mysql     ""docker-entrypoint.s…""   3 seconds ago   Up 2 seconds   0.0.0.0:3306->3306/tcp, :::3306->3306/tcp, 33060/tcp   mysql-master\n```\n\n```\ndocker cp mysql-master:/etc/my.cnf /opt/mysql_master/config/my.cnf\n```\n\n### 4.2.2 Master Node Config File\n\n```\nvim /opt/mysql_master/config/my.cnf\n\n# For advice on how to change settings please see\n# http://dev.mysql.com/doc/refman/8.0/en/server-configuration-defaults.html\n\n[mysqld]\n#\n# Remove leading # and set to the amount of RAM for the most important data\n# cache in MySQL. Start at 70% of total RAM for dedicated server, else 10%.\n# innodb_buffer_pool_size = 128M\n#\n# Remove leading # to turn on a very important data integrity option: logging\n# changes to the binary log between backups.\n# log_bin\n#\n# Remove leading # to set options mainly useful for reporting servers.\n# The server defaults are faster for transactions and fast SELECTs.\n# Adjust sizes as needed, experiment to find the optimal values.\n# join_buffer_size = 128M\n# sort_buffer_size = 2M\n# read_rnd_buffer_size = 2M\n\n# Remove leading # to revert to previous value for default_authentication_plugin,\n# this will increase compatibility with older clients. For background, see:\n# https://dev.mysql.com/doc/refman/8.0/en/server-system-variables.html#sysvar_default_authentication_plugin\n# default-authentication-plugin=mysql_native_password\nskip-host-cache\nskip-name-resolve\ndatadir=/var/lib/mysql\nsocket=/var/run/mysqld/mysqld.sock\nsecure-file-priv=/var/lib/mysql-files\nuser=mysql\n\npid-file=/var/run/mysqld/mysqld.pid\n\n# add these to the file!!!!!!!!!!!!!!!!!!!! (start)\nserver_id=1\nlog-bin=mysql-bin\nread-only=0\nbinlog-do-db=your_database\n\nreplicate-ignore-db=mysql\nreplicate-ignore-db=sys\nreplicate-ignore-db=information_schema\nreplicate-ignore-db=performance_schema\n\n# add these to the file!!!!!!!!!!!!!!!!!!!!! (end)\n\n[client]\nsocket=/var/run/mysqld/mysqld.sock\n\n!includedir /etc/mysql/conf.d/\n```\n\n```\ndocker cp /opt/mysql_master/config/my.cnf mysql-master:/etc/my.cnf\ndocker restart mysql-master\n```\n\n```\ndocker exec -it mysql-master mysql -u root -p\n```\n\n### 4.2.3 Slave Node\n\n```\ndocker run -p 3307:3306 --name mysql-slave \\n-e MYSQL_ROOT_PASSWORD=root \\n-e MYSQL_DATABASE=your_database \\n-v /opt/mysql_slave/log:/var/log \\n-v /opt/mysql_slave/data:/var/lib/mysql \\n-d --link mysql-master:mysql-master mysql\n```\n\n```\n# docker ps\nCONTAINER ID   IMAGE     COMMAND                  CREATED          STATUS          PORTS                                                  NAMES\nf880333ee83b   mysql     ""docker-entrypoint.s…""   22 minutes ago   Up 4 minutes    33060/tcp, 0.0.0.0:3307->3306/tcp, :::3307->3306/tcp   mysql-slave\n```\n\n```\nmkdir /opt/mysql_slave/config\ndocker cp mysql-slave:/etc/my.cnf /opt/mysql_slave/config/my.cnf\n```\n\n\n### 4.2.4 Slave Node Config File\n\n```\n# vim /opt/mysql_slave/config/my.cnf\n# For advice on how to change settings please see\n# http://dev.mysql.com/doc/refman/8.0/en/server-configuration-defaults.html\n\n[mysqld]\n#\n# Remove leading # and set to the amount of RAM for the most important data\n# cache in MySQL. Start at 70% of total RAM for dedicated server, else 10%.\n# innodb_buffer_pool_size = 128M\n#\n# Remove leading # to turn on a very important data integrity option: logging\n# changes to the binary log between backups.\n# log_bin\n#\n# Remove leading # to set options mainly useful for reporting servers.\n# The server defaults are faster for transactions and fast SELECTs.\n# Adjust sizes as needed, experiment to find the optimal values.\n# join_buffer_size = 128M\n# sort_buffer_size = 2M\n# read_rnd_buffer_size = 2M\n\n# Remove leading # to revert to previous value for default_authentication_plugin,\n# this will increase compatibility with older clients. For background, see:\n# https://dev.mysql.com/doc/refman/8.0/en/server-system-variables.html#sysvar_default_authentication_plugin\n# default-authentication-plugin=mysql_native_password\nskip-host-cache\nskip-name-resolve\ndatadir=/var/lib/mysql\nsocket=/var/run/mysqld/mysqld.sock\nsecure-file-priv=/var/lib/mysql-files\nuser=mysql\n\npid-file=/var/run/mysqld/mysqld.pid\n\n# add these to the file!!!!!!!!!!!!!!!!!!!!! (start)\n\nserver_id=2\nlog-bin=mysql-bin\nread-only=1\nbinlog-do-db=your_database\n\nreplicate-ignore-db=mysql\nreplicate-ignore-db=sys\nreplicate-ignore-db=information_schema\nreplicate-ignore-db=performance_schema\n\n# add these to the file!!!!!!!!!!!!!!!!!!!!! (end)\n\n[client]\nsocket=/var/run/mysqld/mysqld.sock\n\n!includedir /etc/mysql/conf.d/\n```\n\n```\ndocker cp /opt/mysql_slave/config/my.cnf mysql-slave:/etc/my.cnf\ndocker restart mysql-slave\n```\n\n```\ndocker exec -it mysql-slave mysql -u root -p\n```\n\n### 4.2.5 Config Master Node\n```\ndocker exec -it mysql-master mysql -u root -p\n```\n```\nuse mysql;\n# Database changed\n\ncreate user 'backup'@'%' identified with mysql_native_password by '123456';\n# Query OK, 0 rows affected (0.01 sec)\n\ngrant all privileges on *.* to 'backup'@'%' with grant option;\n# Query OK, 0 rows affected (0.00 sec)\n\nflush privileges;\n# Query OK, 0 rows affected (0.01 sec)\n\nshow master status\G\n# *************************** 1. row ***************************\n             File: mysql-bin.000001\n         Position: 157\n     Binlog_Do_DB: your_database\n Binlog_Ignore_DB:\nExecuted_Gtid_Set:\n1 row in set (0.00 sec)\n```\n\n### 4.2.6 Config Slave Node\n```\ndocker exec -it mysql-slave mysql -u root -p\n```\n\n```\nmysql> change master to\n    -> master_host='mysql-master',\n    -> master_user='backup',\n    -> master_password='123456',\n    -> master_log_file='mysql-bin.000001',\n    -> master_log_pos=157,\n    -> master_port=3306;\n# Query OK, 0 rows affected, 9 warnings (0.02 sec)\n\nmysql> start slave;\n# Query OK, 0 rows affected, 1 warning (0.02 sec)\n\nshow slave status\G\n# *************************** 1. row ***************************\n               Slave_IO_State: Waiting for source to send event\n                  Master_Host: mysql-master\n                  Master_User: backup\n                  Master_Port: 3306\n                Connect_Retry: 60\n              Master_Log_File: mysql-bin.000001\n          Read_Master_Log_Pos: 157\n               Relay_Log_File: f880333ee83b-relay-bin.000002\n                Relay_Log_Pos: 326\n        Relay_Master_Log_File: mysql-bin.000001\n             Slave_IO_Running: Yes\n            Slave_SQL_Running: Yes\n              Replicate_Do_DB:\n          Replicate_Ignore_DB: mysql,sys,information_schema,performance_schema\n           Replicate_Do_Table:\n       Replicate_Ignore_Table:\n      Replicate_Wild_Do_Table:\n  Replicate_Wild_Ignore_Table:\n                   Last_Errno: 0\n                   Last_Error:\n                 Skip_Counter: 0\n          Exec_Master_Log_Pos: 157\n              Relay_Log_Space: 543\n              Until_Condition: None\n               Until_Log_File:\n                Until_Log_Pos: 0\n           Master_SSL_Allowed: No\n           Master_SSL_CA_File:\n           Master_SSL_CA_Path:\n              Master_SSL_Cert:\n            Master_SSL_Cipher:\n               Master_SSL_Key:\n        Seconds_Behind_Master: 0\nMaster_SSL_Verify_Server_Cert: No\n                Last_IO_Errno: 0\n                Last_IO_Error:\n               Last_SQL_Errno: 0\n               Last_SQL_Error:\n  Replicate_Ignore_Server_Ids:\n             Master_Server_Id: 1\n                  Master_UUID: 913b5d44-df92-11ed-b2d5-0242ac110002\n             Master_Info_File: mysql.slave_master_info\n                    SQL_Delay: 0\n          SQL_Remaining_Delay: NULL\n      Slave_SQL_Running_State: Replica has read all relay log; waiting for more updates\n           Master_Retry_Count: 86400\n                  Master_Bind:\n      Last_IO_Error_Timestamp:\n     Last_SQL_Error_Timestamp:\n               Master_SSL_Crl:\n           Master_SSL_Crlpath:\n           Retrieved_Gtid_Set:\n            Executed_Gtid_Set:\n                Auto_Position: 0\n         Replicate_Rewrite_DB:\n                 Channel_Name:\n           Master_TLS_Version:\n       Master_public_key_path:\n        Get_master_public_key: 0\n            Network_Namespace:\n1 row in set, 1 warning (0.00 sec)\n```\n\n### 4.2.7 Verify the Availability of the MySQL Cluster\n\nWe are going to add a table in DB 'your_database' on master (we must use this DB, because we only put this DB in the config file for sync):\n\n```\ndocker exec -it mysql-master mysql -u root -p\n\nmysql> use your_database;\n# Database changed\n\nmysql> create table test (id int);\n# Query OK, 0 rows affected (0.03 sec)\n\nmysql> show tables ;\n+-------------------------+\n| Tables_in_your_database |\n+-------------------------+\n| test                    |\n+-------------------------+\n1 row in set (0.00 sec)\n```\n\nCheck the sync status on slave node:\n```\ndocker exec -it mysql-slave mysql -u root -p\n\nmysql> use your_database;\n# Database changed\n\nmysql> show tables;\n+-------------------------+\n| Tables_in_your_database |\n+-------------------------+\n| test                    |\n+-------------------------+\n1 row in set (0.00 sec)\n```",2023-04-20T18:48:05.958Z,hide,com.baizeyu.published.model.Published
6443c60b9ba29477b0013f0d,Comprehensive explanation of Dockerfile and novel container image construction techniques,"# 1. The relationship between container and image\n\nSpeaking of containers managed by Docker, we have to mention container images because they serve as the templates for containers. It is through container images that we can quickly create containers.\n\n\n<p align=""center"">\n<img src=""https://raw.githubusercontent.com/ClarenceWhite/BlogImage/main/images/newblog4-22-12-29-36.jpg"" id=""blog-image"" />\n</p>\n\n\n\n> Docker Daemon creates containers using images\n\n \n\n# 2. Classification of images\n\n- OS\n  - CentOS\n  - Ubuntu\n- Application\n  - Tomcat\n  - Nginx\n  - MySQL\n  - Redis\n\n\n# 3. How to get images?\n\n1. From DockerHub\n\n2. Make the system-related files in an OS into image\n\n3. Using docker commit to make a running container into a new image\n\n4. Use Dockerfile to build an image\n\n\n# 4. A demo using method 3 & 4 above\n\n## 4.1 Make a running container into an image\n\n### 4.1.1 Run a container firstly\n\n```\ndocker run -it ubuntu\n```\n\n\n### 4.1.2 Install an app in the container\n\n```\napt-get update -y && \\napt-get install apache2 -y && \\napt-get install systemctl && \\nsystemctl enable apache2 && \\nsystemctl start apache2\n```\nPlease use `curl localhost` to verify whether the apache2 http server is running.\n\n\n\n### 4.1.3 Make it into an image\n\n```\nroot@master-01:~# docker ps\nCONTAINER ID   IMAGE             COMMAND                  CREATED          STATUS         PORTS                                   NAMES\na83d4a14e3c6   ubuntu            ""/bin/bash""              30 minutes ago   Up 3 minutes                                           brave_leakey\n```\n\n```\ndocker commit -a ""Clarence"" a83d4a14e3c6 ubuntu-apache2:v1\n# sha256:dbc4bd399ef0c4e7c50425ff9de73711e121bbdf14cd960ed181ff62d90ea1bd\n```\n\n```\nroot@master-01:~# docker image ls\nREPOSITORY       TAG       IMAGE ID       CREATED         SIZE\nubuntu-apache2   v1        a86e18671cbb   3 seconds ago   242MB\n```\n\nWe can see that the size of the new image is bigger than the official ubuntu:latest image, that means we successfully added something into the iamge.\n\n\n## 4.2 Use Dockerfile\n\n### 4.2.1 Intro to Dockerfile\n\nA Dockerfile is a script that can be interpreted by the Docker program. It is made up of a series of instructions, each with its own syntax and supported commands. When we need to specify additional requirements in a container image, we can add or modify instructions in the Dockerfile, and then use `docker build` to generate our custom container image.\n\n<p align=""center""><img src=""https://raw.githubusercontent.com/ClarenceWhite/BlogImage/main/images/newblog4-22-12-30-40.jpg"" id=""blog-image"" /></p>\n\n\n\n\n\n\n\n### 4.2.2 Dockerfile commands\n\n| Command    | Description                                                |\n| ------- | --------------------------------------------------- |\n| FROM    | The base image upon which the new image is built                            |\n| LABEL   | A tag                                               |\n| RUN     | Shell commands executed during image build                          |\n| COPY    | Copy local file to image                              |\n| ADD     | Similar to COPY, but can auto-unzip zip files                                    |\n| ENV     | Environment variables                                        |\n| USER    | To specify the user to run commands for RUN, CMD and ENTRYPOINT          |\n| EXPOSE  | To declare the service port for container runtime                             |\n| WORKDIR | To set working directory for RUN, CMD, ENTRYPOINT, COPY and ADD       |\n| CMD     | When running a container, the default CMD instruction is executed. If there are multiple CMD instructions, only the last one takes effect |\n\n(`man dockerfile` can be used to for helping)\n\n1. **FROM**\n\nThe FROM instruction is used to specify the base image that will be used to build a new image in Dockerfile.\n\nThe FROM instruction must be the first line in the Dockerfile.\n\nThe base image specified by the FROM instruction can be from the official remote repository, or it can be in the local repository, with priority given to the local repository.\n\n```\nformat: FROM <image>:<tag>\ne.g.: FROM ubuntu:latest\n```\n\n2. **RUN**\n\n""The RUN instruction is used to execute commands during the image build process, and it has the following two formats:""\n\n* shell format\n\n```\nformat: RUN <commands>\ne.g.: RUN echo 'hello world' > /var/www/html/index.html\n```\n\n* exec format\n\n```\nformat: RUN [""executable file"", ""arg1"", ""arg2""]\ne.g.: RUN [""/bin/bash"", ""-c"", ""echo 'hello' > /var/www/html/index.html""]\n```\n\n**Note:** From an optimization perspective, when there are multiple commands to be executed, do not use multiple RUN instructions. Instead, try to use the && and \ symbols to connect them into one line, because using multiple RUN instructions will create multiple layers in the image.\n\n```\nRUN yum install httpd httpd-devel -y\nRUN echo test > /var/www/html/index.html\n\ncan be turned into:\nRUN yum install httpd httpd-devel -y && echo test > /var/www/html/index.html\n\nor:\nRUN yum install httpd httpd-devel -y  \\n    && echo test > /var/www/html/index.html\n```\n\n3. **CMD**\n\nCMD is different from RUN. CMD is used to specify the command to be executed when the container starts, while RUN is used to specify the command to be executed during image building.\n\n```\nThere are 3 formats of CMD:\nCMD [""executable"",""param1"",""param2""]\nCMD [""param1"",""param2""]\nCMD command param1 param2\n```\n\nEach Dockerfile can only have one CMD instruction. If multiple commands are specified, only the last one will be executed.\n\nIf the user specifies a command to run when starting the container, it will override the command specified by CMD.\n\nWhat is command to run when starting a container?\n`docker run -d -p 80:80 [image_name] [commands]`\n\n\n\n4. **EXPOSE**\n\nThe EXPOSE instruction is used to specify the port that the container will listen on during runtime.\n\n```\nformat: EXPOSE <port> [<port>...]\ne.g.: EXPOSE 80 3306 8080\n```\n\nThe port mentioned above needs to be mapped to the host port using the -p parameter when running the container with docker run.\n\n5. **ENV**\n\nThe ENV instruction is used to specify an environment variable.\n\n```\nformat: ENV <key> <value> or ENV <key>=<value>\ne.g.: ENV JAVA_HOME=/usr/local/jdkxxxx/\n```\n\n6. **ADD**\n\nThe ADD instruction is used to copy files from the host machine to the image.\n\n```\nformat: ADD <src> <dest>\nThe <src> can be a local file or directory, a compressed file, or a URL. If <src> is a URL, then ADD works similarly to the wget command.\n\nThe <dest> path can be an absolute path within the container, or a relative path to the working directory.\n```\n\n7. **COPY**\n\nThe COPY instruction is similar to the ADD instruction, but the source files for COPY can only be local files.\n\n```\nformat: COPY <src> <dest>\n```\n\n8. **ENTRYPOINT**\n\nENTRYPOINT is similar to CMD\n\nSimilarities:\nOnly one instruction should be written per Dockerfile. If multiple instructions are written, only the last one will take effect.\n\nDifferences:\nIf the user specifies a command to run when starting the container, the specified command will not override the ENTRYPOINT instruction, but it will override the CMD instruction.\n\n```\nThere are two formats:\nENTRYPOINT [""executable"", ""param1"", ""param2""]\nENTRYPOINT command param1 param2\n```\n\n9. **VOLUME**\n\nThe VOLUME instruction is used to map a directory on the host machine to a directory in the container.\n\nWhen only specifying the mount point in the VOLUME instruction, Docker will create a new volume for the container, and the directory on the host machine that corresponds to the volume will be automatically generated.\n```\nformat: VOLUME [""<mountpoint>""]\n```\n\n10. **USER**\n\nThe USER instruction sets the user who starts the container (such as Hadoop requires Hadoop user operation, Oracle requires Oracle user operation), and can be either a username or UID.\n\n```\nUSER daemon\nUSER 1001\n```\n\n**Note**: If the container is set to run as the daemon user, then RUN, CMD, and ENTRYPOINT will all run as that user. After the image build is complete, when running the container with `docker run`, you can use the `-u` parameter to override the specified user.\n\n11. **WORKDIR**\n\nThe WORKDIR instruction sets the working directory, similar to the cd command. It is not recommended to use `RUN cd /root`; instead, it is recommended to use the WORKDIR instruction.\n\n```\nWORKDIR /root\n```\n\n\n### 4.2.3 Use Dockerfile to build an image demo (nginx ubuntu)\n\nLet's make a directory first:\n```\nmkdir nginx-image-make\ncd nginx-image-make/\n```\n\nMake an html file:\n```\necho ""I am building an nginx image..."" > index.html\n```\n\nMake a Dockerfile:\n```\nvim Dockerfile\n--------------------------\n# base image\nFROM ubuntu\n# author\nMAINTAINER ""clarencewhite9807@gmail.com""\n# install nginx\nRUN apt-get -y update && apt-get install nginx -y\n# copy index.html from local to image\nADD index.html /var/www/html/index.nginx-debian.html\n# make nginx as a foreground service\nRUN echo ""daemon off;"" >> /etc/nginx/nginx.conf\n# port in container\nEXPOSE 80\n# run the executable file on container start to start nginx service\nCMD /usr/sbin/nginx\n```\n\nBuild the image using Dockerfile:\n```\ndocker build -t ubuntu-nginx:v1 .\n```\n\nCheck the image we built just now:\n```\ndocker image ls\n\nREPOSITORY       TAG       IMAGE ID       CREATED        SIZE\nubuntu-nginx     v1        d8e8e2e8b89d   15 hours ago   163MB\n```\n\nRun the image as a container and check the default html page:\n```\ndocker run ubuntu-nginx:v1 -d -p 9000:80\n\ndocker ps\n-------------\nCONTAINER ID   IMAGE             COMMAND                  CREATED        STATUS        PORTS                                   NAMES\n9fce15688a3c   ubuntu-nginx:v1   ""/bin/sh -c /usr/sbi…""   15 hours ago   Up 15 hours   0.0.0.0:9000->80/tcp, :::9000->80/tcp   condescending_ganguly\n\ncurl localhost:9000\n-------------\nI am building an nginx image...\n```\n\n\n## 4.3 Optimizing container image generation using Dockerfile\n\n### 4.3.1 Reducing image layers\n\nIn a Dockerfile, there are multiple types of instructions. Among them, the RUN command is probably the most commonly used instruction when it comes to deployment. When using the RUN command, it is not recommended to use a separate RUN command for each installation. Instead, you can combine multiple installation commands into a single RUN command. This reduces the number of image layers.\n\n**Bad version:**\n```\nFROM centos:latest\nRUN yum install epel-release -y \nRUN yum install -y gcc gcc-c++ make -y\nRUN wget http://docs.php.net/distributions/php-5.6.36.tar.gz\nRUN tar zxf php-5.6.36.tar.gz\nRUN cd php-5.6.36\nRUN ./configure --prefix=/usr/local/php \nRUN make -j 4 \nRUN make install\nEXPOSE 9000\nCMD [""php-fpm""]\n```\n\n\n\n**Better version:**\n\n\n\n```\nFROM centos:latest\nRUN yum install epel-release -y && \\n    yum install -y gcc gcc-c++ make\n\nRUN wget http://docs.php.net/distributions/php-5.6.36.tar.gz && \\n    tar zxf php-5.6.36.tar.gz && \\n    cd php-5.6.36 && \\n    ./configure --prefix=/usr/local/php && \\n    make -j 4 && make install\nEXPOSE 9000\nCMD [""php-fpm""]\n```\n\n\n\n### 4.3.2 Cleaning up unused data\n\n- When using the RUN command in a Dockerfile, every time a new layer is created. If files are not deleted in the same layer where they were created, they will be carried on to another layer regardless of whether they are ultimately deleted or not. Therefore, it's important to clean up any residual data in each layer to minimize the size of the image.\n- Additionally, it's recommended to delete the application software packages used during the container image generation process.\n\n\n\n```\nFROM centos:latest\n\nRUN yum install epel-release -y && \\n    yum install -y gcc gcc-c++ make gd-devel libxml2-devel \\n    libcurl-devel libjpeg-devel libpng-devel openssl-devel \\n    libmcrypt-devel libxslt-devel libtidy-devel autoconf \\n    iproute net-tools telnet wget curl && \\n    yum clean all && \\n    rm -rf /var/cache/yum/*\n\nRUN wget http://docs.php.net/distributions/php-5.6.36.tar.gz && \\n    tar zxf php-5.6.36.tar.gz && \\n    cd php-5.6.36 && \\n    ./configure --prefix=/usr/local/php \\n    make -j 4 && make install && \\n    cd / && rm -rf php*\n```\n\n\n\n### 4.3.3 Multi-stage build image\n\nThere are two types of project container images: one copies the project code directly into the container image, which can be launched directly when using the container image the next time; and another type compiles the project source code and then copies it to the container image.\n\nBoth methods make the process of creating an image more complex and can result in large container images. It is recommended to use a multi-stage build approach to simplify the creation process and reduce the size of the container image.\n\n\nAn example:\n```\nFROM maven AS build\nADD ./pom.xml pom.xml\nADD ./src src/\nRUN mvn clean package\n\nFROM baizeyu/tomcat\nRUN rm -rf /usr/local/tomcat/webapps/ROOT\nCOPY --from=build target/*.war /usr/local/tomcat/webapps/ROOT.war\n```\n\n\nThe first stage uses the official Maven image as a base image and is named build. The ADD command is used to copy the pom.xml file and the source code files from the local directory to the container. The RUN command starts the Maven build process, which compiles the source code and generates the WAR file. The result of this stage is a new image with the compiled application ready for deployment in the next stage.\n\nThe second stage uses a custom Tomcat image named baizeyu/tomcat as the base image. The RUN command removes the default ROOT web application from the Tomcat container. The COPY command retrieves the previously built WAR file from the build stage using the --from flag and copies it to the Tomcat server's webapps directory with the name ROOT.war.",2023-04-22T11:33:25.313Z,hide,com.baizeyu.published.model.Published
644913089ba29477b0013f0e,"Deep analysis of Docker networking, achieving cross-host communication between containers using etcd+flannel","# 1. Default Docker Container Network Model\n\n## 1.1 Diagram\n\n<p align=""center"">\n<img src=""https://raw.githubusercontent.com/ClarenceWhite/BlogImage/main/images/newblog4-26-12-57-28.jpg"" id=""blog-image"" />\n</p>\n\n\n## 1.2 Concepts\n\n- docker0\n  - It is a Layer2 (OSI model) network device, a bridge \n  - By using a bridge, different ports that are supported by Linux can be connected together.\n  - To achieve multi-to-multi communication similar to a switch, you can use a bridge network in Docker.\n- veth pair\n  - It is a virtual ethernet device\n  - Appear in pairs, used to solve isolation between network namespaces.\n  - One end connected to Container network namespace, the other connected to the host network namespace\n\n# 2. How does the default network model of Docker containers work?\n\n## 2.1 From container to other networks\n\n<p align=""center""><img src=""https://raw.githubusercontent.com/ClarenceWhite/BlogImage/main/images/newblog4-26-12-58-14.jpg"" id=""blog-image"" /></p>\n\nLet's run a container first:\n\n```\ndocker run -d --name=app1 -p 9000:80 nginx:latest\n```\n\nOn the host ubuntu machine, check the iptables:\n\n```\niptables -t nat -vnL POSTROUTING\n------------------\nChain POSTROUTING (policy ACCEPT 0 packets, 0 bytes)\n pkts bytes target     prot opt in     out     source               destination\n  212 14431 MASQUERADE  all  --  *      !docker0  172.17.0.0/16        0.0.0.0/0\n    0     0 MASQUERADE  tcp  --  *      *       172.17.0.2           172.17.0.2           tcp dpt:80\n```\n\n## 2.2 From other networks to container\n\n<p align=""center""><img src=""https://raw.githubusercontent.com/ClarenceWhite/BlogImage/main/images/newblog4-26-12-58-41.jpg"" id=""blog-image"" /></p>\n\nWe now have a container running with its port 80 exposed, also a portforward from host 9000 to it, let's check out the iptables on host machine:\n\n```\niptables -t nat -vnL DOCKER\n------------\nChain DOCKER (2 references)\n pkts bytes target     prot opt in     out     source               destination\n    0     0 RETURN     all  --  docker0 *       0.0.0.0/0            0.0.0.0/0\n    0     0 DNAT       tcp  --  !docker0 *       0.0.0.0/0            0.0.0.0/0            tcp dpt:9000 to:172.17.0.2:80\n```\n\n\n# 3. Four types of Docker networks\n\n<p align=""center""><img src=""https://raw.githubusercontent.com/ClarenceWhite/BlogImage/main/images/newblog4-26-13-0-14.jpg"" id=""blog-image"" /></p>\n\n\n\n| Type                                                         | Usage                              | Explanation                                                  |\n| ------------------------------------------------------------ | ---------------------------------- | ------------------------------------------------------------ |\n| bridge [Bridge network]                                      | `--network bridge`                 | Bridged containers have a private interface connected to the Docker bridge virtual interface, which is then connected to the physical network interface of the host machine through a logical host interface. A bridge network is assigned an IP address range by default, which is 172.17.0.0/16. If no network model is specified when creating a container, the default bridge network is used. This is why the IP addresses of containers created without specifying a network model are in the 172.17.0.0/16 subnet. |\n| host [Host network]                                          | `--network host`                   | More open than a bridged network, a host network allows a container to directly share the host machine's network namespace. Therefore, the container can see as many network interfaces as the host machine has physical network interfaces. We can say that an open container is derived from a bridged network. |\n| none [No network]                                            | `--network none`                   | A closed container with only the loopback interface and cannot communicate with the outside world. |\n| container [Joined container A \| Joined container B] [Joined network] | `--network container:<name or ID>` | Each container has its own mount, PID, and user namespaces, but shares the same UTS, network, and IPC namespaces. As their network is shared, they can communicate via the loopback interface. They also have a private interface connected to the Docker bridge virtual interface, which is then connected to the physical network interface of the host machine through a logical host interface. |\n\n# 4. Application and examples of Docker network\n\n## 4.1 Check current network types\n\nCheck current network types in brief:\n\n```\ndocker network ls\n------------\nNETWORK ID     NAME      DRIVER    SCOPE\n0b4cf0e87225   bridge    bridge    local\n6249aa42ee72   host      host      local\n6bf470240b3b   none      null      local\n```\n\nInspect network types:\n\n```\ndocker network inspect bridge\n----------------\n[\n    {\n        ""Name"": ""bridge"",\n        ""Id"": ""0b4cf0e87225ac0a6f6381bdfb57fa3bb87c54ae93497a0b1d73a7b1dd6418ac"",\n        ""Created"": ""2023-04-20T15:40:47.687436042+01:00"",\n        ""Scope"": ""local"",\n        ""Driver"": ""bridge"",\n        ""EnableIPv6"": false,\n        ""IPAM"": {\n            ""Driver"": ""default"",\n            ""Options"": null,\n            ""Config"": [\n                {\n                    ""Subnet"": ""172.17.0.0/16"",\n                    ""Gateway"": ""172.17.0.1""\n                }\n            ]\n        },\n        ""Internal"": false,\n        ""Attachable"": false,\n        ""Ingress"": false,\n        ""ConfigFrom"": {\n            ""Network"": """"\n        },\n        ""ConfigOnly"": false,\n        ""Containers"": {\n            ""511752d687f722c87f873245ab51e41eef0e8f56ad78d88f3b10ca7fafc7d0df"": {\n                ""Name"": ""app1"",\n                ""EndpointID"": ""2b6d753792716e3b251eca087545751d3bf8c59a16f7f150c479f32184ec28fd"",\n                ""MacAddress"": ""02:42:ac:11:00:02"",\n                ""IPv4Address"": ""172.17.0.2/16"",\n                ""IPv6Address"": """"\n            }\n        },\n        ""Options"": {\n            ""com.docker.network.bridge.default_bridge"": ""true"",\n            ""com.docker.network.bridge.enable_icc"": ""true"",\n            ""com.docker.network.bridge.enable_ip_masquerade"": ""true"",\n            ""com.docker.network.bridge.host_binding_ipv4"": ""0.0.0.0"",\n            ""com.docker.network.bridge.name"": ""docker0"",\n            ""com.docker.network.driver.mtu"": ""1500""\n        },\n        ""Labels"": {}\n    }\n]\n```\n\nCheck supported network types by Docker:\n\n```\ndocker info | grep Network\n-----------\n  Network: bridge host ipvlan macvlan null overlay\n```\n\n\n## 4.2 Create specified network types\n\n### 4.2.1 bridge\n\nCheck manual page:\n\n```\ndocker network create --help\n```\n\nLet's create a bridge network using name 'mybridge0'\n\n```\ndocker network create -d bridge --subnet ""192.168.100.0/24"" --gateway ""192.168.100.1"" -o com.docker.network.bridge.name=docker1 mybridge0\n-----------------------\na928733f54ff9d886f97eea8e2e3af024ee354860aa3b53ce478e5bdb015e2b9\n```\n\nCheck the network we created just now:\n\n```\ndocker network ls\n--------------------\nNETWORK ID     NAME        DRIVER    SCOPE\n0b4cf0e87225   bridge      bridge    local\n6249aa42ee72   host        host      local\na928733f54ff   mybridge0   bridge    local\n6bf470240b3b   none        null      local\n```\n\nThen check bridge on our host machine:\n\n```\nip a s\n--------------------\n82: docker1: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default\n    link/ether 02:42:c0:2c:a1:2d brd ff:ff:ff:ff:ff:ff\n    inet 192.168.100.1/24 brd 192.168.100.255 scope global docker1\n       valid_lft forever preferred_lft forever\n```\n\nNext, let's start a container and connect it to the network we created just now:\n\n```\ndocker run -it --network mybridge0 --rm busybox\n--------------------------\n/ # ifconfig\neth0      Link encap:Ethernet  HWaddr 02:42:C0:A8:64:02\n          inet addr:192.168.100.2  Bcast:192.168.100.255  Mask:255.255.255.0\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:12 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0\n          RX bytes:1112 (1.0 KiB)  TX bytes:0 (0.0 B)\n\nlo        Link encap:Local Loopback\n          inet addr:127.0.0.1  Mask:255.0.0.0\n          UP LOOPBACK RUNNING  MTU:65536  Metric:1\n          RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000\n          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)\n/ # exit\n```\n\nAs we can see, the eth0 address of this container is what we configured in `mybridge0` just now!\n\n\n### 4.2.2 host\n\nInspect host type:\n\n```\ndocker network inspect host\n--------------------\n[\n    {\n        ""Name"": ""host"",\n        ""Id"": ""6249aa42ee7246a026a5df16cc1e56b6f81bb398429315723f825dce21e92e48"",\n        ""Created"": ""2023-04-19T16:36:33.457196045+01:00"",\n        ""Scope"": ""local"",\n        ""Driver"": ""host"",\n        ""EnableIPv6"": false,\n        ""IPAM"": {\n            ""Driver"": ""default"",\n            ""Options"": null,\n            ""Config"": []\n        },\n        ""Internal"": false,\n        ""Attachable"": false,\n        ""Ingress"": false,\n        ""ConfigFrom"": {\n            ""Network"": """"\n        },\n        ""ConfigOnly"": false,\n        ""Containers"": {},\n        ""Options"": {},\n        ""Labels"": {}\n    }\n]\n```\n\nLet's create another busybox using `host` network type:\n\n```\ndocker run -it --network host --rm busybox\n--------------------------\n/ # ifconfig\ndocker0   Link encap:Ethernet  HWaddr 02:42:7F:3F:7F:31\n          inet addr:172.17.0.1  Bcast:172.17.255.255  Mask:255.255.0.0\n          inet6 addr: fe80::42:7fff:fe3f:7f31/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:19069 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:21837 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0\n          RX bytes:1049180 (1.0 MiB)  TX bytes:374936966 (357.5 MiB)\n\ndocker1   Link encap:Ethernet  HWaddr 02:42:C0:2C:A1:2D\n          inet addr:192.168.100.1  Bcast:192.168.100.255  Mask:255.255.255.0\n          inet6 addr: fe80::42:c0ff:fe2c:a12d/64 Scope:Link\n          UP BROADCAST MULTICAST  MTU:1500  Metric:1\n          RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:5 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0\n          RX bytes:0 (0.0 B)  TX bytes:526 (526.0 B)\n\neth0      Link encap:Ethernet  HWaddr EA:B7:35:7B:CD:09\n          inet addr:100.115.93.74  Bcast:100.115.93.255  Mask:255.255.255.0\n          inet6 addr: fe80::e8b7:35ff:fe7b:cd09/64 Scope:Link\n          inet6 addr: fd00:30:31:0:e8b7:35ff:fe7b:cd09/64 Scope:Global\n          UP BROADCAST RUNNING MULTICAST  MTU:65520  Metric:1\n          RX packets:41712 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:31185 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000\n          RX bytes:908781796 (866.6 MiB)  TX bytes:2351185 (2.2 MiB)\n\nlo        Link encap:Local Loopback\n          inet addr:127.0.0.1  Mask:255.0.0.0\n          inet6 addr: ::1/128 Scope:Host\n          UP LOOPBACK RUNNING  MTU:65536  Metric:1\n          RX packets:40 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:40 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000\n          RX bytes:4080 (3.9 KiB)  TX bytes:4080 (3.9 KiB)\n\nvethf40e041 Link encap:Ethernet  HWaddr 56:95:0B:9D:EC:F8\n          inet6 addr: fe80::5495:bff:fe9d:ecf8/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:18 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0\n          RX bytes:0 (0.0 B)  TX bytes:1436 (1.4 KiB)\n\n/ #exit\n```\n\nWow, this information is exact the same as our host machine.\n\n**Hint**: you can also run an Nginx container that uses host type, then go to http://localhost on your host machine to verify this. \n\n### 4.2.3 none\n\nInspect none type:\n\n```\ndocker network inspect none\n-------------------------\n[\n    {\n        ""Name"": ""none"",\n        ""Id"": ""6bf470240b3bd3b99c08fd06e5e06e97bde830e23e1a97ffe89a5c6ea0b8b118"",\n        ""Created"": ""2023-04-19T16:36:33.450201607+01:00"",\n        ""Scope"": ""local"",\n        ""Driver"": ""null"",\n        ""EnableIPv6"": false,\n        ""IPAM"": {\n            ""Driver"": ""default"",\n            ""Options"": null,\n            ""Config"": []\n        },\n        ""Internal"": false,\n        ""Attachable"": false,\n        ""Ingress"": false,\n        ""ConfigFrom"": {\n            ""Network"": """"\n        },\n        ""ConfigOnly"": false,\n        ""Containers"": {},\n        ""Options"": {},\n        ""Labels"": {}\n    }\n]\n```\n\nLet's test this type of network using busybox container:\n\n```\ndocker run -it --network none --rm busybox\n-------------------------\n/ # ifconfig\nlo        Link encap:Local Loopback\n          inet addr:127.0.0.1  Mask:255.0.0.0\n          UP LOOPBACK RUNNING  MTU:65536  Metric:1\n          RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000\n          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)\n\n/ # exit\n```\n\nIt only has loopback address, nothing more!\n\n\n### 4.2.4 Shared networks\n\nFirstly, create a container that uses the default network type `bridge`:\n\n```\ndocker run -it --name c1 --rm busybox\n---------------------\n/ # ifconfig\neth0      Link encap:Ethernet  HWaddr 02:42:AC:11:00:03\n          inet addr:172.17.0.3  Bcast:172.17.255.255  Mask:255.255.0.0\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:6 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0\n          RX bytes:516 (516.0 B)  TX bytes:0 (0.0 B)\n\nlo        Link encap:Local Loopback\n          inet addr:127.0.0.1  Mask:255.0.0.0\n          UP LOOPBACK RUNNING  MTU:65536  Metric:1\n          RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000\n          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)\n\n/ # exit\n```\n\nThen create another contianer who will share the same network with c1:\n\n```\ndocker run -it --name c2 --network container:c1 --rm busybox\n----------------------\neth0      Link encap:Ethernet  HWaddr 02:42:AC:11:00:03\n          inet addr:172.17.0.3  Bcast:172.17.255.255  Mask:255.255.0.0\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:8 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0\n          RX bytes:656 (656.0 B)  TX bytes:0 (0.0 B)\n\nlo        Link encap:Local Loopback\n          inet addr:127.0.0.1  Mask:255.0.0.0\n          UP LOOPBACK RUNNING  MTU:65536  Metric:1\n          RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000\n          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)\n\n/ # exit\n```\n\nDid you see? They have the same network address!\nLet's verify this by starting an httpd service in c2 and access it via c1:\n\n```\n/ # echo ""hello "" >> /tmp/index.html\n/ # ls /tmp\n------------\nindex.html\n/ # httpd -h /tmp\n/ # netstat -nlp (check port 80 status here)\n------------\nActive Internet connections (only servers)\nProto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name\ntcp        0      0 :::80                   :::*                    LISTEN      16/httpd\nActive UNIX domain sockets (only servers)\nProto RefCnt Flags       Type       State         I-Node PID/Program name    Path\n```\n\nGo back to c1, visit localhost:\n\n```\n/ # wget localhost\n-----------------\nConnecting to localhost (127.0.0.1:80)\nsaving to 'index.html'\nindex.html           100% |********************************************************************************************************************************|    40  0:00:00 ETA\n'index.html' saved\n\n/ # cat index.html\n-------------------------\nI am verifying docker shared network...\n```\n\nCool, we get it from c1!\n\nFinally, let's check if they will share the file system in c1:\n\n```\n/ # cd /tmp/\n/tmp # ls\n/tmp #\n```\n\nNothing under /tmp on c1, so they are only sharing the network.\n\n\n# 5. Implementing communication between Docker containers across multiple hosts\n\n## 5.1 The need for communication between Docker containers across multiple hosts\n\n- Since the environment in which Docker containers run is similar to running services on a LAN, they cannot be accessed directly from outside. If port mapping is used on the Docker host, it can lead to serious consumption of ports.\n- This allows for easy access to services provided by containers running on different Docker hosts.\n\n## 5.2 Solution for implementing communication between containers across Docker Hosts\n\n### 5.2.1 Docker Native Solutions\n\n- overlay\n  - Docker native overlay network based on VXLAN encapsulation\n- macvlan\n  - Docker host NIC interface is logically divided into multiple sub-interfaces, each sub-interface identifies a VLAN, and the container interface is directly connected to the Docker Host\n- NIC interface\n  - Forwarding to another Docker Host via routing policy\n\n### 5.2.2 Third party programs\n\n#### 5.2.2.1 Tunnel Solutions\n\n- Flannel\n  - Supports UDP and VLAN encapsulated transport\n- Weave\n  - UDP and VXLAN support\n- OpenvSwitch\n  - VXLAN and GRE protocol support\n\n#### 5.2.2.2 Routing Solutions\n\n- Calico\n\n  - Supports BGP protocol and IPIP tunneling\n  - Each host acts as a virtual route for communication between different host containers via the BGP protocol.\n\n## 5.3 Flannel\n\n### 5.3.1 Introduction to overlay network\n\nOverlay networking is a new data format that encapsulates Layer 2 messages on top of IP messages through some agreed communication protocol without changing the existing network infrastructure. This not only makes full use of the proven IP routing protocol process data distribution; but also the use of extended isolated identification bits in Overlay technology enables the support of up to 16M users beyond the 4000 number limit of VLANs and allows broadcast traffic to be converted into multicast traffic when necessary to avoid broadcast data flooding.\n\nAs a result, Overlay networks are in fact the most dominant solution for container cross-node data transmission and routing today.\n\n### 5.3.2 Introduction to Flannel\n\nFlannel is an overlay network tool designed by the CoreOS team for Kubernetes to help every CoreOS host using Kuberentes have a full subnet. Flannel provides a virtual network for containers by assigning a subnet to each host. It is based on Linux TUN/TAP and uses UDP to encapsulate IP packets to create the overlay network and maintain the distribution of the network with the help of etcd. Flannel is a simple and easy way to configure a layer 3 network fabric designed for Kubernetes.\n\n### 5.3.3 How Flannel Works\n\nFlannel is a network planning service designed by the CoreOS team for Kubernetes. Simply put, it allows Docker containers created by different node hosts in a cluster to have a cluster-wide unique virtual IP address. In the default Docker configuration, each Node's Docker service is responsible for assigning IP addresses to the containers on that Node, but containers within a Node can access each other, but across a network of hosts (Nodes) they cannot communicate with each other. containers on different nodes can obtain ""same intranet"" and ""non-duplicate"" IP addresses, and allow containers on different nodes to communicate directly over the intranet IP. Flannel uses etcd to store configuration data and subnet assignment information. flannel starts up with a background process that first retrieves the configuration and list of subnets in use, then selects an available subnet and attempts to register it. etcd also stores the corresponding ip of each host. flannel uses the watch mechanism of etcd to monitor `/coreos.com/network/subnets` and maintains a routing table based on it. To improve performance, flannel has optimised the Universal TAP/TUN device to proxy the ip slicing between TUN and UDP. The following schematic illustrates this:\n\n<p align=""center""><img src=""https://raw.githubusercontent.com/ClarenceWhite/BlogImage/main/images/newblog4-26-13-1-10.jpg"" id=""blog-image"" /></p>\n\n```text\n1. After the data is sent from the source container, it is forwarded via the docker0 virtual NIC on the host to the flannel0 virtual NIC, which is a P2P virtual NIC with the flanneld service listening on the other end of the NIC.\n2. Flannel maintains an inter-node routing table via the Etcd service, which holds the subnet segment information for each node host.\n3. The flanneld service of the source host encapsulates the original data content in UDP and delivers it to the flanneld service of the destination node according to its own routing table, where the data is unpackaged and then goes directly to the flannel0 virtual NIC of the destination node and then is forwarded to the docker0 virtual NIC of the destination host, and finally is routed by docker0 is routed to the destination container, just like local container communication.\n```\n\n\n\n## 5.4 ETCD\n\netcd is an open source project launched by the CoreOS team in June 2013, its goal is to build a highly available distributed key-value (key-value) database. etcd internally uses the `raft` protocol as the consistency algorithm, and etcd is implemented in the Go language.\n\netcd is used as a service discovery system and is characterised by:\n\n- Simple: easy to install and configure, and provides an HTTP API for interaction, which is also simple to use\n- Secure: supports SSL certificate validation\n- Fast: according to the official benchmark data, a single instance supports 2k+ reads per second\n- Reliable: draft algorithm for data availability and consistency in distributed systems\n\n## 5.5 ETCD Deployment\n\nHere we will use two Fedora Linux machines named with 'node-01' and 'node-02', both the host firewall and SELINUX should be turned off.\n\n### 5.5.0 Turn off firewall and selinux\n\nCheck firewall status:\n\n```\nsystemctl status firewalld\n---------------------\n○ firewalld.service - firewalld - dynamic firewall daemon\n     Loaded: loaded (/usr/lib/systemd/system/firewalld.service; disabled; preset: enabled)\n    Drop-In: /usr/lib/systemd/system/service.d\n             └─10-timeout-abort.conf\n     Active: inactive (dead)\n       Docs: man:firewalld(1)\n```\n\nIf firewall is running on your machine, just run these:\n\n```\nsystemctl stop firewalld\nsystemctl disable firewalld\n```\n\nCheck selinux:\n\n```\nsestatus\n-------------------\nSELinux status:                 disabled\n```\n\nIf your SELinux status is active, do this:\n\n```\nvim /etc/selinux/config\n--------------------------\nSELINUX=disabled\n```\n\nFinally, don't forget to reboot! \n\n### 5.5.1  Configure hostnames\n\n```\nhostnamectl set-hostname node1\n```\n\n```\nhostnamectl set-hostname node2\n```\n\n### 5.5.2 Configure host ip addresses\n\nAs I already have ip addresses for both of my machine, so check them with:\n\n(node-01)\n\n```\nifconfig\n----------------\nenp0s5: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet 10.211.55.10  netmask 255.255.255.0  broadcast 10.211.55.255\n        inet6 fe80::21c:42ff:fe95:201e  prefixlen 64  scopeid 0x20<link>\n        inet6 fdb2:2c26:f4e4:0:21c:42ff:fe95:201e  prefixlen 64  scopeid 0x0<global>\n        ether 00:1c:42:95:20:1e  txqueuelen 1000  (Ethernet)\n        RX packets 12647  bytes 16599159 (15.8 MiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 3226  bytes 284194 (277.5 KiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nlo: flags=73<UP,LOOPBACK,RUNNING>  mtu 65536\n        inet 127.0.0.1  netmask 255.0.0.0\n        inet6 ::1  prefixlen 128  scopeid 0x10<host>\n        loop  txqueuelen 1000  (Local Loopback)\n        RX packets 17  bytes 1008 (1008.0 B)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 17  bytes 1008 (1008.0 B)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n```\n\n(node-02)\n\n```\nenp0s5: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet 10.211.55.11  netmask 255.255.255.0  broadcast 10.211.55.255\n        inet6 fdb2:2c26:f4e4:0:21c:42ff:fede:7aea  prefixlen 64  scopeid 0x0<global>\n        inet6 fe80::21c:42ff:fede:7aea  prefixlen 64  scopeid 0x20<link>\n        ether 00:1c:42:de:7a:ea  txqueuelen 1000  (Ethernet)\n        RX packets 12030  bytes 16672288 (15.8 MiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 2528  bytes 190407 (185.9 KiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nlo: flags=73<UP,LOOPBACK,RUNNING>  mtu 65536\n        inet 127.0.0.1  netmask 255.0.0.0\n        inet6 ::1  prefixlen 128  scopeid 0x10<host>\n        loop  txqueuelen 1000  (Local Loopback)\n        RX packets 17  bytes 1008 (1008.0 B)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 17  bytes 1008 (1008.0 B)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n```\n\nIf there is no ip address on your virtual machine, you can add one via:\n\n```\nvim /etc/sysconfig/network-scripts/ifcfg-[interface-name]\n---------------------------\nIPADDR=[ip-address]\nNETMASK=[netmask]\nGATEWAY=[gateway-address]\n---------------------------\nsystemctl restart network\n```\n\n### 5.5.3 Hostname and IP address resolution\n\nFor node1:\n\n```\nvim /etc/hosts\n-------------------------\n# Loopback entries; do not change.\n# For historical reasons, localhost precedes localhost.localdomain:\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n# See hosts(5) for proper format and other examples:\n10.211.55.10 node1\n10.211.55.11 node2\n```\n\nFor node2:\n\n```\nvim /etc/hosts\n-------------------------\n# Loopback entries; do not change.\n# For historical reasons, localhost precedes localhost.localdomain:\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n# See hosts(5) for proper format and other examples:\n10.211.55.10 node1\n10.211.55.11 node2\n```\n\n### 5.5.4 Turn on forward\n\nFor both machines, enable ipv4 ip_forward:\n\n```\nvim /etc/sysctl.conf\n--------------------\nnet.ipv4.ip_forward=1\n```\n\n```\nsysctl -p\n--------------\nnet.ipv4.ip_forward = 1\n```\n\nFinally, we need verify if they can communicate with each other by pinging each other.\n\n### 5.5.5 etcd Installation\n\nSame, install this on both:\n\n```\nyum update -y\nyum install etcd -y\nsystemctl status etcd\n-----------------------\n○ etcd.service - Etcd Server\n     Loaded: loaded (/usr/lib/systemd/system/etcd.service; disabled; preset: disabled)\n    Drop-In: /usr/lib/systemd/system/service.d\n             └─10-timeout-abort.conf\n     Active: inactive (dead)\n```\n\nNow, etcd has been installed, we need to change configurations!\n\n### 5.5.6 etcd Configuration\n\nOn node-01, change the config file into this:\n\n```\nvim /etc/etcd/etcd.conf\n----------------------------\n# [member]\nETCD_NAME=""node1""\nETCD_DATA_DIR=""/var/lib/etcd/node1.etcd""\n#ETCD_WAL_DIR=""""\n#ETCD_SNAPSHOT_COUNT=""10000""\n#ETCD_HEARTBEAT_INTERVAL=""100""\n#ETCD_ELECTION_TIMEOUT=""1000""\nETCD_LISTEN_PEER_URLS=""http://0.0.0.0:2380""\nETCD_LISTEN_CLIENT_URLS=""http://0.0.0.0:2379, http://0.0.0.0:4001""\n#ETCD_MAX_SNAPSHOTS=""5""\n#ETCD_MAX_WALS=""5""\n#ETCD_CORS=""""\n#\n#[cluster]\nETCD_INITIAL_ADVERTISE_PEER_URLS=""http://10.211.55.10:2380""\n# if you use different ETCD_NAME (e.g. test), set ETCD_INITIAL_CLUSTER value for this name, i.e. ""test=http://...""\nETCD_INITIAL_CLUSTER=""node1=http://10.211.55.10:2380, node2=http://10.211.55.11:2380""\n#ETCD_INITIAL_CLUSTER_STATE=""new""\n#ETCD_INITIAL_CLUSTER_TOKEN=""etcd-cluster""\nETCD_ADVERTISE_CLIENT_URLS=""http://10.211.55.10:2379, http://10.211.55.10:4001""\n#ETCD_DISCOVERY=""""\n#ETCD_DISCOVERY_SRV=""""\n#ETCD_DISCOVERY_FALLBACK=""proxy""\n#ETCD_DISCOVERY_PROXY=""""\n#ETCD_STRICT_RECONFIG_CHECK=""false""\n#ETCD_AUTO_COMPACTION_RETENTION=""0""\n#\n#[proxy]\n#ETCD_PROXY=""off""\n#ETCD_PROXY_FAILURE_WAIT=""5000""\n#ETCD_PROXY_REFRESH_INTERVAL=""30000""\n#ETCD_PROXY_DIAL_TIMEOUT=""1000""\n#ETCD_PROXY_WRITE_TIMEOUT=""5000""\n#ETCD_PROXY_READ_TIMEOUT=""0""\n#\n#[security]\n#ETCD_CERT_FILE=""""\n#ETCD_KEY_FILE=""""\n#ETCD_CLIENT_CERT_AUTH=""false""\n#ETCD_TRUSTED_CA_FILE=""""\n#ETCD_AUTO_TLS=""false""\n#ETCD_PEER_CERT_FILE=""""\n#ETCD_PEER_KEY_FILE=""""\n#ETCD_PEER_CLIENT_CERT_AUTH=""false""\n#ETCD_PEER_TRUSTED_CA_FILE=""""\n#ETCD_PEER_AUTO_TLS=""false""\n#\n#[logging]\n#ETCD_DEBUG=""false""\n# examples for -log-package-levels etcdserver=WARNING,security=DEBUG\n#ETCD_LOG_PACKAGE_LEVELS=""""\n```\n\nOn node-02, change it to something similar:\n\n```\nvim /etc/etcd/etcd.conf\n----------------------------\n#[member]\nETCD_NAME=""node2""\nETCD_DATA_DIR=""/var/lib/etcd/node2.etcd""\n#ETCD_WAL_DIR=""""\n#ETCD_SNAPSHOT_COUNT=""10000""\n#ETCD_HEARTBEAT_INTERVAL=""100""\n#ETCD_ELECTION_TIMEOUT=""1000""\nETCD_LISTEN_PEER_URLS=""http://0.0.0.0:2380""\nETCD_LISTEN_CLIENT_URLS=""http://0.0.0.0:2379,http://0.0.0.0:4001""\n#ETCD_MAX_SNAPSHOTS=""5""\n#ETCD_MAX_WALS=""5""\n#ETCD_CORS=""""\n#\n#[cluster]\nETCD_INITIAL_ADVERTISE_PEER_URLS=""http://10.211.55.11:2380""\n# if you use different ETCD_NAME (e.g. test), set ETCD_INITIAL_CLUSTER value for this name, i.e. ""test=http://...""\nETCD_INITIAL_CLUSTER=""node1=http://10.211.55.10:2380,node2=http://10.211.55.11:2380""\n#ETCD_INITIAL_CLUSTER_STATE=""new""\n#ETCD_INITIAL_CLUSTER_TOKEN=""etcd-cluster""\nETCD_ADVERTISE_CLIENT_URLS=""http://10.211.55.11:2379,http://10.211.55.11:4001""\n#ETCD_DISCOVERY=""""\n#ETCD_DISCOVERY_SRV=""""\n#ETCD_DISCOVERY_FALLBACK=""proxy""\n#ETCD_DISCOVERY_PROXY=""""\n#ETCD_STRICT_RECONFIG_CHECK=""false""\n#ETCD_AUTO_COMPACTION_RETENTION=""0""\n#\n#[proxy]\n#ETCD_PROXY=""off""\n#ETCD_PROXY_FAILURE_WAIT=""5000""\n#ETCD_PROXY_REFRESH_INTERVAL=""30000""\n#ETCD_PROXY_DIAL_TIMEOUT=""1000""\n#ETCD_PROXY_WRITE_TIMEOUT=""5000""\n#ETCD_PROXY_READ_TIMEOUT=""0""\n#\n#[security]\n#ETCD_CERT_FILE=""""\n#ETCD_KEY_FILE=""""\n#ETCD_CLIENT_CERT_AUTH=""false""\n#ETCD_TRUSTED_CA_FILE=""""\n#ETCD_AUTO_TLS=""false""\n#ETCD_PEER_CERT_FILE=""""\n#ETCD_PEER_KEY_FILE=""""\n#ETCD_PEER_CLIENT_CERT_AUTH=""false""\n#ETCD_PEER_TRUSTED_CA_FILE=""""\n#ETCD_PEER_AUTO_TLS=""false""\n#\n#[logging]\n#ETCD_DEBUG=""false""\n# examples for -log-package-levels etcdserver=WARNING,security=DEBUG\n#ETCD_LOG_PACKAGE_LEVELS=""""\n```\n\n### 5.5.7 Check etcd status on both nodes\n\nOn node1:\n\n```\nsystemctl status etcd\n-------------------------\n● etcd.service - Etcd Server\n     Loaded: loaded (/usr/lib/systemd/system/etcd.service; enabled; preset: disabled)\n    Drop-In: /usr/lib/systemd/system/service.d\n             └─10-timeout-abort.conf\n     Active: active (running) since Tue 2023-04-25 18:08:52 IST; 5min ago\n   Main PID: 1278 (etcd)\n      Tasks: 8 (limit: 2218)\n     Memory: 13.9M\n        CPU: 4.939s\n     CGroup: /system.slice/etcd.service\n             └─1278 /usr/bin/etcd\n\nApr 25 18:08:52 node1 bash[1278]: {""level"":""info"",""ts"":""2023-04-25T18:08:52.713+0100"",>\nApr 25 18:08:52 node1 bash[1278]: {""level"":""info"",""ts"":""2023-04-25T18:08:52.714+0100"",>\nApr 25 18:08:52 node1 bash[1278]: {""level"":""info"",""ts"":""2023-04-25T18:08:52.715+0100"",>\nApr 25 18:08:52 node1 bash[1278]: {""level"":""info"",""ts"":""2023-04-25T18:08:52.717+0100"",>\nApr 25 18:08:52 node1 bash[1278]: {""level"":""info"",""ts"":""2023-04-25T18:08:52.717+0100"",>\nApr 25 18:08:52 node1 systemd[1]: Started etcd.service - Etcd Server.\nApr 25 18:08:52 node1 bash[1278]: {""level"":""info"",""ts"":""2023-04-25T18:08:52.718+0100"",>\nApr 25 18:08:52 node1 bash[1278]: {""level"":""info"",""ts"":""2023-04-25T18:08:52.720+0100"",>\nApr 25 18:08:52 node1 bash[1278]: {""level"":""info"",""ts"":""2023-04-25T18:08:52.720+0100"",>\nApr 25 18:08:52 node1 bash[1278]: {""level"":""info"",""ts"":""2023-04-25T18:08:52.720+0100"",\n```\n\nOn node2:\n\n```\nsystemctl status etcd\n-------------------------\n● etcd.service - Etcd Server\n     Loaded: loaded (/usr/lib/systemd/system/etcd.service; enabled; preset: disabled)\n    Drop-In: /usr/lib/systemd/system/service.d\n             └─10-timeout-abort.conf\n     Active: active (running) since Tue 2023-04-25 18:08:52 IST; 6min ago\n   Main PID: 1081 (etcd)\n      Tasks: 8 (limit: 2218)\n     Memory: 14.9M\n        CPU: 4.265s\n     CGroup: /system.slice/etcd.service\n             └─1081 /usr/bin/etcd\n\nApr 25 18:08:52 node2 bash[1081]: {""level"":""info"",""ts"":""2023-04-25T18:08:52.716+0100"",""c>\nApr 25 18:08:52 node2 bash[1081]: {""level"":""info"",""ts"":""2023-04-25T18:08:52.716+0100"",""c>\nApr 25 18:08:52 node2 bash[1081]: {""level"":""info"",""ts"":""2023-04-25T18:08:52.717+0100"",""c>\nApr 25 18:08:52 node2 bash[1081]: {""level"":""info"",""ts"":""2023-04-25T18:08:52.717+0100"",""c>\nApr 25 18:08:52 node2 bash[1081]: {""level"":""info"",""ts"":""2023-04-25T18:08:52.718+0100"",""c>\nApr 25 18:08:52 node2 systemd[1]: Started etcd.service - Etcd Server.\nApr 25 18:08:52 node2 bash[1081]: {""level"":""info"",""ts"":""2023-04-25T18:08:52.722+0100"",""c>\nApr 25 18:08:52 node2 bash[1081]: {""level"":""info"",""ts"":""2023-04-25T18:08:52.722+0100"",""c>\nApr 25 18:08:52 node2 bash[1081]: {""level"":""info"",""ts"":""2023-04-25T18:08:52.724+0100"",""c>\nApr 25 18:08:52 node2 bash[1081]: {""level"":""info"",""ts"":""2023-04-25T18:08:52.724+0100"",""c>\n```\n\nAs etcd is using port 2380, if you have any errors/issues with starting it and set up the connection between nodes, just try to check if 2380 is opened, for example, if you want to verify the connectivity from node1 and node2, you can use the following methods:\n\n- use `telnet` on node1:\n\n  ```\n  dnf install telnet\n  telnet node2 2380\n  ---------------\n  Trying 10.211.55.11...\n  Connected to node2.\n  Escape character is '^]'.\n  Connection closed by foreign host.\n  ```\n\n- use `nmap` on node1:\n\n  ```\n  dnf install nmap\n  nmap -p 2380 node2\n  -----------------\n  Starting Nmap 7.93 ( https://nmap.org ) at 2023-04-25 18:19 IST\n  Nmap scan report for node2 (10.211.55.11)\n  Host is up (0.00052s latency).\n  \n  PORT     STATE SERVICE\n  2380/tcp open  etcd-server\n  MAC Address: 00:1C:42:DE:7A:EA (Parallels)\n  \n  Nmap done: 1 IP address (1 host up) scanned in 0.30 seconds\n  ```\n\n- use `lsof` on node2:\n\n  ```\n  lsof -i :2380\n  -------------\n  COMMAND  PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\n  etcd    1081 etcd    3u  IPv6  25415      0t0  TCP *:etcd-server (LISTEN)\n  etcd    1081 etcd   13u  IPv4  25419      0t0  TCP node2:39382->node1:etcd-server (ESTABLISHED)\n  etcd    1081 etcd   15u  IPv4  25435      0t0  TCP node2:39392->node1:etcd-server (ESTABLISHED)\n  etcd    1081 etcd   16u  IPv6  25437      0t0  TCP node2:etcd-server->node1:51804 (ESTABLISHED)\n  etcd    1081 etcd   17u  IPv6  25438      0t0  TCP node2:etcd-server->node1:51806 (ESTABLISHED)\n  etcd    1081 etcd   18u  IPv6  24346      0t0  TCP node2:etcd-server->node1:51814 (ESTABLISHED)\n  etcd    1081 etcd   23u  IPv4  25446      0t0  TCP node2:42870->node1:etcd-server (ESTABLISHED)\n  etcd    1081 etcd   24u  IPv6  24353      0t0  TCP node2:etcd-server->node1:51820 (ESTABLISHED)\n  ```\n\n- use `netstat`:\n\n  ```\n  netstat -tunlp | grep -E '2380|4001'\n  ----------------------\n  tcp6       0      0 :::2380                 :::*                    LISTEN      1278/etcd\n  tcp6       0      0 :::4001                 :::*                    LISTEN      1278/etcd\n  ```\n\n### 5.5.8 Check the health of etcd cluster\n\n```\netcdctl endpoint health\n-----------------\n127.0.0.1:2379 is healthy: successfully committed proposal: took = 6.241474ms\n```\n\n```\netcdctl member list\n------------------\n95085dc63d7deee3, started, node1, http://10.211.55.10:2380, http://10.211.55.10:2379,http://10.211.55.10:4001, false\nbd93686a68a54c2d, started, node2, http://10.211.55.11:2380, http://10.211.55.11:2379,http://10.211.55.11:4001, false\n(here 'false' indicates whether it is leader)\n```\n\n## 5.6 Flannel Deployment\n\n### 5.6.1 Flannel Installation\n\nThis is the official releases of Flannel: https://github.com/flannel-io/flannel/releases\n\nAs I am using Apple M1 chip (arm64 arch), I will download the arm64 tar to my virtual Fedora machines:\n\n```\nwget https://github.com/flannel-io/flannel/releases/download/v0.21.4/flannel-v0.21.4-linux-arm64.tar.gz\n\nls\n-----------\nflannel-v0.21.4-linux-arm64.tar.gz\n\ntar -xvzf flannel-v0.21.4-linux-arm64.tar.gz\nls \n------------\nflanneld  mk-docker-opts.sh  README.md\n```\n\nThen we are going to add flannel configuration to etcd via `etcdctl`:\n\nFor node1:\n\n```\netcdctl --endpoints http://10.211.55.10:2379 put /coreos.com/network/config '{""Network"": ""10.0.0.0/16"", ""SubnetLen"": 24, ""SubnetMin"": ""10.0.1.0"",""SubnetMax"": ""10.0.20.0"", ""Backend"": {""Type"": ""vxlan""}}'\n--------------\nOK\n```\n\nFor node2:\n\n```\netcdctl --endpoints http://10.211.55.11:2379 put /coreos.com/network/config '{""Network"": ""10.0.0.0/16"", ""SubnetLen"": 24, ""SubnetMin"": ""10.0.1.0"",""SubnetMax"": ""10.0.20.0"", ""Backend"": {""Type"": ""vxlan""}}'\n--------------\nOK\n```\n\n### 5.6.2 Change flanneld Configuration\n\nFirst copy the two extracted from our tar file to /usr/local/bin:\n\n```\ncp ~/flanneld /usr/local/bin\ncp ~/mk-docker-opts.sh /usr/local/bin\n```\n\nThen change the systemd config, for node1:\n\n```\nvim /etc/systemd/system/flanneld.service\n-------------------------\n[Unit]\nDescription=Flanneld\nDocumentation=https://github.com/coreos/flannel\nAfter=network.target\nBefore=docker.service\n\n[Service]\nUser=root\nExecStartPost=/usr/local/bin/mk-docker-opts.sh\nExecStart=/usr/local/bin/flanneld \\n--etcd-endpoints=""http://10.211.55.10:2379,http://10.211.55.11:2379"" \\n--iface=10.211.55.10 \\n--ip-masq=true \\n--etcd-prefix=/coreos.com/network\nRestart=on-failure\nType=notify\nLimitNOFILE=65536\n\n[Install]\nWantedBy=multi-user.target\n```\n\nFor node2:\n\n```\nvim /etc/systemd/system/flanneld.service\n-------------------------\n[Unit]\nDescription=Flanneld\nDocumentation=https://github.com/coreos/flannel\nAfter=network.target\nBefore=docker.service\n\n[Service]\nUser=root\nExecStartPost=/usr/local/bin/mk-docker-opts.sh\nExecStart=/usr/local/bin/flanneld \\n--etcd-endpoints=""http://10.211.55.10:2379,http://10.211.55.11:2379"" \\n--iface=10.211.55.11 \\n--ip-masq=true \\n--etcd-prefix=/coreos.com/network\nRestart=on-failure\nType=notify\nLimitNOFILE=65536\n\n[Install]\nWantedBy=multi-user.target\n```\n\nAfter modifying the systemd config, we need to reload the daemon and start flanneld:\n\n```\nsystemctl daemon-reload\nsystemctl start flanneld\n-------------------\n● flanneld.service - Flanneld\n     Loaded: loaded (/etc/systemd/system/flanneld.service; enabled; preset: disabled)\n    Drop-In: /usr/lib/systemd/system/service.d\n             └─10-timeout-abort.conf\n     Active: active (running) since Tue 2023-04-25 23:47:01 IST; 13s ago\n       Docs: https://github.com/coreos/flannel\n    Process: 10162 ExecStartPost=/usr/local/bin/mk-docker-opts.sh (code=exited, status=0/SUCCESS)\n   Main PID: 10129 (flanneld)\n      Tasks: 9 (limit: 2218)\n     Memory: 36.6M\n        CPU: 335ms\n     CGroup: /system.slice/flanneld.service\n             └─10129 /usr/local/bin/flanneld --etcd-endpoints=http://10.211.55.10:2379,http://10.211.55.11:2379 --iface=10.211.55.10 --ip-masq=true --etcd-prefix=/coreos.com/net>\n\nApr 25 23:47:01 node1 flanneld[10129]: I0425 23:47:01.063815   10129 main.go:439] Running backend.\nApr 25 23:47:01 node1 flanneld[10129]: I0425 23:47:01.064017   10129 iptables.go:290] generated 3 rules\nApr 25 23:47:01 node1 flanneld[10129]: I0425 23:47:01.064061   10129 vxlan_network.go:64] watching for new subnet leases\nApr 25 23:47:01 node1 flanneld[10129]: I0425 23:47:01.076946   10129 registry.go:291] registry: watching subnets starting from rev 8\nApr 25 23:47:01 node1 flanneld[10129]: I0425 23:47:01.077123   10129 watch.go:51] Batch elem [0] is { subnet.Event{Type:0, Lease:subnet.Lease{EnableIPv4:true, EnableIPv6:false, >\nApr 25 23:47:01 node1 flanneld[10129]: I0425 23:47:01.080774   10129 local_manager.go:313] manager.WatchLease: sending reset results...\nApr 25 23:47:01 node1 flanneld[10129]: I0425 23:47:01.080815   10129 local_manager.go:390] Waiting for 22h59m58.99995396s to renew lease\nApr 25 23:47:01 node1 flanneld[10129]: I0425 23:47:01.102726   10129 iptables.go:283] bootstrap done\nApr 25 23:47:01 node1 flanneld[10129]: I0425 23:47:01.126716   10129 iptables.go:283] bootstrap done\nApr 25 23:47:01 node1 systemd[1]: Started flanneld.service - Flanneld.\n```\n\nPerfect!\n\n### 5.6.3 View the configuration information generated by Flannel on each node\n\n- Node1:\n\nThe config generated by flannel can be found here:\n\n```\nls /run/flannel/\n---------------\nsubnet.env\n\ncat /run/flannel/subnet.env\n---------------\nFLANNEL_NETWORK=10.0.0.0/16\nFLANNEL_SUBNET=10.0.13.1/24\nFLANNEL_MTU=1450\nFLANNEL_IPMASQ=true\n```\n\nUsing `ifconfig` we can see that a network on the host machine named with 'flannel.1' has been created:\n\n```\nifconfig\n---------------\ndocker0: flags=4099<UP,BROADCAST,MULTICAST>  mtu 1500\n        inet 172.17.0.1  netmask 255.255.0.0  broadcast 172.17.255.255\n        inet6 fe80::42:a1ff:fe08:e168  prefixlen 64  scopeid 0x20<link>\n        ether 02:42:a1:08:e1:68  txqueuelen 0  (Ethernet)\n        RX packets 8309  bytes 348610 (340.4 KiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 50196  bytes 73261483 (69.8 MiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nenp0s5: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet 10.211.55.10  netmask 255.255.255.0  broadcast 10.211.55.255\n        inet6 fe80::21c:42ff:fe95:201e  prefixlen 64  scopeid 0x20<link>\n        inet6 fdb2:2c26:f4e4:0:21c:42ff:fe95:201e  prefixlen 64  scopeid 0x0<global>\n        ether 00:1c:42:95:20:1e  txqueuelen 1000  (Ethernet)\n        RX packets 1257821  bytes 907345118 (865.3 MiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 784986  bytes 94347614 (89.9 MiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nflannel.1: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1450\n        inet 10.0.13.0  netmask 255.255.255.255  broadcast 0.0.0.0\n        inet6 fe80::407e:caff:fe8f:7c99  prefixlen 64  scopeid 0x20<link>\n        ether 42:7e:ca:8f:7c:99  txqueuelen 0  (Ethernet)\n        RX packets 0  bytes 0 (0.0 B)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 0  bytes 0 (0.0 B)\n        TX errors 0  dropped 9 overruns 0  carrier 0  collisions 0\n\nlo: flags=73<UP,LOOPBACK,RUNNING>  mtu 65536\n        inet 127.0.0.1  netmask 255.0.0.0\n        inet6 ::1  prefixlen 128  scopeid 0x10<host>\n        loop  txqueuelen 1000  (Local Loopback)\n        RX packets 9033  bytes 492352 (480.8 KiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 9033  bytes 492352 (480.8 KiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n```\n\n- Node2:\n\n```\nls /run/flannel/\n--------------------\nsubnet.env\n\ncat /run/flannel/subnet.env\n---------------------\nFLANNEL_NETWORK=10.0.0.0/16\nFLANNEL_SUBNET=10.0.14.1/24\nFLANNEL_MTU=1450\nFLANNEL_IPMASQ=true\n```\n\n```\nifconfig\n------------------\nenp0s5: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet 10.211.55.11  netmask 255.255.255.0  broadcast 10.211.55.255\n        inet6 fe80::21c:42ff:fede:7aea  prefixlen 64  scopeid 0x20<link>\n        inet6 fdb2:2c26:f4e4:0:21c:42ff:fede:7aea  prefixlen 64  scopeid 0x0<global>\n        ether 00:1c:42:de:7a:ea  txqueuelen 1000  (Ethernet)\n        RX packets 1330986  bytes 1038765119 (990.6 MiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 780934  bytes 77990387 (74.3 MiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nflannel.1: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1450\n        inet 10.0.14.0  netmask 255.255.255.255  broadcast 0.0.0.0\n        inet6 fe80::b455:9bff:fe5a:ac7c  prefixlen 64  scopeid 0x20<link>\n        ether b6:55:9b:5a:ac:7c  txqueuelen 0  (Ethernet)\n        RX packets 0  bytes 0 (0.0 B)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 0  bytes 0 (0.0 B)\n        TX errors 0  dropped 9 overruns 0  carrier 0  collisions 0\n\nlo: flags=73<UP,LOOPBACK,RUNNING>  mtu 65536\n        inet 127.0.0.1  netmask 255.0.0.0\n        inet6 ::1  prefixlen 128  scopeid 0x10<host>\n        loop  txqueuelen 1000  (Local Loopback)\n        RX packets 9528  bytes 500098 (488.3 KiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 9528  bytes 500098 (488.3 KiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n```\n\n## 5.7 Docker Configuration\n\nI will only demo using node1 here, node2 should be the same.\n\nCheck docker env file:\n\n```\ncat /run/docker_opts.env\n-----------------\nDOCKER_OPT_BIP=""--bip=10.0.13.1/24""\nDOCKER_OPT_IPMASQ=""--ip-masq=false""\nDOCKER_OPT_MTU=""--mtu=1450""\nDOCKER_OPTS="" --bip=10.0.13.1/24 --ip-masq=false --mtu=1450""\n```\n\nModify docker daemon service file:\n\n```\nvim /lib/systemd/system/docker.service\n--------------------------\n.......\n[Service]\nType=notify\nEnvironmentFile=-/run/docker_opts.env\n# the default is not to use systemd for cgroups because the delegate issues still\n# exists and systemd currently does not support the cgroup feature set required\n# for containers run by docker\nExecStart=/usr/bin/dockerd \\n          --host=fd:// \\n          --exec-opt native.cgroupdriver=systemd \\n          $DOCKER_OPTS\n```\n\nReload daemon and restart docker:\n\n```\nsystemctl daemon-reload\nsystemctl restart docker\n```\n\nCheck ip address of docker and flannel:\n\n```\nifconfig\n--------------------\ndocker0: flags=4099<UP,BROADCAST,MULTICAST>  mtu 1500\n        inet 10.0.13.1  netmask 255.255.255.0  broadcast 10.0.13.255\n        inet6 fe80::42:a1ff:fe08:e168  prefixlen 64  scopeid 0x20<link>\n        ether 02:42:a1:08:e1:68  txqueuelen 0  (Ethernet)\n        RX packets 8309  bytes 348610 (340.4 KiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 50196  bytes 73261483 (69.8 MiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n        \nflannel.1: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1450\n        inet 10.0.13.0  netmask 255.255.255.255  broadcast 0.0.0.0\n        inet6 fe80::407e:caff:fe8f:7c99  prefixlen 64  scopeid 0x20<link>\n        ether 42:7e:ca:8f:7c:99  txqueuelen 0  (Ethernet)\n        RX packets 0  bytes 0 (0.0 B)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 0  bytes 0 (0.0 B)\n        TX errors 0  dropped 9 overruns 0  carrier 0  collisions 0\n```\n\nCool, docker now joined flannel's network!\n\n## 5.8 Verify the connectivity between docker containers on two hosts\n\nFinally, let's run docker containers on two different hosts (node1 and node2), check if they can communicate with each other via etcd and flannel.\n\nOn node1:\n\n```\ndocker run -it --name=busybox-node1 busybox\n-----------------\n/ # ifconfig\neth0      Link encap:Ethernet  HWaddr 02:42:0A:00:0D:02\n          inet addr:10.0.13.2  Bcast:10.0.13.255  Mask:255.255.255.0\n          UP BROADCAST RUNNING MULTICAST  MTU:1450  Metric:1\n          RX packets:13 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0\n          RX bytes:1154 (1.1 KiB)  TX bytes:0 (0.0 B)\n\nlo        Link encap:Local Loopback\n          inet addr:127.0.0.1  Mask:255.0.0.0\n          UP LOOPBACK RUNNING  MTU:65536  Metric:1\n          RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000\n          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)\n          \n/ # ping 10.0.14.2\n--------------------------\nPING 10.0.14.2 (10.0.14.2): 56 data bytes\n64 bytes from 10.0.14.2: seq=0 ttl=62 time=3.128 ms\n64 bytes from 10.0.14.2: seq=1 ttl=62 time=1.523 ms\n64 bytes from 10.0.14.2: seq=2 ttl=62 time=1.359 ms\n```\n\nOn node2:\n\n```\ndocker run -it --name=busybox-node2 busybox\n-------------------\n/ # ifconfig\neth0      Link encap:Ethernet  HWaddr 02:42:0A:00:0E:02\n          inet addr:10.0.14.2  Bcast:10.0.14.255  Mask:255.255.255.0\n          UP BROADCAST RUNNING MULTICAST  MTU:1450  Metric:1\n          RX packets:19 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0\n          RX bytes:1690 (1.6 KiB)  TX bytes:0 (0.0 B)\n\nlo        Link encap:Local Loopback\n          inet addr:127.0.0.1  Mask:255.0.0.0\n          UP LOOPBACK RUNNING  MTU:65536  Metric:1\n          RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000\n          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)\n\n/ # ping 10.0.13.2\nPING 10.0.13.2 (10.0.13.2): 56 data bytes\n64 bytes from 10.0.13.2: seq=0 ttl=62 time=0.805 ms\n64 bytes from 10.0.13.2: seq=1 ttl=62 time=1.293 ms\n64 bytes from 10.0.13.2: seq=2 ttl=62 time=1.117 ms\n```\n\nWell done! We can see that the newly created docker container will join the flannel network, we have achieved cross-host communication between Docker containers! 🥳",2023-04-26T12:03:14.143Z,hide,com.baizeyu.published.model.Published
644d73e39ba29477b0013f0f,Mechanism for persistent storage of container data,"# 1. Introduction\n\n- Persistent storage for physical or virtual machines\n  - Since physical or virtual machines already have large-capacity disks, data can be directly stored in the local file system of the physical or virtual machine. Alternatively, additional storage systems such as NFS, GlusterFS, and Ceph can be used to achieve persistent data storage.\n\n- Persistent storage for Docker containers\n  - Since Docker containers are generated from container images, whatever files or directories are included in the container image can still be seen after the container is started.\n  - As Docker containers are considered ""disposable"" computing resources, they are not suitable for persistent data storage.\n\n# 2. Solutions\n\nDocker provides three ways to mount data from the host machine into a container:\n\n- docker run -v ('v' stands for volume)\n  - Mounts a local directory to the container at runtime.\n- Volumes\n  - A part of the host file system managed by Docker (/var/lib/docker/volumes).\n  - This is the default way that Docker stores data.\n- Bind mounts\n  - Mounts a file or directory from anywhere on the host machine into the container.\n\n# 3. Demo\n\n## 3.1 docker run -v\n\nFirst, let's create a directory on host:\n\n```\nmkdir /opt/www\n```\n\nSecond, create an index.html inside it:\n\n```\nvim index.html\n-------------\nThis is the local volume of nginx docker container!\n```\n\nNext, start a container based on Nginx image:\n\n```\ndocker run --name=nginx-volume -d -v /opt/www:/usr/share/nginx/html nginx\ndocker ps\n----------------\nCONTAINER ID   IMAGE     COMMAND                  CREATED         STATUS         PORTS     NAMES\nb22f4de7018f   nginx     ""/docker-entrypoint.…""   3 seconds ago   Up 2 seconds   80/tcp    nginx-volume\n```\n\nThen, check the ip address of the container:\n\n```\ndocker ispect b22 | grep IPAddress\n----------------------\n""IPAddress"": ""172.17.0.2"",\n```\n\nUse `curl` to get the index page on host:\n\n```\ncurl 172.17.0.2\n------------------\nThis is the local volume of nginx docker container!\n```\n\nLet's try to change the content of the index file locally?\n\n```\nvim /opt/www/index.html\n-------------------\nIndex file changed for nginx-volume!\n```\n\n`curl` again:\n\n```\ncurl 172.17.0.2\n------------------\nIndex file changed for nginx-volume!\n```\n\nWhat if we change the index file in the container? what will happen to the local file ?\n\n```\ncd ~\n\nvim index.html\n-----------------\nCopy an index file from local to container, and check local file.\n\ndocker cp index.html nginx-volume:/usr/share/nginx/html/index.html\n----------------\nSuccessfully copied 2.05kB to nginx-volume:/usr/share/nginx/html/index.html\n\ncurl 172.17.0.2\n----------------\nCopy an index file from local to container, and check local file.\n\ncat /opt/www/index.html\n-----------------\nCopy an index file from local to container, and check local file.\n```\n\nOh! The local file was changed to the one in container.\n\n**Note:** If the directory under '-v' option does not exist, it will be automatically created.\n\n## 3.2 Volumes\n\n### 3.2.1 Create a volume\n\nCreate a volume named 'nginx-vol':\n\n```\ndocker volume create nginx-vol\n------------------\nnginx-vol\n```\n\nAll the volumes are under `/var/lib/docker/volumes`:\n\n```\nls /var/lib/docker/volumes\n-------------------\nbackingFsBlockDev  metadata.db  nginx-vol\n```\n\nOr check created volumes using:\n\n```\ndocker volume ls\n-----------------\nDRIVER    VOLUME NAME\nlocal     nginx-vol\n```\n\nIt also provides `inspect` option:\n\n```\ndocker volume inspect nginx-vol\n----------------------\n[\n    {\n        ""CreatedAt"": ""2023-04-29T20:21:44+01:00"",\n        ""Driver"": ""local"",\n        ""Labels"": null,\n        ""Mountpoint"": ""/var/lib/docker/volumes/nginx-vol/_data"",\n        ""Name"": ""nginx-vol"",\n        ""Options"": null,\n        ""Scope"": ""local""\n    }\n]\n```\n\n### 3.2.2 Use volume\n\nLet's start another nginx container using the volume we created just now:\n\n```\ndocker run -d --name=nginx-volume2 --mount src=nginx-vol,dst=/usr/share/nginx/html nginx\n```\n\nor\n\n```\ndocker run -d --name-nginx-volume2 -v nginx-vol:/usr/share/nginx/html/ nginx\n```\n\n```\ndocker ps\n----------------------\nCONTAINER ID   IMAGE     COMMAND                  CREATED          STATUS          PORTS     NAMES\nd7fdfbc43579   nginx     ""/docker-entrypoint.…""   3 seconds ago    Up 2 seconds    80/tcp    nginx-volume2\n```\n\nCheck the volume directory on host machine:\n\n```\nls /var/lib/docker/volumes/nginx-vol/_data/\n----------------------\n50x.html  index.html\n```\n\nCheck the index file on host:\n\n```\ncat /var/lib/docker/volumes/nginx-vol/_data/index.html\n-------------------\n<!DOCTYPE html>\n<html>\n<head>\n<title>Welcome to nginx!</title>\n<style>\nhtml { color-scheme: light dark; }\nbody { width: 35em; margin: 0 auto;\nfont-family: Tahoma, Verdana, Arial, sans-serif; }\n</style>\n</head>\n<body>\n<h1>Welcome to nginx!</h1>\n<p>If you see this page, the nginx web server is successfully installed and\nworking. Further configuration is required.</p>\n\n<p>For online documentation and support please refer to\n<a href=""http://nginx.org/"">nginx.org</a>.<br/>\nCommercial support is available at\n<a href=""http://nginx.com/"">nginx.com</a>.</p>\n\n<p><em>Thank you for using nginx.</em></p>\n</body>\n</html>\n```\n\nIf we change the index on the host, what will we get from container's localhost?\n\n```\necho ""🥹"" > /var/lib/docker/volumes/nginx-vol/_data/index.html\n```\n\n```\ncurl 172.17.0.3\n---------------------------\n🥹\n```\n\nThis is what we expected :) \n\n## 3.3 bind mounts\n\nbind mounts allows us to bind a point wherever we want on the host machine. \n\nAlso, create a dicrectory first:\n\n```\nmkdir /opt/bind_mounts\n```\n\nStart another container:\n\n```\ndocker run -d --name=nginx-bind-mounts --mount type=bind,src=/opt/bind_mounts,dst=/usr/share/nginx/html nginx\n```\n\nCreate an html file in it:\n\n```\necho ""🤨"" > /opt/bind_mounts/index.html\n```\n\nAccess the container on host machine:\n\n```\ncurl 172.17.0.4\n---------------------\n🤨\n```\n\nThis chapter is easy!\n\n",2023-04-29T19:45:38.078Z,hide,com.baizeyu.published.model.Published
644fc7e29ba29477b0013f10,Docker Compose,"# 1. Why Compose?\n\nTo run a service in a container, you need to use the `docker run` command. But what if you want to run multiple services? Should you use one container or multiple containers?\n\nRunning multiple services in one container can increase the complexity of the image and goes against Docker's preference for one container per application. As a result, complex architectures require many containers that are dependent and connected to each other.\n\nThis complexity requires a solution, which brings up the issue of container orchestration. \n\n- Compose \n  - Orchestration \n    - A method for starting and managing multiple containers \n    - For example: start MySQL first, then Tomcat, and finally Nginx\n- Evolution of Service Architecture \n  - Monolithic Service Architecture \n  - Distributed Service Architecture \n  - Microservice Architecture \n  - Hyper-microservice Architecture \n- Container Orchestration Tools \n  - Docker Machine \n    - A tool for deploying Docker container engines in virtual machines \n  - Docker Compose \n    - A tool for defining and running multi-container Docker applications \n  - Docker Swarm \n    - A tool for batch management and resource scheduling of Docker Hosts \n  - Mesos+Marathon \n    - Mesos manages and schedules computer computing resources \n    - Marathon provides service discovery and load balancing functions \n  - Kubernetes \n    - An open source container orchestration tool developed by Google\n\n# 2. Docker Compose Intro\n\n## 2.1 Terms\n\n- Project: A group of related services that work together to provide an application.\n\n- Service: A container or group of containers that perform a specific task as part of the application.\n- Container: A standalone package of software that includes everything needed to run an application, and is isolated from other containers to ensure portability and consistency.\n\n## 2.2 How it works in brief\n\n1. Define a Dockerfile: this allows us to build an image anywhere.\n2. Define a docker-compose.yaml file.\n3. use `docker-compose up` to start an app.\n\n# 3. Docker Compose Installation\n\nDuring the installation of Docker, I also installed all related tools, including `docker-compose`. Therefore, this command is already available on my machine. \n\nIf you do not have this command, you can go to the official github release page: https://github.com/docker/compose/releases, find the package under 'Assets' that is suitable for your machine, download and install it.\n\nOr you can also follow the official documents: https://docs.docker.com/compose/install/, this might be easier for you.\n\n# 4. Docker Compose Demo\n\nWe are going to follow the official documents (https://docs.docker.com/compose/gettingstarted/) to start a simple redis-flask application on our linux machine.\n\n## 4.1 Define the application dependencies\n\nCreate a directory for the project:\n\n```\nmkdir composetest\ncd composetest\n```\n\nCreate a file called `app.py` in your project directory and paste the following code in:\n\n```\nvim app.py\n----------------\nimport time\nimport redis\nfrom flask import Flask\n\napp = Flask(__name__)\ncache = redis.Redis(host='redis', port=6379)\n\ndef get_hit_count():\n    retries = 5\n    while True:\n        try:\n            return cache.incr('hits')\n        except redis.exceptions.ConnectionError as exc:\n            if retries == 0:\n                raise exc\n            retries -= 1\n            time.sleep(0.5)\n\n@app.route('/')\ndef hello():\n    count = get_hit_count()\n    return 'Hello World! I have been seen {} times.\n'.format(count)\n```\n\nCreate another file called `requirements.txt` in your project directory and paste the following code in:\n\n```\nvim requirements.txt\n----------------------\nflask\nredis\n```\n\n## 4.2 Create a Dockerfile\n\n```\nvim Dockerfile\n--------------------\n# syntax=docker/dockerfile:1\nFROM python:3.7-alpine\nWORKDIR /code\nENV FLASK_APP=app.py\nENV FLASK_RUN_HOST=0.0.0.0\nRUN apk add --no-cache gcc musl-dev linux-headers\nCOPY requirements.txt requirements.txt\nRUN pip install -r requirements.txt\nEXPOSE 5000\nCOPY . .\nCMD [""flask"", ""run""]\n```\n\n## 4.3 Define services in a Compose file\n\n```\nvim docker-compose.yaml\n------------------------\nversion: ""3.9""\nservices:\n  web:\n    build: .\n    ports:\n      - ""8000:5000""\n  redis:\n    image: ""redis:alpine""\n```\n\n## 4.4 Build and run your app with Compose\n\n```\ndocker compose up\n-----------------------\n[+] Running 3/1\n ✔ Network composetest_default    Created                                                                                                                                  0.1s\n ✔ Container composetest-redis-1  Created                                                                                                                                  0.0s\n ✔ Container composetest-web-1    Created                                                                                                                                  0.0s\nAttaching to composetest-redis-1, composetest-web-1\ncomposetest-redis-1  | 1:C 30 Apr 2023 00:31:54.724 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\ncomposetest-redis-1  | 1:C 30 Apr 2023 00:31:54.724 # Redis version=7.0.11, bits=64, commit=00000000, modified=0, pid=1, just started\ncomposetest-redis-1  | 1:C 30 Apr 2023 00:31:54.724 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\ncomposetest-redis-1  | 1:M 30 Apr 2023 00:31:54.725 * monotonic clock: POSIX clock_gettime\ncomposetest-redis-1  | 1:M 30 Apr 2023 00:31:54.725 * Running mode=standalone, port=6379.\ncomposetest-redis-1  | 1:M 30 Apr 2023 00:31:54.725 # Server initialized\ncomposetest-redis-1  | 1:M 30 Apr 2023 00:31:54.725 # WARNING Memory overcommit must be enabled! Without it, a background save or replication may fail under low memory condition. Being disabled, it can can also cause failures without low memory condition, see https://github.com/jemalloc/jemalloc/issues/1328. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.\ncomposetest-redis-1  | 1:M 30 Apr 2023 00:31:54.727 * Ready to accept connections\ncomposetest-web-1    |  * Serving Flask app 'app.py'\ncomposetest-web-1    |  * Debug mode: off\ncomposetest-web-1    | WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\ncomposetest-web-1    |  * Running on all addresses (0.0.0.0)\ncomposetest-web-1    |  * Running on http://127.0.0.1:5000\ncomposetest-web-1    |  * Running on http://172.18.0.2:5000\ncomposetest-web-1    | Press CTRL+C to quit\n```\n\nOpen another terminal and visit:\n\n```\ncurl localhost:8000\n---------------------\nHello World! I have been seen 1 times.\n```\n\nVisit again: \n\n```\ncurl localhost:8000\n--------------------\nHello World! I have been seen 2 times.\n```\n\nCheck docker images: \n\n```\ndocker image ls\n-----------------\nREPOSITORY        TAG       IMAGE ID       CREATED         SIZE\ncomposetest-web   latest    a224d19462e3   2 minutes ago   203MB\nredis             alpine    d196fde608b2   12 days ago     30.4MB\nnginx             latest    9e7e7b26c784   2 weeks ago     135MB\n```\n\nGreat! This was just a quick and simple demonstration. If you want to learn more, I encourage you to visit the documentation I mentioned earlier at https://docs.docker.com/compose/gettingstarted/. There, you can find complete and detailed information on Docker Compose and its functionality.",2023-05-01T14:09:00.952Z,hide,com.baizeyu.published.model.Published
